{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch \n",
    "- https://pytorch.org\n",
    "- https://pytorch.org/tutorials\n",
    "- https://github.com/pytorch/pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation with jupyterhub/jupyterlab.\n",
    "\n",
    "```\n",
    "conda install numpy\n",
    "conda install scikit-image\n",
    "\n",
    "conda install pytorch torchvision cudatoolkit=10.0 -c pytorch\n",
    "# or: conda install pytorch-cpu torchvision-cpu -c pytorch\n",
    "\n",
    "conda update --all\n",
    "```\n",
    "## Installation with kubernetes.\n",
    "- PyTorch支持Kubernetes集群, https://my.oschina.net/u/2306127/blog/1817835\n",
    "  -  Kubeflow 使用指南，https://my.oschina.net/u/2306127/blog/1808582\n",
    "  -  pytorch-operator 项目源码，https://github.com/kubeflow/pytorch-operator\n",
    "  -  pytorch-operator on Kubernetes，https://my.oschina.net/u/2306127/blog/1811457"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get tutorial data.\n",
    "- https://download.pytorch.org/tutorial/faces.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.0.176\n"
     ]
    }
   ],
   "source": [
    "print(torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package torch:\n",
      "\n",
      "NAME\n",
      "    torch\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    _C\n",
      "    _dl\n",
      "    _nvrtc\n",
      "    _six\n",
      "    _storage_docs\n",
      "    _tensor_docs\n",
      "    _tensor_str\n",
      "    _thnn (package)\n",
      "    _torch_docs\n",
      "    _utils\n",
      "    autograd (package)\n",
      "    backends (package)\n",
      "    contrib (package)\n",
      "    cuda (package)\n",
      "    distributed (package)\n",
      "    distributions (package)\n",
      "    for_onnx (package)\n",
      "    functional\n",
      "    jit (package)\n",
      "    legacy (package)\n",
      "    multiprocessing (package)\n",
      "    nn (package)\n",
      "    onnx (package)\n",
      "    optim (package)\n",
      "    random\n",
      "    serialization\n",
      "    sparse (package)\n",
      "    storage\n",
      "    tensor\n",
      "    testing (package)\n",
      "    utils (package)\n",
      "    version\n",
      "\n",
      "CLASSES\n",
      "    builtins.Exception(builtins.BaseException)\n",
      "        FatalError\n",
      "    builtins.object\n",
      "        builtins.module\n",
      "        ByteTensor\n",
      "        CharTensor\n",
      "        Device\n",
      "        DoubleTensor\n",
      "        FloatTensor\n",
      "        IntTensor\n",
      "        LongTensor\n",
      "        ShortTensor\n",
      "        dtype\n",
      "        layout\n",
      "        torch._C.Generator\n",
      "        torch.autograd.grad_mode.enable_grad\n",
      "        torch.autograd.grad_mode.no_grad\n",
      "        torch.autograd.grad_mode.set_grad_enabled\n",
      "    builtins.tuple(builtins.object)\n",
      "        Size\n",
      "    pybind11_builtins.pybind11_object(builtins.object)\n",
      "        torch._C.CompiledFunction\n",
      "        torch._C.Graph\n",
      "        torch._C.GraphExecutor\n",
      "        torch._C.IODescriptor\n",
      "        torch._C.InterpreterFunctionFactory\n",
      "        torch._C.Node\n",
      "        torch._C.ScriptMethod\n",
      "        torch._C.ScriptModule\n",
      "        torch._C.TracingState\n",
      "        torch._C.Type\n",
      "        torch._C.Use\n",
      "        torch._C.Value\n",
      "    torch._C.ByteStorageBase(builtins.object)\n",
      "        ByteStorage(torch._C.ByteStorageBase, torch.storage._StorageBase)\n",
      "    torch._C.CharStorageBase(builtins.object)\n",
      "        CharStorage(torch._C.CharStorageBase, torch.storage._StorageBase)\n",
      "    torch._C.DoubleStorageBase(builtins.object)\n",
      "        DoubleStorage(torch._C.DoubleStorageBase, torch.storage._StorageBase)\n",
      "    torch._C.FloatStorageBase(builtins.object)\n",
      "        FloatStorage(torch._C.FloatStorageBase, torch.storage._StorageBase)\n",
      "    torch._C.IntStorageBase(builtins.object)\n",
      "        IntStorage(torch._C.IntStorageBase, torch.storage._StorageBase)\n",
      "    torch._C.LongStorageBase(builtins.object)\n",
      "        LongStorage(torch._C.LongStorageBase, torch.storage._StorageBase)\n",
      "    torch._C.ShortStorageBase(builtins.object)\n",
      "        ShortStorage(torch._C.ShortStorageBase, torch.storage._StorageBase)\n",
      "    torch._C._TensorBase(builtins.object)\n",
      "        Tensor\n",
      "    torch.storage._StorageBase(builtins.object)\n",
      "        ByteStorage(torch._C.ByteStorageBase, torch.storage._StorageBase)\n",
      "        CharStorage(torch._C.CharStorageBase, torch.storage._StorageBase)\n",
      "        DoubleStorage(torch._C.DoubleStorageBase, torch.storage._StorageBase)\n",
      "        FloatStorage(torch._C.FloatStorageBase, torch.storage._StorageBase)\n",
      "        IntStorage(torch._C.IntStorageBase, torch.storage._StorageBase)\n",
      "        LongStorage(torch._C.LongStorageBase, torch.storage._StorageBase)\n",
      "        ShortStorage(torch._C.ShortStorageBase, torch.storage._StorageBase)\n",
      "    \n",
      "    class ByteStorage(torch._C.ByteStorageBase, torch.storage._StorageBase)\n",
      "     |  Method resolution order:\n",
      "     |      ByteStorage\n",
      "     |      torch._C.ByteStorageBase\n",
      "     |      torch.storage._StorageBase\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch._C.ByteStorageBase:\n",
      "     |  \n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |  \n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |  \n",
      "     |  __len__(self, /)\n",
      "     |      Return len(self).\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  __setitem__(self, key, value, /)\n",
      "     |      Set self[key] to value.\n",
      "     |  \n",
      "     |  copy_(...)\n",
      "     |  \n",
      "     |  data_ptr(...)\n",
      "     |  \n",
      "     |  element_size(...)\n",
      "     |  \n",
      "     |  fill_(...)\n",
      "     |  \n",
      "     |  is_pinned(...)\n",
      "     |  \n",
      "     |  is_shared(...)\n",
      "     |  \n",
      "     |  new(...)\n",
      "     |  \n",
      "     |  resize_(...)\n",
      "     |  \n",
      "     |  size(...)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from torch._C.ByteStorageBase:\n",
      "     |  \n",
      "     |  from_buffer(...)\n",
      "     |  \n",
      "     |  from_file(...)\n",
      "     |      from_file(filename, shared=False, size=0) -> Storage\n",
      "     |      \n",
      "     |      If `shared` is `True`, then memory is shared between all processes.\n",
      "     |      All changes are written to the file. If `shared` is `False`, then the changes on\n",
      "     |      the storage do not affect the file.\n",
      "     |      \n",
      "     |      `size` is the number of elements in the storage. If `shared` is `False`,\n",
      "     |      then the file must contain at least `size * sizeof(Type)` bytes\n",
      "     |      (`Type` is the type of storage). If `shared` is `True` the file will be\n",
      "     |      created if needed.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          filename (str): file name to map\n",
      "     |          shared (bool): whether to share memory\n",
      "     |          size (int): number of elements in the storage\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.storage._StorageBase:\n",
      "     |  \n",
      "     |  __copy__(self)\n",
      "     |  \n",
      "     |  __deepcopy__(self, memo)\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      helper for pickle\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __sizeof__(self)\n",
      "     |      __sizeof__() -> int\n",
      "     |      size of object in memory, in bytes\n",
      "     |  \n",
      "     |  __str__(self)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  byte(self)\n",
      "     |      Casts this storage to byte type\n",
      "     |  \n",
      "     |  char(self)\n",
      "     |      Casts this storage to char type\n",
      "     |  \n",
      "     |  clone(self)\n",
      "     |      Returns a copy of this storage\n",
      "     |  \n",
      "     |  cpu(self)\n",
      "     |      Returns a CPU copy of this storage if it's not already on the CPU\n",
      "     |  \n",
      "     |  cuda = _cuda(self, device=None, non_blocking=False, **kwargs)\n",
      "     |      Returns a copy of this object in CUDA memory.\n",
      "     |      \n",
      "     |      If this object is already in CUDA memory and on the correct device, then\n",
      "     |      no copy is performed and the original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          device (int): The destination GPU id. Defaults to the current device.\n",
      "     |          non_blocking (bool): If ``True`` and the source is in pinned memory,\n",
      "     |              the copy will be asynchronous with respect to the host. Otherwise,\n",
      "     |              the argument has no effect.\n",
      "     |          **kwargs: For compatibility, may contain the key ``async`` in place of\n",
      "     |              the ``non_blocking`` argument.\n",
      "     |  \n",
      "     |  double(self)\n",
      "     |      Casts this storage to double type\n",
      "     |  \n",
      "     |  float(self)\n",
      "     |      Casts this storage to float type\n",
      "     |  \n",
      "     |  half(self)\n",
      "     |      Casts this storage to half type\n",
      "     |  \n",
      "     |  int(self)\n",
      "     |      Casts this storage to int type\n",
      "     |  \n",
      "     |  long(self)\n",
      "     |      Casts this storage to long type\n",
      "     |  \n",
      "     |  pin_memory(self)\n",
      "     |      Copies the storage to pinned memory, if it's not already pinned.\n",
      "     |  \n",
      "     |  share_memory_(self)\n",
      "     |      Moves the storage to shared memory.\n",
      "     |      \n",
      "     |      This is a no-op for storages already in shared memory and for CUDA\n",
      "     |      storages, which do not need to be moved for sharing across processes.\n",
      "     |      Storages in shared memory cannot be resized.\n",
      "     |      \n",
      "     |      Returns: self\n",
      "     |  \n",
      "     |  short(self)\n",
      "     |      Casts this storage to short type\n",
      "     |  \n",
      "     |  tolist(self)\n",
      "     |      Returns a list containing the elements of this storage\n",
      "     |  \n",
      "     |  type = _type(self, dtype=None, non_blocking=False, **kwargs)\n",
      "     |      Returns the type if `dtype` is not provided, else casts this object to\n",
      "     |      the specified type.\n",
      "     |      \n",
      "     |      If this is already of the correct type, no copy is performed and the\n",
      "     |      original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (type or string): The desired type\n",
      "     |          non_blocking (bool): If ``True``, and the source is in pinned memory\n",
      "     |              and destination is on the GPU or vice versa, the copy is performed\n",
      "     |              asynchronously with respect to the host. Otherwise, the argument\n",
      "     |              has no effect.\n",
      "     |          **kwargs: For compatibility, may contain the key ``async`` in place of\n",
      "     |              the ``non_blocking`` argument. The ``async`` arg is deprecated.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.storage._StorageBase:\n",
      "     |  \n",
      "     |  is_cuda = False\n",
      "     |  \n",
      "     |  is_sparse = False\n",
      "    \n",
      "    class ByteTensor(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __abs__ = abs(...)\n",
      "     |  \n",
      "     |  __add__(...)\n",
      "     |  \n",
      "     |  __and__(...)\n",
      "     |  \n",
      "     |  __array__(self, dtype=None)\n",
      "     |      # Numpy array interface, to support `numpy.asarray(tensor) -> ndarray`\n",
      "     |  \n",
      "     |  __array_wrap__(self, array)\n",
      "     |      # Wrap Numpy array again in a suitable tensor when done, to support e.g.\n",
      "     |      # `numpy.sin(tensor) -> tensor` or `numpy.greater(tensor, 0) -> ByteTensor`\n",
      "     |  \n",
      "     |  __bool__(...)\n",
      "     |  \n",
      "     |  __deepcopy__(self, memo)\n",
      "     |  \n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |  \n",
      "     |  __dir__(self)\n",
      "     |      __dir__() -> list\n",
      "     |      default dir() implementation\n",
      "     |  \n",
      "     |  __div__(...)\n",
      "     |  \n",
      "     |  __eq__ = eq(...)\n",
      "     |  \n",
      "     |  __float__(...)\n",
      "     |  \n",
      "     |  __format__(self, format_spec)\n",
      "     |      default object formatter\n",
      "     |  \n",
      "     |  __ge__ = ge(...)\n",
      "     |  \n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |  \n",
      "     |  __gt__ = gt(...)\n",
      "     |  \n",
      "     |  __hash__(self)\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __iadd__(...)\n",
      "     |  \n",
      "     |  __iand__(...)\n",
      "     |  \n",
      "     |  __idiv__(...)\n",
      "     |  \n",
      "     |  __ilshift__(...)\n",
      "     |  \n",
      "     |  __imul__(...)\n",
      "     |  \n",
      "     |  __index__(...)\n",
      "     |  \n",
      "     |  __int__(...)\n",
      "     |  \n",
      "     |  __invert__(...)\n",
      "     |  \n",
      "     |  __ior__(...)\n",
      "     |  \n",
      "     |  __ipow__(self, other)\n",
      "     |  \n",
      "     |  __irshift__(...)\n",
      "     |  \n",
      "     |  __isub__(...)\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |  \n",
      "     |  __itruediv__ = __idiv__(...)\n",
      "     |  \n",
      "     |  __ixor__(...)\n",
      "     |  \n",
      "     |  __le__ = le(...)\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |      Return len(self).\n",
      "     |  \n",
      "     |  __long__(...)\n",
      "     |  \n",
      "     |  __lshift__(...)\n",
      "     |  \n",
      "     |  __lt__ = lt(...)\n",
      "     |  \n",
      "     |  __matmul__(...)\n",
      "     |  \n",
      "     |  __mod__(...)\n",
      "     |  \n",
      "     |  __mul__(...)\n",
      "     |  \n",
      "     |  __ne__ = ne(...)\n",
      "     |  \n",
      "     |  __neg__ = neg(...)\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from tensortype\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  __nonzero__(...)\n",
      "     |  \n",
      "     |  __or__(...)\n",
      "     |  \n",
      "     |  __pow__ = pow(...)\n",
      "     |  \n",
      "     |  __radd__(...)\n",
      "     |  \n",
      "     |  __rdiv__(self, other)\n",
      "     |  \n",
      "     |  __reduce_ex__(self, proto)\n",
      "     |      helper for pickle\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __rmul__(...)\n",
      "     |  \n",
      "     |  __rpow__(self, other)\n",
      "     |  \n",
      "     |  __rshift__(...)\n",
      "     |  \n",
      "     |  __rsub__(self, other)\n",
      "     |  \n",
      "     |  __rtruediv__ = __rdiv__(self, other)\n",
      "     |  \n",
      "     |  __setitem__(self, key, value, /)\n",
      "     |      Set self[key] to value.\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |  \n",
      "     |  __sub__(...)\n",
      "     |  \n",
      "     |  __truediv__(...)\n",
      "     |  \n",
      "     |  __xor__(...)\n",
      "     |  \n",
      "     |  abs(...)\n",
      "     |      abs() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.abs`\n",
      "     |  \n",
      "     |  abs_(...)\n",
      "     |      abs_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.abs`\n",
      "     |  \n",
      "     |  acos(...)\n",
      "     |      acos() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.acos`\n",
      "     |  \n",
      "     |  acos_(...)\n",
      "     |      acos_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.acos`\n",
      "     |  \n",
      "     |  add(...)\n",
      "     |      add(value) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.add`\n",
      "     |  \n",
      "     |  add_(...)\n",
      "     |      add_(value) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.add`\n",
      "     |  \n",
      "     |  addbmm(...)\n",
      "     |      addbmm(beta=1, mat, alpha=1, batch1, batch2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addbmm`\n",
      "     |  \n",
      "     |  addbmm_(...)\n",
      "     |      addbmm_(beta=1, mat, alpha=1, batch1, batch2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addbmm`\n",
      "     |  \n",
      "     |  addcdiv(...)\n",
      "     |      addcdiv(value=1, tensor1, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addcdiv`\n",
      "     |  \n",
      "     |  addcdiv_(...)\n",
      "     |      addcdiv_(value=1, tensor1, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addcdiv`\n",
      "     |  \n",
      "     |  addcmul(...)\n",
      "     |      addcmul(value=1, tensor1, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addcmul`\n",
      "     |  \n",
      "     |  addcmul_(...)\n",
      "     |      addcmul_(value=1, tensor1, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addcmul`\n",
      "     |  \n",
      "     |  addmm(...)\n",
      "     |      addmm(beta=1, mat, alpha=1, mat1, mat2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addmm`\n",
      "     |  \n",
      "     |  addmm_(...)\n",
      "     |      addmm_(beta=1, mat, alpha=1, mat1, mat2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addmm`\n",
      "     |  \n",
      "     |  addmv(...)\n",
      "     |      addmv(beta=1, tensor, alpha=1, mat, vec) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addmv`\n",
      "     |  \n",
      "     |  addmv_(...)\n",
      "     |      addmv_(beta=1, tensor, alpha=1, mat, vec) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addmv`\n",
      "     |  \n",
      "     |  addr(...)\n",
      "     |      addr(beta=1, alpha=1, vec1, vec2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addr`\n",
      "     |  \n",
      "     |  addr_(...)\n",
      "     |      addr_(beta=1, alpha=1, vec1, vec2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addr`\n",
      "     |  \n",
      "     |  all(...)\n",
      "     |      all() -> bool\n",
      "     |      \n",
      "     |      Returns ``True`` if all elements in the tensor are non-zero, ``False`` otherwise.\n",
      "     |  \n",
      "     |  allclose(...)\n",
      "     |  \n",
      "     |  any(...)\n",
      "     |      any() -> bool\n",
      "     |      \n",
      "     |      Returns ``True`` if any elements in the tensor are non-zero, ``False`` otherwise.\n",
      "     |  \n",
      "     |  apply_(...)\n",
      "     |      apply_(callable) -> Tensor\n",
      "     |      \n",
      "     |      Applies the function :attr:`callable` to each element in the tensor, replacing\n",
      "     |      each element with the value returned by :attr:`callable`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          This function only works with CPU tensors and should not be used in code\n",
      "     |          sections that require high performance.\n",
      "     |  \n",
      "     |  argmax(self, dim=None, keepdim=False)\n",
      "     |      See :func:`torch.argmax`\n",
      "     |  \n",
      "     |  argmin(self, dim=None, keepdim=False)\n",
      "     |      See :func:`torch.argmin`\n",
      "     |  \n",
      "     |  as_strided(...)\n",
      "     |  \n",
      "     |  as_strided_(...)\n",
      "     |  \n",
      "     |  asin(...)\n",
      "     |      asin() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.asin`\n",
      "     |  \n",
      "     |  asin_(...)\n",
      "     |      asin_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.asin`\n",
      "     |  \n",
      "     |  atan(...)\n",
      "     |      atan() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.atan`\n",
      "     |  \n",
      "     |  atan2(...)\n",
      "     |      atan2(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.atan2`\n",
      "     |  \n",
      "     |  atan2_(...)\n",
      "     |      atan2_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.atan2`\n",
      "     |  \n",
      "     |  atan_(...)\n",
      "     |      atan_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.atan`\n",
      "     |  \n",
      "     |  backward(self, gradient=None, retain_graph=None, create_graph=False)\n",
      "     |      Computes the gradient of current tensor w.r.t. graph leaves.\n",
      "     |      \n",
      "     |      The graph is differentiated using the chain rule. If the tensor is\n",
      "     |      non-scalar (i.e. its data has more than one element) and requires\n",
      "     |      gradient, the function additionally requires specifying ``gradient``.\n",
      "     |      It should be a tensor of matching type and location, that contains\n",
      "     |      the gradient of the differentiated function w.r.t. ``self``.\n",
      "     |      \n",
      "     |      This function accumulates gradients in the leaves - you might need to\n",
      "     |      zero them before calling it.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          gradient (Tensor or None): Gradient w.r.t. the\n",
      "     |              tensor. If it is a tensor, it will be automatically converted\n",
      "     |              to a Tensor that does not require grad unless ``create_graph`` is True.\n",
      "     |              None values can be specified for scalar Tensors or ones that\n",
      "     |              don't require grad. If a None value would be acceptable then\n",
      "     |              this argument is optional.\n",
      "     |          retain_graph (bool, optional): If ``False``, the graph used to compute\n",
      "     |              the grads will be freed. Note that in nearly all cases setting\n",
      "     |              this option to True is not needed and often can be worked around\n",
      "     |              in a much more efficient way. Defaults to the value of\n",
      "     |              ``create_graph``.\n",
      "     |          create_graph (bool, optional): If ``True``, graph of the derivative will\n",
      "     |              be constructed, allowing to compute higher order derivative\n",
      "     |              products. Defaults to ``False``.\n",
      "     |  \n",
      "     |  baddbmm(...)\n",
      "     |      baddbmm(beta=1, alpha=1, batch1, batch2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.baddbmm`\n",
      "     |  \n",
      "     |  baddbmm_(...)\n",
      "     |      baddbmm_(beta=1, alpha=1, batch1, batch2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.baddbmm`\n",
      "     |  \n",
      "     |  bernoulli(...)\n",
      "     |      bernoulli() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bernoulli`\n",
      "     |  \n",
      "     |  bernoulli_(...)\n",
      "     |      bernoulli_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.bernoulli`\n",
      "     |  \n",
      "     |  bmm(...)\n",
      "     |      bmm(batch2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bmm`\n",
      "     |  \n",
      "     |  btrifact(self, info=None, pivot=True)\n",
      "     |      See :func:`torch.btrifact`\n",
      "     |  \n",
      "     |  btrifact_with_info(...)\n",
      "     |      btrifact_with_info(pivot=True) -> (Tensor, Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.btrifact_with_info`\n",
      "     |  \n",
      "     |  btrisolve(...)\n",
      "     |  \n",
      "     |  byte(...)\n",
      "     |      byte() -> Tensor\n",
      "     |      \n",
      "     |      ``self.byte()`` is equivalent to ``self.to(torch.uint8)``. See :func:`to`.\n",
      "     |  \n",
      "     |  cauchy_(...)\n",
      "     |      cauchy_(median=0, sigma=1, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills the tensor with numbers drawn from the Cauchy distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(x) = \\dfrac{1}{\\pi} \\dfrac{\\sigma}{(x - median)^2 + \\sigma^2}\n",
      "     |  \n",
      "     |  ceil(...)\n",
      "     |      ceil() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ceil`\n",
      "     |  \n",
      "     |  ceil_(...)\n",
      "     |      ceil_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ceil`\n",
      "     |  \n",
      "     |  char(...)\n",
      "     |      char() -> Tensor\n",
      "     |      \n",
      "     |      ``self.char()`` is equivalent to ``self.to(torch.int8)``. See :func:`to`.\n",
      "     |  \n",
      "     |  chunk(...)\n",
      "     |      chunk(chunks, dim=0) -> List of Tensors\n",
      "     |      \n",
      "     |      See :func:`torch.chunk`\n",
      "     |  \n",
      "     |  clamp(...)\n",
      "     |      clamp(min, max) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.clamp`\n",
      "     |  \n",
      "     |  clamp_(...)\n",
      "     |      clamp_(min, max) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.clamp`\n",
      "     |  \n",
      "     |  clone(...)\n",
      "     |      clone() -> Tensor\n",
      "     |      \n",
      "     |      Returns a copy of the :attr:`self` tensor. The copy has the same size and data\n",
      "     |      type as :attr:`self`.\n",
      "     |  \n",
      "     |  coalesce(...)\n",
      "     |  \n",
      "     |  contiguous(...)\n",
      "     |      contiguous() -> Tensor\n",
      "     |      \n",
      "     |      Returns a contiguous tensor containing the same data as :attr:`self` tensor. If\n",
      "     |      :attr:`self` tensor is contiguous, this function returns the :attr:`self`\n",
      "     |      tensor.\n",
      "     |  \n",
      "     |  conv_tbc(...)\n",
      "     |  \n",
      "     |  copy_(...)\n",
      "     |      copy_(src, non_blocking=False) -> Tensor\n",
      "     |      \n",
      "     |      Copies the elements from :attr:`src` into :attr:`self` tensor and returns\n",
      "     |      :attr:`self`.\n",
      "     |      \n",
      "     |      The :attr:`src` tensor must be :ref:`broadcastable <broadcasting-semantics>`\n",
      "     |      with the :attr:`self` tensor. It may be of a different data type or reside on a\n",
      "     |      different device.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          src (Tensor): the source tensor to copy from\n",
      "     |          non_blocking (bool): if ``True`` and this copy is between CPU and GPU,\n",
      "     |              the copy may occur asynchronously with respect to the host. For other\n",
      "     |              cases, this argument has no effect.\n",
      "     |  \n",
      "     |  cos(...)\n",
      "     |      cos() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cos`\n",
      "     |  \n",
      "     |  cos_(...)\n",
      "     |      cos_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.cos`\n",
      "     |  \n",
      "     |  cosh(...)\n",
      "     |      cosh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cosh`\n",
      "     |  \n",
      "     |  cosh_(...)\n",
      "     |      cosh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.cosh`\n",
      "     |  \n",
      "     |  cpu(...)\n",
      "     |  \n",
      "     |  cross(...)\n",
      "     |      cross(other, dim=-1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cross`\n",
      "     |  \n",
      "     |  cuda(...)\n",
      "     |      cuda(device=None, non_blocking=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a copy of this object in CUDA memory.\n",
      "     |      \n",
      "     |      If this object is already in CUDA memory and on the correct device,\n",
      "     |      then no copy is performed and the original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          device (:class:`torch.device`): The destination GPU device.\n",
      "     |              Defaults to the current CUDA device.\n",
      "     |          non_blocking (bool): If ``True`` and the source is in pinned memory,\n",
      "     |              the copy will be asynchronous with respect to the host.\n",
      "     |              Otherwise, the argument has no effect. Default: ``False``.\n",
      "     |  \n",
      "     |  cumprod(...)\n",
      "     |      cumprod(dim) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cumprod`\n",
      "     |  \n",
      "     |  cumsum(...)\n",
      "     |      cumsum(dim) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cumsum`\n",
      "     |  \n",
      "     |  data_ptr(...)\n",
      "     |      data_ptr() -> int\n",
      "     |      \n",
      "     |      Returns the address of the first element of :attr:`self` tensor.\n",
      "     |  \n",
      "     |  det(...)\n",
      "     |      det() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.det`\n",
      "     |  \n",
      "     |  detach(...)\n",
      "     |      Returns a new Tensor, detached from the current graph.\n",
      "     |      \n",
      "     |      The result will never require gradient.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |        Returned Tensor uses the same data tensor as the original one.\n",
      "     |        In-place modifications on either of them will be seen, and may trigger\n",
      "     |        errors in correctness checks.\n",
      "     |  \n",
      "     |  detach_(...)\n",
      "     |      Detaches the Tensor from the graph that created it, making it a leaf.\n",
      "     |      Views cannot be detached in-place.\n",
      "     |  \n",
      "     |  diag(...)\n",
      "     |      diag(diagonal=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diag`\n",
      "     |  \n",
      "     |  digamma(...)\n",
      "     |  \n",
      "     |  digamma_(...)\n",
      "     |  \n",
      "     |  dim(...)\n",
      "     |      dim() -> int\n",
      "     |      \n",
      "     |      Returns the number of dimensions of :attr:`self` tensor.\n",
      "     |  \n",
      "     |  dist(...)\n",
      "     |      dist(other, p=2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.dist`\n",
      "     |  \n",
      "     |  div(...)\n",
      "     |      div(value) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.div`\n",
      "     |  \n",
      "     |  div_(...)\n",
      "     |      div_(value) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.div`\n",
      "     |  \n",
      "     |  dot(...)\n",
      "     |      dot(tensor2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.dot`\n",
      "     |  \n",
      "     |  double(...)\n",
      "     |      double() -> Tensor\n",
      "     |      \n",
      "     |      ``self.double()`` is equivalent to ``self.to(torch.float64)``. See :func:`to`.\n",
      "     |  \n",
      "     |  eig(...)\n",
      "     |      eig(eigenvectors=False) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.eig`\n",
      "     |  \n",
      "     |  element_size(...)\n",
      "     |      element_size() -> int\n",
      "     |      \n",
      "     |      Returns the size in bytes of an individual element.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> torch.tensor([]).element_size()\n",
      "     |          4\n",
      "     |          >>> torch.tensor([], dtype=torch.uint8).element_size()\n",
      "     |          1\n",
      "     |  \n",
      "     |  eq(...)\n",
      "     |      eq(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.eq`\n",
      "     |  \n",
      "     |  eq_(...)\n",
      "     |      eq_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.eq`\n",
      "     |  \n",
      "     |  equal(...)\n",
      "     |      equal(other) -> bool\n",
      "     |      \n",
      "     |      See :func:`torch.equal`\n",
      "     |  \n",
      "     |  erf(...)\n",
      "     |      erf() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.erf`\n",
      "     |  \n",
      "     |  erf_(...)\n",
      "     |  \n",
      "     |  erfinv(...)\n",
      "     |      erfinv() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.erfinv`\n",
      "     |  \n",
      "     |  erfinv_(...)\n",
      "     |  \n",
      "     |  exp(...)\n",
      "     |      exp() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.exp`\n",
      "     |  \n",
      "     |  exp_(...)\n",
      "     |      exp_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.exp`\n",
      "     |  \n",
      "     |  expand(...)\n",
      "     |      expand(*sizes) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new view of the :attr:`self` tensor with singleton dimensions expanded\n",
      "     |      to a larger size.\n",
      "     |      \n",
      "     |      Passing -1 as the size for a dimension means not changing the size of\n",
      "     |      that dimension.\n",
      "     |      \n",
      "     |      Tensor can be also expanded to a larger number of dimensions, and the\n",
      "     |      new ones will be appended at the front. For the new dimensions, the\n",
      "     |      size cannot be set to -1.\n",
      "     |      \n",
      "     |      Expanding a tensor does not allocate new memory, but only creates a\n",
      "     |      new view on the existing tensor where a dimension of size one is\n",
      "     |      expanded to a larger size by setting the ``stride`` to 0. Any dimension\n",
      "     |      of size 1 can be expanded to an arbitrary value without allocating new\n",
      "     |      memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *sizes (torch.Size or int...): the desired expanded size\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1], [2], [3]])\n",
      "     |          >>> x.size()\n",
      "     |          torch.Size([3, 1])\n",
      "     |          >>> x.expand(3, 4)\n",
      "     |          tensor([[ 1,  1,  1,  1],\n",
      "     |                  [ 2,  2,  2,  2],\n",
      "     |                  [ 3,  3,  3,  3]])\n",
      "     |          >>> x.expand(-1, 4)   # -1 means not changing the size of that dimension\n",
      "     |          tensor([[ 1,  1,  1,  1],\n",
      "     |                  [ 2,  2,  2,  2],\n",
      "     |                  [ 3,  3,  3,  3]])\n",
      "     |  \n",
      "     |  expand_as(self, tensor)\n",
      "     |  \n",
      "     |  expm1(...)\n",
      "     |      expm1() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.expm1`\n",
      "     |  \n",
      "     |  expm1_(...)\n",
      "     |      expm1_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.expm1`\n",
      "     |  \n",
      "     |  exponential_(...)\n",
      "     |      exponential_(lambd=1, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with elements drawn from the exponential distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(x) = \\lambda e^{-\\lambda x}\n",
      "     |  \n",
      "     |  fft(...)\n",
      "     |      fft(signal_ndim, normalized=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fft`\n",
      "     |  \n",
      "     |  fill_(...)\n",
      "     |      fill_(value) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with the specified value.\n",
      "     |  \n",
      "     |  float(...)\n",
      "     |      float() -> Tensor\n",
      "     |      \n",
      "     |      ``self.float()`` is equivalent to ``self.to(torch.float32)``. See :func:`to`.\n",
      "     |  \n",
      "     |  floor(...)\n",
      "     |      floor() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.floor`\n",
      "     |  \n",
      "     |  floor_(...)\n",
      "     |      floor_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.floor`\n",
      "     |  \n",
      "     |  fmod(...)\n",
      "     |      fmod(divisor) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fmod`\n",
      "     |  \n",
      "     |  fmod_(...)\n",
      "     |      fmod_(divisor) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.fmod`\n",
      "     |  \n",
      "     |  frac(...)\n",
      "     |      frac() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.frac`\n",
      "     |  \n",
      "     |  frac_(...)\n",
      "     |      frac_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.frac`\n",
      "     |  \n",
      "     |  gather(...)\n",
      "     |      gather(dim, index) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.gather`\n",
      "     |  \n",
      "     |  ge(...)\n",
      "     |      ge(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ge`\n",
      "     |  \n",
      "     |  ge_(...)\n",
      "     |      ge_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ge`\n",
      "     |  \n",
      "     |  gels(...)\n",
      "     |      gels(A) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.gels`\n",
      "     |  \n",
      "     |  geometric_(...)\n",
      "     |      geometric_(p, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with elements drawn from the geometric distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(X=k) = (1 - p)^{k - 1} p\n",
      "     |  \n",
      "     |  geqrf(...)\n",
      "     |      geqrf() -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.geqrf`\n",
      "     |  \n",
      "     |  ger(...)\n",
      "     |      ger(vec2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ger`\n",
      "     |  \n",
      "     |  gesv(...)\n",
      "     |      gesv(A) -> Tensor, Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.gesv`\n",
      "     |  \n",
      "     |  get_device(...)\n",
      "     |  \n",
      "     |  gt(...)\n",
      "     |      gt(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.gt`\n",
      "     |  \n",
      "     |  gt_(...)\n",
      "     |      gt_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.gt`\n",
      "     |  \n",
      "     |  half(...)\n",
      "     |      half() -> Tensor\n",
      "     |      \n",
      "     |      ``self.half()`` is equivalent to ``self.to(torch.float16)``. See :func:`to`.\n",
      "     |  \n",
      "     |  histc(...)\n",
      "     |      histc(bins=100, min=0, max=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.histc`\n",
      "     |  \n",
      "     |  ifft(...)\n",
      "     |      ifft(signal_ndim, normalized=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ifft`\n",
      "     |  \n",
      "     |  index(...)\n",
      "     |      index(m) -> Tensor\n",
      "     |      \n",
      "     |      Selects elements from :attr:`self` tensor using a binary mask or along a given\n",
      "     |      dimension. The expression ``tensor.index(m)`` is equivalent to ``tensor[m]``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          m (int or ByteTensor or slice): the dimension or mask used to select elements\n",
      "     |  \n",
      "     |  index_add(self, dim, index, tensor)\n",
      "     |  \n",
      "     |  index_add_(...)\n",
      "     |      index_add_(dim, index, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Accumulate the elements of :attr:`tensor` into the :attr:`self` tensor by adding\n",
      "     |      to the indices in the order given in :attr:`index`. For example, if ``dim == 0``\n",
      "     |      and ``index[i] == j``, then the ``i``\\ th row of :attr:`tensor` is added to the\n",
      "     |      ``j``\\ th row of :attr:`self`.\n",
      "     |      \n",
      "     |      The :attr:`dim`\\ th dimension of :attr:`tensor` must have the same size as the\n",
      "     |      length of :attr:`index` (which must be a vector), and all other dimensions must\n",
      "     |      match :attr:`self`, or an error will be raised.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension along which to index\n",
      "     |          index (LongTensor): indices of :attr:`tensor` to select from\n",
      "     |          tensor (Tensor): the tensor containing values to add\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.ones(5, 3)\n",
      "     |          >>> t = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
      "     |          >>> index = torch.tensor([0, 4, 2])\n",
      "     |          >>> x.index_add_(0, index, t)\n",
      "     |          tensor([[  2.,   3.,   4.],\n",
      "     |                  [  1.,   1.,   1.],\n",
      "     |                  [  8.,   9.,  10.],\n",
      "     |                  [  1.,   1.,   1.],\n",
      "     |                  [  5.,   6.,   7.]])\n",
      "     |  \n",
      "     |  index_copy(self, dim, index, tensor)\n",
      "     |  \n",
      "     |  index_copy_(...)\n",
      "     |      index_copy_(dim, index, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Copies the elements of :attr:`tensor` into the :attr:`self` tensor by selecting\n",
      "     |      the indices in the order given in :attr:`index`. For example, if ``dim == 0``\n",
      "     |      and ``index[i] == j``, then the ``i``\\ th row of :attr:`tensor` is copied to the\n",
      "     |      ``j``\\ th row of :attr:`self`.\n",
      "     |      \n",
      "     |      The :attr:`dim`\\ th dimension of :attr:`tensor` must have the same size as the\n",
      "     |      length of :attr:`index` (which must be a vector), and all other dimensions must\n",
      "     |      match :attr:`self`, or an error will be raised.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension along which to index\n",
      "     |          index (LongTensor): indices of :attr:`tensor` to select from\n",
      "     |          tensor (Tensor): the tensor containing values to copy\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.zeros(5, 3)\n",
      "     |          >>> t = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
      "     |          >>> index = torch.tensor([0, 4, 2])\n",
      "     |          >>> x.index_copy_(0, index, t)\n",
      "     |          tensor([[ 1.,  2.,  3.],\n",
      "     |                  [ 0.,  0.,  0.],\n",
      "     |                  [ 7.,  8.,  9.],\n",
      "     |                  [ 0.,  0.,  0.],\n",
      "     |                  [ 4.,  5.,  6.]])\n",
      "     |  \n",
      "     |  index_fill(self, dim, index, value)\n",
      "     |  \n",
      "     |  index_fill_(...)\n",
      "     |      index_fill_(dim, index, val) -> Tensor\n",
      "     |      \n",
      "     |      Fills the elements of the :attr:`self` tensor with value :attr:`val` by\n",
      "     |      selecting the indices in the order given in :attr:`index`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension along which to index\n",
      "     |          index (LongTensor): indices of :attr:`self` tensor to fill in\n",
      "     |          val (float): the value to fill with\n",
      "     |      \n",
      "     |      Example::\n",
      "     |          >>> x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
      "     |          >>> index = torch.tensor([0, 2])\n",
      "     |          >>> x.index_fill_(1, index, -1)\n",
      "     |          tensor([[-1.,  2., -1.],\n",
      "     |                  [-1.,  5., -1.],\n",
      "     |                  [-1.,  8., -1.]])\n",
      "     |  \n",
      "     |  index_put_(...)\n",
      "     |      index_put_(indices, value) -> Tensor\n",
      "     |      \n",
      "     |      Puts values from the tensor :attr:`value` into the tensor :attr:`self` using\n",
      "     |      the indices specified in :attr:`indices` (which is a tuple of Tensors). The\n",
      "     |      expression ``tensor.index_put_(indices, value)`` is equivalent to\n",
      "     |      ``tensor[indices] = value``. Returns :attr:`self`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          indices (tuple of LongTensor): tensors used to index into `self`.\n",
      "     |          value (Tensor): tensor of same dtype as `self`.\n",
      "     |  \n",
      "     |  index_select(...)\n",
      "     |      index_select(dim, index) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.index_select`\n",
      "     |  \n",
      "     |  int(...)\n",
      "     |      int() -> Tensor\n",
      "     |      \n",
      "     |      ``self.int()`` is equivalent to ``self.to(torch.int32)``. See :func:`to`.\n",
      "     |  \n",
      "     |  inverse(...)\n",
      "     |      inverse() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.inverse`\n",
      "     |  \n",
      "     |  irfft(...)\n",
      "     |      irfft(signal_ndim, normalized=False, onesided=True, signal_sizes=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.irfft`\n",
      "     |  \n",
      "     |  is_coalesced(...)\n",
      "     |  \n",
      "     |  is_contiguous(...)\n",
      "     |      is_contiguous() -> bool\n",
      "     |      \n",
      "     |      Returns True if :attr:`self` tensor is contiguous in memory in C order.\n",
      "     |  \n",
      "     |  is_distributed(...)\n",
      "     |  \n",
      "     |  is_floating_point(...)\n",
      "     |  \n",
      "     |  is_nonzero(...)\n",
      "     |  \n",
      "     |  is_pinned(self)\n",
      "     |      Returns true if this tensor resides in pinned memory\n",
      "     |  \n",
      "     |  is_same_size(...)\n",
      "     |  \n",
      "     |  is_set_to(...)\n",
      "     |      is_set_to(tensor) -> bool\n",
      "     |      \n",
      "     |      Returns True if this object refers to the same ``THTensor`` object from the\n",
      "     |      Torch C API as the given tensor.\n",
      "     |  \n",
      "     |  is_shared(self)\n",
      "     |      Checks if tensor is in shared memory.\n",
      "     |      \n",
      "     |      This is always ``True`` for CUDA tensors.\n",
      "     |  \n",
      "     |  is_signed(...)\n",
      "     |  \n",
      "     |  isclose(...)\n",
      "     |  \n",
      "     |  item(...)\n",
      "     |      item() -> number\n",
      "     |      \n",
      "     |      Returns the value of this tensor as a standard Python number. This only works\n",
      "     |      for tensors with one element.\n",
      "     |      \n",
      "     |      This operation is not differentiable.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([1.0])\n",
      "     |          >>> x.item()\n",
      "     |          1.0\n",
      "     |  \n",
      "     |  kthvalue(...)\n",
      "     |      kthvalue(k, dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.kthvalue`\n",
      "     |  \n",
      "     |  le(...)\n",
      "     |      le(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.le`\n",
      "     |  \n",
      "     |  le_(...)\n",
      "     |      le_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.le`\n",
      "     |  \n",
      "     |  lerp(...)\n",
      "     |      lerp(start, end, weight) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lerp`\n",
      "     |  \n",
      "     |  lerp_(...)\n",
      "     |      lerp_(start, end, weight) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lerp`\n",
      "     |  \n",
      "     |  lgamma(...)\n",
      "     |  \n",
      "     |  lgamma_(...)\n",
      "     |  \n",
      "     |  log(...)\n",
      "     |      log() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log`\n",
      "     |  \n",
      "     |  log10(...)\n",
      "     |      log10() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log10`\n",
      "     |  \n",
      "     |  log10_(...)\n",
      "     |      log10_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log10`\n",
      "     |  \n",
      "     |  log1p(...)\n",
      "     |      log1p() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log1p`\n",
      "     |  \n",
      "     |  log1p_(...)\n",
      "     |      log1p_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log1p`\n",
      "     |  \n",
      "     |  log2(...)\n",
      "     |      log2() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log2`\n",
      "     |  \n",
      "     |  log2_(...)\n",
      "     |      log2_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log2`\n",
      "     |  \n",
      "     |  log_(...)\n",
      "     |      log_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log`\n",
      "     |  \n",
      "     |  log_normal_(...)\n",
      "     |      log_normal_(mean=1, std=2, *, generator=None)\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with numbers samples from the log-normal distribution\n",
      "     |      parameterized by the given mean (µ) and standard deviation (σ).\n",
      "     |      Note that :attr:`mean` and :attr:`stdv` are the mean and standard deviation of\n",
      "     |      the underlying normal distribution, and not of the returned distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(x) = \\dfrac{1}{x \\sigma \\sqrt{2\\pi}}\\ e^{-\\dfrac{(\\ln x - \\mu)^2}{2\\sigma^2}}\n",
      "     |  \n",
      "     |  logdet(...)\n",
      "     |      logdet() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logdet`\n",
      "     |  \n",
      "     |  long(...)\n",
      "     |      long() -> Tensor\n",
      "     |      \n",
      "     |      ``self.long()`` is equivalent to ``self.to(torch.int64)``. See :func:`to`.\n",
      "     |  \n",
      "     |  lt(...)\n",
      "     |      lt(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lt`\n",
      "     |  \n",
      "     |  lt_(...)\n",
      "     |      lt_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lt`\n",
      "     |  \n",
      "     |  map2_(...)\n",
      "     |  \n",
      "     |  map_(...)\n",
      "     |      map_(tensor, callable)\n",
      "     |      \n",
      "     |      Applies :attr:`callable` for each element in :attr:`self` tensor and the given\n",
      "     |      :attr:`tensor` and stores the results in :attr:`self` tensor. :attr:`self` tensor and\n",
      "     |      the given :attr:`tensor` must be :ref:`broadcastable <broadcasting-semantics>`.\n",
      "     |      \n",
      "     |      The :attr:`callable` should have the signature::\n",
      "     |      \n",
      "     |          def callable(a, b) -> number\n",
      "     |  \n",
      "     |  masked_copy(self, mask, tensor)\n",
      "     |  \n",
      "     |  masked_copy_(self, mask, tensor)\n",
      "     |  \n",
      "     |  masked_fill(self, mask, value)\n",
      "     |  \n",
      "     |  masked_fill_(...)\n",
      "     |      masked_fill_(mask, value)\n",
      "     |      \n",
      "     |      Fills elements of :attr:`self` tensor with :attr:`value` where :attr:`mask` is\n",
      "     |      one. The shape of :attr:`mask` must be\n",
      "     |      :ref:`broadcastable <broadcasting-semantics>` with the shape of the underlying\n",
      "     |      tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          mask (ByteTensor): the binary mask\n",
      "     |          value (float): the value to fill in with\n",
      "     |  \n",
      "     |  masked_scatter(self, mask, tensor)\n",
      "     |  \n",
      "     |  masked_scatter_(...)\n",
      "     |      masked_scatter_(mask, source)\n",
      "     |      \n",
      "     |      Copies elements from :attr:`source` into :attr:`self` tensor at positions where\n",
      "     |      the :attr:`mask` is one.\n",
      "     |      The shape of :attr:`mask` must be :ref:`broadcastable <broadcasting-semantics>`\n",
      "     |      with the shape of the underlying tensor. The :attr:`source` should have at least\n",
      "     |      as many elements as the number of ones in :attr:`mask`\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          mask (ByteTensor): the binary mask\n",
      "     |          source (Tensor): the tensor to copy from\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The :attr:`mask` operates on the :attr:`self` tensor, not on the given\n",
      "     |          :attr:`source` tensor.\n",
      "     |  \n",
      "     |  masked_select(...)\n",
      "     |      masked_select(mask) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.masked_select`\n",
      "     |  \n",
      "     |  matmul(...)\n",
      "     |      matmul(tensor2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.matmul`\n",
      "     |  \n",
      "     |  max(...)\n",
      "     |      max(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.max`\n",
      "     |  \n",
      "     |  mean(...)\n",
      "     |      mean(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.mean`\n",
      "     |  \n",
      "     |  median(...)\n",
      "     |      median(dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.median`\n",
      "     |  \n",
      "     |  min(...)\n",
      "     |      min(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.min`\n",
      "     |  \n",
      "     |  mm(...)\n",
      "     |      mm(mat2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mm`\n",
      "     |  \n",
      "     |  mode(...)\n",
      "     |      mode(dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.mode`\n",
      "     |  \n",
      "     |  mul(...)\n",
      "     |      mul(value) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mul`\n",
      "     |  \n",
      "     |  mul_(...)\n",
      "     |      mul_(value)\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.mul`\n",
      "     |  \n",
      "     |  multinomial(...)\n",
      "     |      multinomial(num_samples, replacement=False, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.multinomial`\n",
      "     |  \n",
      "     |  mv(...)\n",
      "     |      mv(vec) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mv`\n",
      "     |  \n",
      "     |  narrow(...)\n",
      "     |      narrow(dimension, start, length) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new tensor that is a narrowed version of :attr:`self` tensor. The\n",
      "     |      dimension :attr:`dim` is narrowed from :attr:`start` to :attr:`start + length`. The\n",
      "     |      returned tensor and :attr:`self` tensor share the same underlying storage.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dimension (int): the dimension along which to narrow\n",
      "     |          start (int): the starting dimension\n",
      "     |          length (int): the distance to the ending dimension\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
      "     |          >>> x.narrow(0, 0, 2)\n",
      "     |          tensor([[ 1,  2,  3],\n",
      "     |                  [ 4,  5,  6]])\n",
      "     |          >>> x.narrow(1, 1, 2)\n",
      "     |          tensor([[ 2,  3],\n",
      "     |                  [ 5,  6],\n",
      "     |                  [ 8,  9]])\n",
      "     |  \n",
      "     |  ndimension(...)\n",
      "     |      ndimension() -> int\n",
      "     |      \n",
      "     |      Alias for :meth:`~Tensor.dim()`\n",
      "     |  \n",
      "     |  ne(...)\n",
      "     |      ne(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ne`\n",
      "     |  \n",
      "     |  ne_(...)\n",
      "     |      ne_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ne`\n",
      "     |  \n",
      "     |  neg(...)\n",
      "     |      neg() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.neg`\n",
      "     |  \n",
      "     |  neg_(...)\n",
      "     |      neg_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.neg`\n",
      "     |  \n",
      "     |  nelement(...)\n",
      "     |      nelement() -> int\n",
      "     |      \n",
      "     |      Alias for :meth:`~Tensor.numel`\n",
      "     |  \n",
      "     |  new(...)\n",
      "     |  \n",
      "     |  new_empty(...)\n",
      "     |      new_empty(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with uninitialized data.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones(())\n",
      "     |          >>> tensor.new_empty((2, 3))\n",
      "     |          tensor([[ 5.8182e-18,  4.5765e-41, -1.0545e+30],\n",
      "     |                  [ 3.0949e-41,  4.4842e-44,  0.0000e+00]])\n",
      "     |  \n",
      "     |  new_full(...)\n",
      "     |      new_full(size, fill_value, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with :attr:`fill_value`.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          fill_value (scalar): the number to fill the output tensor with.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones((2,), dtype=torch.float64)\n",
      "     |          >>> tensor.new_full((3, 4), 3.141592)\n",
      "     |          tensor([[ 3.1416,  3.1416,  3.1416,  3.1416],\n",
      "     |                  [ 3.1416,  3.1416,  3.1416,  3.1416],\n",
      "     |                  [ 3.1416,  3.1416,  3.1416,  3.1416]], dtype=torch.float64)\n",
      "     |  \n",
      "     |  new_ones(...)\n",
      "     |      new_ones(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with ``1``.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (int...): a list, tuple, or :class:`torch.Size` of integers defining the\n",
      "     |              shape of the output tensor.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.tensor((), dtype=torch.int32)\n",
      "     |          >>> tensor.new_ones((2, 3))\n",
      "     |          tensor([[ 1,  1,  1],\n",
      "     |                  [ 1,  1,  1]], dtype=torch.int32)\n",
      "     |  \n",
      "     |  new_tensor(...)\n",
      "     |      new_tensor(data, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new Tensor with :attr:`data` as the tensor data.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          :func:`new_tensor` always copies :attr:`data`. If you have a Tensor\n",
      "     |          ``data`` and want to avoid a copy, use :func:`torch.Tensor.requires_grad_`\n",
      "     |          or :func:`torch.Tensor.detach`.\n",
      "     |          If you have a numpy array and want to avoid a copy, use\n",
      "     |          :func:`torch.from_numpy`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          data (array_like): The returned Tensor copies :attr:`data`.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones((2,), dtype=torch.int8)\n",
      "     |          >>> data = [[0, 1], [2, 3]]\n",
      "     |          >>> tensor.new_tensor(data)\n",
      "     |          tensor([[ 0,  1],\n",
      "     |                  [ 2,  3]], dtype=torch.int8)\n",
      "     |  \n",
      "     |  new_zeros(...)\n",
      "     |      new_zeros(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with ``0``.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (int...): a list, tuple, or :class:`torch.Size` of integers defining the\n",
      "     |              shape of the output tensor.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.tensor((), dtype=torch.float64)\n",
      "     |          >>> tensor.new_ones((2, 3))\n",
      "     |          tensor([[ 1.,  1.,  1.],\n",
      "     |                  [ 1.,  1.,  1.]], dtype=torch.float64)\n",
      "     |  \n",
      "     |  nonzero(...)\n",
      "     |      nonzero() -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.nonzero`\n",
      "     |  \n",
      "     |  norm(...)\n",
      "     |      norm(p=2, dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.norm`\n",
      "     |  \n",
      "     |  normal_(...)\n",
      "     |      normal_(mean=0, std=1, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with elements samples from the normal distribution\n",
      "     |      parameterized by :attr:`mean` and :attr:`std`.\n",
      "     |  \n",
      "     |  numel(...)\n",
      "     |      numel() -> int\n",
      "     |      \n",
      "     |      See :func:`torch.numel`\n",
      "     |  \n",
      "     |  numpy(...)\n",
      "     |      numpy() -> numpy.ndarray\n",
      "     |      \n",
      "     |      Returns :attr:`self` tensor as a NumPy :class:`ndarray`. This tensor and the\n",
      "     |      returned :class:`ndarray` share the same underlying storage. Changes to\n",
      "     |      :attr:`self` tensor will be reflected in the :class:`ndarray` and vice versa.\n",
      "     |  \n",
      "     |  orgqr(...)\n",
      "     |      orgqr(input2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.orgqr`\n",
      "     |  \n",
      "     |  ormqr(...)\n",
      "     |      ormqr(input2, input3, left=True, transpose=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ormqr`\n",
      "     |  \n",
      "     |  permute(...)\n",
      "     |  \n",
      "     |  pin_memory(...)\n",
      "     |  \n",
      "     |  polygamma(...)\n",
      "     |  \n",
      "     |  polygamma_(...)\n",
      "     |  \n",
      "     |  potrf(...)\n",
      "     |      potrf(upper=True) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.potrf`\n",
      "     |  \n",
      "     |  potri(...)\n",
      "     |      potri(upper=True) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.potri`\n",
      "     |  \n",
      "     |  potrs(...)\n",
      "     |      potrs(input2, upper=True) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.potrs`\n",
      "     |  \n",
      "     |  pow(...)\n",
      "     |      pow(exponent) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.pow`\n",
      "     |  \n",
      "     |  pow_(...)\n",
      "     |      pow_(exponent) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.pow`\n",
      "     |  \n",
      "     |  prod(...)\n",
      "     |      prod(dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.prod`\n",
      "     |  \n",
      "     |  pstrf(...)\n",
      "     |      pstrf(upper=True, tol=-1) -> (Tensor, IntTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.pstrf`\n",
      "     |  \n",
      "     |  put_(...)\n",
      "     |      put_(indices, tensor, accumulate=False) -> Tensor\n",
      "     |      \n",
      "     |      Copies the elements from :attr:`tensor` into the positions specified by\n",
      "     |      indices. For the purpose of indexing, the :attr:`self` tensor is treated as if\n",
      "     |      it were a 1-D tensor.\n",
      "     |      \n",
      "     |      If :attr:`accumulate` is ``True``, the elements in :attr:`tensor` are added to\n",
      "     |      :attr:`self`. If accumulate is ``False``, the behavior is undefined if indices\n",
      "     |      contain duplicate elements.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          indices (LongTensor): the indices into self\n",
      "     |          tensor (Tensor): the tensor containing values to copy from\n",
      "     |          accumulate (bool): whether to accumulate into self\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> src = torch.tensor([[4, 3, 5],\n",
      "     |                                  [6, 7, 8]])\n",
      "     |          >>> src.put_(torch.tensor([1, 3]), torch.tensor([9, 10]))\n",
      "     |          tensor([[  4,   9,   5],\n",
      "     |                  [ 10,   7,   8]])\n",
      "     |  \n",
      "     |  qr(...)\n",
      "     |      qr() -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.qr`\n",
      "     |  \n",
      "     |  random_(...)\n",
      "     |      random_(from=0, to=None, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with numbers sampled from the discrete uniform\n",
      "     |      distribution over ``[from, to - 1]``. If not specified, the values are usually\n",
      "     |      only bounded by :attr:`self` tensor's data type. However, for floating point\n",
      "     |      types, if unspecified, range will be ``[0, 2^mantissa]`` to ensure that every\n",
      "     |      value is representable. For example, `torch.tensor(1, dtype=torch.double).random_()`\n",
      "     |      will be uniform in ``[0, 2^53]``.\n",
      "     |  \n",
      "     |  reciprocal(...)\n",
      "     |      reciprocal() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.reciprocal`\n",
      "     |  \n",
      "     |  reciprocal_(...)\n",
      "     |      reciprocal_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.reciprocal`\n",
      "     |  \n",
      "     |  record_stream(...)\n",
      "     |  \n",
      "     |  register_hook(self, hook)\n",
      "     |      Registers a backward hook.\n",
      "     |      \n",
      "     |      The hook will be called every time a gradient with respect to the\n",
      "     |      Tensor is computed. The hook should have the following signature::\n",
      "     |      \n",
      "     |          hook(grad) -> Tensor or None\n",
      "     |      \n",
      "     |      The hook should not modify its argument, but it can optionally return\n",
      "     |      a new gradient which will be used in place of :attr:`grad`.\n",
      "     |      \n",
      "     |      This function returns a handle with a method ``handle.remove()``\n",
      "     |      that removes the hook from the module.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          >>> v = torch.tensor([0., 0., 0.], requires_grad=True)\n",
      "     |          >>> h = v.register_hook(lambda grad: grad * 2)  # double the gradient\n",
      "     |          >>> v.backward(torch.tensor([1., 2., 3.]))\n",
      "     |          >>> v.grad\n",
      "     |      \n",
      "     |           2\n",
      "     |           4\n",
      "     |           6\n",
      "     |          [torch.FloatTensor of size (3,)]\n",
      "     |      \n",
      "     |          >>> h.remove()  # removes the hook\n",
      "     |  \n",
      "     |  reinforce(self, reward)\n",
      "     |  \n",
      "     |  relu(...)\n",
      "     |  \n",
      "     |  relu_(...)\n",
      "     |  \n",
      "     |  remainder(...)\n",
      "     |      remainder(divisor) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.remainder`\n",
      "     |  \n",
      "     |  remainder_(...)\n",
      "     |      remainder_(divisor) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.remainder`\n",
      "     |  \n",
      "     |  renorm(...)\n",
      "     |      renorm(p, dim, maxnorm) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.renorm`\n",
      "     |  \n",
      "     |  renorm_(...)\n",
      "     |      renorm_(p, dim, maxnorm) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.renorm`\n",
      "     |  \n",
      "     |  repeat(...)\n",
      "     |      repeat(*sizes) -> Tensor\n",
      "     |      \n",
      "     |      Repeats this tensor along the specified dimensions.\n",
      "     |      \n",
      "     |      Unlike :meth:`~Tensor.expand`, this function copies the tensor's data.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          sizes (torch.Size or int...): The number of times to repeat this tensor along each\n",
      "     |              dimension\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([1, 2, 3])\n",
      "     |          >>> x.repeat(4, 2)\n",
      "     |          tensor([[ 1,  2,  3,  1,  2,  3],\n",
      "     |                  [ 1,  2,  3,  1,  2,  3],\n",
      "     |                  [ 1,  2,  3,  1,  2,  3],\n",
      "     |                  [ 1,  2,  3,  1,  2,  3]])\n",
      "     |          >>> x.repeat(4, 2, 1).size()\n",
      "     |          torch.Size([4, 2, 3])\n",
      "     |  \n",
      "     |  requires_grad_(...)\n",
      "     |      requires_grad_(requires_grad=True) -> Tensor\n",
      "     |      \n",
      "     |      Change if autograd should record operations on this tensor: sets this tensor's\n",
      "     |      :attr:`requires_grad` attribute in-place. Returns this tensor.\n",
      "     |      \n",
      "     |      :func:`require_grad_`'s main use case is to tell autograd to begin recording\n",
      "     |      operations on a Tensor ``tensor``. If ``tensor`` has ``requires_grad=False``\n",
      "     |      (because it was obtained through a DataLoader, or required preprocessing or\n",
      "     |      initialization), ``tensor.requires_grad_()`` makes it so that autograd will\n",
      "     |      begin to record operations on ``tensor``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          requires_grad (bool): If autograd should record operations on this tensor.\n",
      "     |              Default: ``True``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> # Let's say we want to preprocess some saved weights and use\n",
      "     |          >>> # the result as new weights.\n",
      "     |          >>> saved_weights = [0.1, 0.2, 0.3, 0.25]\n",
      "     |          >>> loaded_weights = torch.tensor(saved_weights)\n",
      "     |          >>> weights = preprocess(loaded_weights)  # some function\n",
      "     |          >>> weights\n",
      "     |          tensor([-0.5503,  0.4926, -2.1158, -0.8303])\n",
      "     |      \n",
      "     |          >>> # Now, start to record operations done to weights\n",
      "     |          >>> weights.requires_grad_()\n",
      "     |          >>> out = weights.pow(2).sum()\n",
      "     |          >>> out.backward()\n",
      "     |          >>> weights.grad\n",
      "     |          tensor([-1.1007,  0.9853, -4.2316, -1.6606])\n",
      "     |  \n",
      "     |  reshape(...)\n",
      "     |      reshape(*shape) -> Tensor\n",
      "     |      \n",
      "     |      Returns a tensor with the same data and number of elements as :attr:`self`,\n",
      "     |      but with the specified shape.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          shape (tuple of ints or int...): the desired shape\n",
      "     |      \n",
      "     |      See :func:`torch.reshape`\n",
      "     |  \n",
      "     |  resize(self, *sizes)\n",
      "     |  \n",
      "     |  resize_(...)\n",
      "     |      resize_(*sizes) -> Tensor\n",
      "     |      \n",
      "     |      Resizes :attr:`self` tensor to the specified size. If the number of elements is\n",
      "     |      larger than the current storage size, then the underlying storage is resized\n",
      "     |      to fit the new number of elements. If the number of elements is smaller, the\n",
      "     |      underlying storage is not changed. Existing elements are preserved but any new\n",
      "     |      memory is uninitialized.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          sizes (torch.Size or int...): the desired size\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1, 2], [3, 4], [5, 6]])\n",
      "     |          >>> x.resize_(2, 2)\n",
      "     |          tensor([[ 1,  2],\n",
      "     |                  [ 3,  4]])\n",
      "     |  \n",
      "     |  resize_as(self, tensor)\n",
      "     |  \n",
      "     |  resize_as_(...)\n",
      "     |      resize_as_(tensor) -> Tensor\n",
      "     |      \n",
      "     |      Resizes the :attr:`self` tensor to be the same size as the specified\n",
      "     |      :attr:`tensor`. This is equivalent to ``self.resize_(tensor.size())``.\n",
      "     |  \n",
      "     |  retain_grad(self)\n",
      "     |      Enables .grad attribute for non-leaf Tensors.\n",
      "     |  \n",
      "     |  rfft(...)\n",
      "     |      rfft(signal_ndim, normalized=False, onesided=True) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.rfft`\n",
      "     |  \n",
      "     |  round(...)\n",
      "     |      round() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.round`\n",
      "     |  \n",
      "     |  round_(...)\n",
      "     |      round_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.round`\n",
      "     |  \n",
      "     |  rsqrt(...)\n",
      "     |      rsqrt() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.rsqrt`\n",
      "     |  \n",
      "     |  rsqrt_(...)\n",
      "     |      rsqrt_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.rsqrt`\n",
      "     |  \n",
      "     |  scatter(self, dim, index, source)\n",
      "     |  \n",
      "     |  scatter_(...)\n",
      "     |      scatter_(dim, index, src) -> Tensor\n",
      "     |      \n",
      "     |      Writes all values from the tensor :attr:`src` into :attr:`self` at the indices\n",
      "     |      specified in the :attr:`index` tensor. For each value in :attr:`src`, its output\n",
      "     |      index is specified by its index in :attr:`src` for dimension != :attr:`dim` and\n",
      "     |      by the corresponding value in :attr:`index` for dimension = :attr:`dim`.\n",
      "     |      \n",
      "     |      For a 3-D tensor, :attr:`self` is updated as::\n",
      "     |      \n",
      "     |          self[index[i][j][k]][j][k] = src[i][j][k]  # if dim == 0\n",
      "     |          self[i][index[i][j][k]][k] = src[i][j][k]  # if dim == 1\n",
      "     |          self[i][j][index[i][j][k]] = src[i][j][k]  # if dim == 2\n",
      "     |      \n",
      "     |      This is the reverse operation of the manner described in :meth:`~Tensor.gather`.\n",
      "     |      \n",
      "     |      :attr:`self`, :attr:`index` and :attr:`src` should have same number of\n",
      "     |      dimensions. It is also required that `index->size[d] <= src->size[d]` for all\n",
      "     |      dimension `d`, and that `index->size[d] <= real->size[d]` for all dimensions\n",
      "     |      `d != dim`.\n",
      "     |      \n",
      "     |      Moreover, as for :meth:`~Tensor.gather`, the values of :attr:`index` must be\n",
      "     |      between `0` and `(self.size(dim) -1)` inclusive, and all values in a row along\n",
      "     |      the specified dimension :attr:`dim` must be unique.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          input (Tensor): the source tensor\n",
      "     |          dim (int): the axis along which to index\n",
      "     |          index (LongTensor): the indices of elements to scatter\n",
      "     |          src (Tensor or float): the source element(s) to scatter\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.rand(2, 5)\n",
      "     |          >>> x\n",
      "     |          tensor([[ 0.3992,  0.2908,  0.9044,  0.4850,  0.6004],\n",
      "     |                  [ 0.5735,  0.9006,  0.6797,  0.4152,  0.1732]])\n",
      "     |          >>> torch.zeros(3, 5).scatter_(0, torch.tensor([[0, 1, 2, 0, 0], [2, 0, 0, 1, 2]]), x)\n",
      "     |          tensor([[ 0.3992,  0.9006,  0.6797,  0.4850,  0.6004],\n",
      "     |                  [ 0.0000,  0.2908,  0.0000,  0.4152,  0.0000],\n",
      "     |                  [ 0.5735,  0.0000,  0.9044,  0.0000,  0.1732]])\n",
      "     |      \n",
      "     |          >>> z = torch.zeros(2, 4).scatter_(1, torch.tensor([[2], [3]]), 1.23)\n",
      "     |          >>> z\n",
      "     |          tensor([[ 0.0000,  0.0000,  1.2300,  0.0000],\n",
      "     |                  [ 0.0000,  0.0000,  0.0000,  1.2300]])\n",
      "     |  \n",
      "     |  scatter_add(self, dim, index, source)\n",
      "     |  \n",
      "     |  scatter_add_(...)\n",
      "     |  \n",
      "     |  select(...)\n",
      "     |      select(dim, index) -> Tensor\n",
      "     |      \n",
      "     |      Slices the :attr:`self` tensor along the selected dimension at the given index.\n",
      "     |      This function returns a tensor with the given dimension removed.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the dimension to slice\n",
      "     |          index (int): the index to select with\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          :meth:`select` is equivalent to slicing. For example,\n",
      "     |          ``tensor.select(0, index)`` is equivalent to ``tensor[index]`` and\n",
      "     |          ``tensor.select(2, index)`` is equivalent to ``tensor[:,:,index]``.\n",
      "     |  \n",
      "     |  set_(...)\n",
      "     |      set_(source=None, storage_offset=0, size=None, stride=None) -> Tensor\n",
      "     |      \n",
      "     |      Sets the underlying storage, size, and strides. If :attr:`source` is a tensor,\n",
      "     |      :attr:`self` tensor will share the same storage and have the same size and\n",
      "     |      strides as :attr:`source`. Changes to elements in one tensor will be reflected\n",
      "     |      in the other.\n",
      "     |      \n",
      "     |      If :attr:`source` is a :class:`~torch.Storage`, the method sets the underlying\n",
      "     |      storage, offset, size, and stride.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          source (Tensor or Storage): the tensor or storage to use\n",
      "     |          storage_offset (int, optional): the offset in the storage\n",
      "     |          size (torch.Size, optional): the desired size. Defaults to the size of the source.\n",
      "     |          stride (tuple, optional): the desired stride. Defaults to C-contiguous strides.\n",
      "     |  \n",
      "     |  share_memory_(self)\n",
      "     |      Moves the underlying storage to shared memory.\n",
      "     |      \n",
      "     |      This is a no-op if the underlying storage is already in shared memory\n",
      "     |      and for CUDA tensors. Tensors in shared memory cannot be resized.\n",
      "     |  \n",
      "     |  short(...)\n",
      "     |      short() -> Tensor\n",
      "     |      \n",
      "     |      ``self.short()`` is equivalent to ``self.to(torch.int16)``. See :func:`to`.\n",
      "     |  \n",
      "     |  sigmoid(...)\n",
      "     |      sigmoid() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sigmoid`\n",
      "     |  \n",
      "     |  sigmoid_(...)\n",
      "     |      sigmoid_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sigmoid`\n",
      "     |  \n",
      "     |  sign(...)\n",
      "     |      sign() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sign`\n",
      "     |  \n",
      "     |  sign_(...)\n",
      "     |      sign_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sign`\n",
      "     |  \n",
      "     |  sin(...)\n",
      "     |      sin() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sin`\n",
      "     |  \n",
      "     |  sin_(...)\n",
      "     |      sin_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sin`\n",
      "     |  \n",
      "     |  sinh(...)\n",
      "     |      sinh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sinh`\n",
      "     |  \n",
      "     |  sinh_(...)\n",
      "     |      sinh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sinh`\n",
      "     |  \n",
      "     |  size(...)\n",
      "     |      size() -> torch.Size\n",
      "     |      \n",
      "     |      Returns the size of the :attr:`self` tensor. The returned value is a subclass of\n",
      "     |      :class:`tuple`.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> torch.empty(3, 4, 5).size()\n",
      "     |          torch.Size([3, 4, 5])\n",
      "     |  \n",
      "     |  slice(...)\n",
      "     |  \n",
      "     |  slogdet(...)\n",
      "     |      slogdet() -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.slogdet`\n",
      "     |  \n",
      "     |  smm(...)\n",
      "     |  \n",
      "     |  sort(...)\n",
      "     |      sort(dim=None, descending=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.sort`\n",
      "     |  \n",
      "     |  split(self, split_size, dim=0)\n",
      "     |      See :func:`torch.split`\n",
      "     |  \n",
      "     |  split_with_sizes(...)\n",
      "     |  \n",
      "     |  sqrt(...)\n",
      "     |      sqrt() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sqrt`\n",
      "     |  \n",
      "     |  sqrt_(...)\n",
      "     |      sqrt_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sqrt`\n",
      "     |  \n",
      "     |  squeeze(...)\n",
      "     |      squeeze(dim=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.squeeze`\n",
      "     |  \n",
      "     |  squeeze_(...)\n",
      "     |      squeeze_(dim=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.squeeze`\n",
      "     |  \n",
      "     |  sspaddmm(...)\n",
      "     |  \n",
      "     |  std(...)\n",
      "     |      std(dim=None, unbiased=True, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.std`\n",
      "     |  \n",
      "     |  stft(...)\n",
      "     |      stft(frame_length, hop, fft_size=None, return_onesided=True, window=None, pad_end=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.stft`\n",
      "     |  \n",
      "     |  storage(...)\n",
      "     |      storage() -> torch.Storage\n",
      "     |      \n",
      "     |      Returns the underlying storage\n",
      "     |  \n",
      "     |  storage_offset(...)\n",
      "     |      storage_offset() -> int\n",
      "     |      \n",
      "     |      Returns :attr:`self` tensor's offset in the underlying storage in terms of\n",
      "     |      number of storage elements (not bytes).\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([1, 2, 3, 4, 5])\n",
      "     |          >>> x.storage_offset()\n",
      "     |          0\n",
      "     |          >>> x[3:].storage_offset()\n",
      "     |          3\n",
      "     |  \n",
      "     |  storage_type(...)\n",
      "     |  \n",
      "     |  stride(...)\n",
      "     |      stride(dim) -> tuple or int\n",
      "     |      \n",
      "     |      Returns the stride of :attr:`self` tensor.\n",
      "     |      \n",
      "     |      Stride is the jump necessary to go from one element to the next one in the\n",
      "     |      specified dimension :attr:`dim`. A tuple of all strides is returned when no\n",
      "     |      argument is passed in. Otherwise, an integer value is returned as the stride in\n",
      "     |      the particular dimension :attr:`dim`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int, optional): the desired dimension in which stride is required\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1, 2, 3, 4, 5], [6, 7, 8, 9, 10]])\n",
      "     |          >>> x.stride()\n",
      "     |          (5, 1)\n",
      "     |          >>>x.stride(0)\n",
      "     |          5\n",
      "     |          >>> x.stride(-1)\n",
      "     |          1\n",
      "     |  \n",
      "     |  sub(...)\n",
      "     |      sub(value, other) -> Tensor\n",
      "     |      \n",
      "     |      Subtracts a scalar or tensor from :attr:`self` tensor. If both :attr:`value` and\n",
      "     |      :attr:`other` are specified, each element of :attr:`other` is scaled by\n",
      "     |      :attr:`value` before being used.\n",
      "     |      \n",
      "     |      When :attr:`other` is a tensor, the shape of :attr:`other` must be\n",
      "     |      :ref:`broadcastable <broadcasting-semantics>` with the shape of the underlying\n",
      "     |      tensor.\n",
      "     |  \n",
      "     |  sub_(...)\n",
      "     |      sub_(x) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sub`\n",
      "     |  \n",
      "     |  sum(...)\n",
      "     |      sum(dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sum`\n",
      "     |  \n",
      "     |  svd(...)\n",
      "     |      svd(some=True) -> (Tensor, Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.svd`\n",
      "     |  \n",
      "     |  symeig(...)\n",
      "     |      symeig(eigenvectors=False, upper=True) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.symeig`\n",
      "     |  \n",
      "     |  t(...)\n",
      "     |      t() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.t`\n",
      "     |  \n",
      "     |  t_(...)\n",
      "     |      t_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.t`\n",
      "     |  \n",
      "     |  take(...)\n",
      "     |      take(indices) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.take`\n",
      "     |  \n",
      "     |  tan(...)\n",
      "     |  \n",
      "     |  tan_(...)\n",
      "     |      tan_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.tan`\n",
      "     |  \n",
      "     |  tanh(...)\n",
      "     |      tanh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tanh`\n",
      "     |  \n",
      "     |  tanh_(...)\n",
      "     |      tanh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.tanh`\n",
      "     |  \n",
      "     |  to(...)\n",
      "     |      to(*args, **kwargs) -> Tensor\n",
      "     |      \n",
      "     |      Performs Tensor dtype and/or device conversion. A :class:`torch.dtype` and :class:`torch.device` are\n",
      "     |      inferred from the arguments of ``self.to(*args, **kwargs)``.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          If the ``self`` Tensor already\n",
      "     |          has the correct :class:`torch.dtype` and :class:`torch.device`, then ``self`` is returned.\n",
      "     |          Otherwise, the returned tensor is a copy of ``self`` with the desired\n",
      "     |          :class:`torch.dtype` and :class:`torch.device`.\n",
      "     |      \n",
      "     |      Here are the ways to call ``to``:\n",
      "     |      \n",
      "     |      .. function:: to(dtype) -> Tensor\n",
      "     |      \n",
      "     |          Returns a Tensor with the specified :attr:`dtype`\n",
      "     |      \n",
      "     |      .. function:: to(device, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |          Returns a Tensor with the specified :attr:`device` and (optional)\n",
      "     |          :attr:`dtype`. If :attr:`dtype` is ``None`` it is inferred to be ``self.dtype``.\n",
      "     |      \n",
      "     |      .. function:: to(other) -> Tensor\n",
      "     |      \n",
      "     |          Returns a Tensor with same :class:`torch.dtype` and :class:`torch.device` as the Tensor\n",
      "     |          :attr:`other`.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.randn(2, 2)  # Initially dtype=float32, device=cpu\n",
      "     |          >>> tensor.to(torch.float64)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], dtype=torch.float64)\n",
      "     |      \n",
      "     |          >>> cuda0 = torch.device('cuda:0')\n",
      "     |          >>> tensor.to(cuda0)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], device='cuda:0')\n",
      "     |      \n",
      "     |          >>> tensor.to(cuda0, dtype=torch.float64)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], dtype=torch.float64, device='cuda:0')\n",
      "     |      \n",
      "     |          >>> other = torch.randn((), dtype=torch.float64, device=cuda0)\n",
      "     |          >>> tensor.to(other)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], dtype=torch.float64, device='cuda:0')\n",
      "     |  \n",
      "     |  to_dense(...)\n",
      "     |  \n",
      "     |  tolist(...)\n",
      "     |  \n",
      "     |  topk(...)\n",
      "     |      topk(k, dim=None, largest=True, sorted=True) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.topk`\n",
      "     |  \n",
      "     |  trace(...)\n",
      "     |      trace() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.trace`\n",
      "     |  \n",
      "     |  transpose(...)\n",
      "     |      transpose(dim0, dim1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.transpose`\n",
      "     |  \n",
      "     |  transpose_(...)\n",
      "     |      transpose_(dim0, dim1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.transpose`\n",
      "     |  \n",
      "     |  tril(...)\n",
      "     |      tril(k=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tril`\n",
      "     |  \n",
      "     |  tril_(...)\n",
      "     |      tril_(k=0) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.tril`\n",
      "     |  \n",
      "     |  triu(...)\n",
      "     |      triu(k=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.triu`\n",
      "     |  \n",
      "     |  triu_(...)\n",
      "     |      triu_(k=0) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.triu`\n",
      "     |  \n",
      "     |  trtrs(...)\n",
      "     |      trtrs(A, upper=True, transpose=False, unitriangular=False) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.trtrs`\n",
      "     |  \n",
      "     |  trunc(...)\n",
      "     |      trunc() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.trunc`\n",
      "     |  \n",
      "     |  trunc_(...)\n",
      "     |      trunc_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.trunc`\n",
      "     |  \n",
      "     |  type(...)\n",
      "     |      type(dtype=None, non_blocking=False, **kwargs) -> str or Tensor\n",
      "     |      Returns the type if `dtype` is not provided, else casts this object to\n",
      "     |      the specified type.\n",
      "     |      \n",
      "     |      If this is already of the correct type, no copy is performed and the\n",
      "     |      original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (type or string): The desired type\n",
      "     |          non_blocking (bool): If ``True``, and the source is in pinned memory\n",
      "     |              and destination is on the GPU or vice versa, the copy is performed\n",
      "     |              asynchronously with respect to the host. Otherwise, the argument\n",
      "     |              has no effect.\n",
      "     |          **kwargs: For compatibility, may contain the key ``async`` in place of\n",
      "     |              the ``non_blocking`` argument. The ``async`` arg is deprecated.\n",
      "     |  \n",
      "     |  type_as(...)\n",
      "     |      type_as(tensor) -> Tensor\n",
      "     |      \n",
      "     |      Returns this tensor cast to the type of the given tensor.\n",
      "     |      \n",
      "     |      This is a no-op if the tensor is already of the correct type. This is\n",
      "     |      equivalent to::\n",
      "     |      \n",
      "     |          self.type(tensor.type())\n",
      "     |      \n",
      "     |      Params:\n",
      "     |          tensor (Tensor): the tensor which has the desired type\n",
      "     |  \n",
      "     |  unfold(...)\n",
      "     |      unfold(dim, size, step) -> Tensor\n",
      "     |      \n",
      "     |      Returns a tensor which contains all slices of size :attr:`size` from\n",
      "     |      :attr:`self` tensor in the dimension :attr:`dim`.\n",
      "     |      \n",
      "     |      Step between two slices is given by :attr:`step`.\n",
      "     |      \n",
      "     |      If `sizedim` is the size of dimension dim for :attr:`self`, the size of\n",
      "     |      dimension :attr:`dim` in the returned tensor will be\n",
      "     |      `(sizedim - size) / step + 1`.\n",
      "     |      \n",
      "     |      An additional dimension of size size is appended in the returned tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension in which unfolding happens\n",
      "     |          size (int): the size of each slice that is unfolded\n",
      "     |          step (int): the step between each slice\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.arange(1, 8)\n",
      "     |          >>> x\n",
      "     |          tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.])\n",
      "     |          >>> x.unfold(0, 2, 1)\n",
      "     |          tensor([[ 1.,  2.],\n",
      "     |                  [ 2.,  3.],\n",
      "     |                  [ 3.,  4.],\n",
      "     |                  [ 4.,  5.],\n",
      "     |                  [ 5.,  6.],\n",
      "     |                  [ 6.,  7.]])\n",
      "     |          >>> x.unfold(0, 2, 2)\n",
      "     |          tensor([[ 1.,  2.],\n",
      "     |                  [ 3.,  4.],\n",
      "     |                  [ 5.,  6.]])\n",
      "     |  \n",
      "     |  uniform_(...)\n",
      "     |      uniform_(from=0, to=1) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with numbers sampled from the continuous uniform\n",
      "     |      distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |          P(x) = \\dfrac{1}{\\text{to} - \\text{from}}\n",
      "     |  \n",
      "     |  unique(self, sorted=False, return_inverse=False)\n",
      "     |      Returns the unique scalar elements of the tensor as a 1-D tensor.\n",
      "     |      \n",
      "     |      See :func:`torch.unique`\n",
      "     |  \n",
      "     |  unsqueeze(...)\n",
      "     |      unsqueeze(dim) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.unsqueeze`\n",
      "     |  \n",
      "     |  unsqueeze_(...)\n",
      "     |      unsqueeze_(dim) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.unsqueeze`\n",
      "     |  \n",
      "     |  var(...)\n",
      "     |      var(dim=None, unbiased=True, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.var`\n",
      "     |  \n",
      "     |  view(...)\n",
      "     |      view(*args) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new tensor with the same data as the :attr:`self` tensor but of a\n",
      "     |      different size.\n",
      "     |      \n",
      "     |      The returned tensor shares the same data and must have the same number\n",
      "     |      of elements, but may have a different size. For a tensor to be viewed, the new\n",
      "     |      view size must be compatible with its original size and stride, i.e., each new\n",
      "     |      view dimension must either be a subspace of an original dimension, or only span\n",
      "     |      across original dimensions :math:`d, d+1, \\dots, d+k` that satisfy the following\n",
      "     |      contiguity-like condition that :math:`\\forall i = 0, \\dots, k-1`,\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |        stride[i] = stride[i+1] \\times size[i+1]\n",
      "     |      \n",
      "     |      Otherwise, :func:`contiguous` needs to be called before the tensor can be\n",
      "     |      viewed.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          args (torch.Size or int...): the desired size\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.randn(4, 4)\n",
      "     |          >>> x.size()\n",
      "     |          torch.Size([4, 4])\n",
      "     |          >>> y = x.view(16)\n",
      "     |          >>> y.size()\n",
      "     |          torch.Size([16])\n",
      "     |          >>> z = x.view(-1, 8)  # the size -1 is inferred from other dimensions\n",
      "     |          >>> z.size()\n",
      "     |          torch.Size([2, 8])\n",
      "     |  \n",
      "     |  view_as(self, tensor)\n",
      "     |      view_as(other) -> Tensor\n",
      "     |      \n",
      "     |      View this tensor as the same size as :attr:`other`.\n",
      "     |      ``self.view_as(other)`` is equivalent to ``self.view(other.size())``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          other (:class:`torch.Tensor`): The result tensor has the same size\n",
      "     |              as :attr:`other.size()`.\n",
      "     |  \n",
      "     |  where(...)\n",
      "     |      where(condition, y) -> Tensor\n",
      "     |      \n",
      "     |      ``self.where(condition, y)`` is equivalent to ``torch.where(condition, self, y)``.\n",
      "     |      See :func:`torch.where`\n",
      "     |  \n",
      "     |  zero_(...)\n",
      "     |      zero_() -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with zeros.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  data\n",
      "     |  \n",
      "     |  device\n",
      "     |  \n",
      "     |  grad\n",
      "     |  \n",
      "     |  grad_fn\n",
      "     |  \n",
      "     |  is_leaf\n",
      "     |  \n",
      "     |  name\n",
      "     |  \n",
      "     |  output_nr\n",
      "     |  \n",
      "     |  requires_grad\n",
      "     |  \n",
      "     |  shape\n",
      "     |  \n",
      "     |  volatile\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  dtype = torch.uint8\n",
      "     |  \n",
      "     |  is_cuda = False\n",
      "     |  \n",
      "     |  is_sparse = False\n",
      "     |  \n",
      "     |  layout = torch.strided\n",
      "    \n",
      "    class CharStorage(torch._C.CharStorageBase, torch.storage._StorageBase)\n",
      "     |  Method resolution order:\n",
      "     |      CharStorage\n",
      "     |      torch._C.CharStorageBase\n",
      "     |      torch.storage._StorageBase\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch._C.CharStorageBase:\n",
      "     |  \n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |  \n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |  \n",
      "     |  __len__(self, /)\n",
      "     |      Return len(self).\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  __setitem__(self, key, value, /)\n",
      "     |      Set self[key] to value.\n",
      "     |  \n",
      "     |  copy_(...)\n",
      "     |  \n",
      "     |  data_ptr(...)\n",
      "     |  \n",
      "     |  element_size(...)\n",
      "     |  \n",
      "     |  fill_(...)\n",
      "     |  \n",
      "     |  is_pinned(...)\n",
      "     |  \n",
      "     |  is_shared(...)\n",
      "     |  \n",
      "     |  new(...)\n",
      "     |  \n",
      "     |  resize_(...)\n",
      "     |  \n",
      "     |  size(...)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from torch._C.CharStorageBase:\n",
      "     |  \n",
      "     |  from_buffer(...)\n",
      "     |  \n",
      "     |  from_file(...)\n",
      "     |      from_file(filename, shared=False, size=0) -> Storage\n",
      "     |      \n",
      "     |      If `shared` is `True`, then memory is shared between all processes.\n",
      "     |      All changes are written to the file. If `shared` is `False`, then the changes on\n",
      "     |      the storage do not affect the file.\n",
      "     |      \n",
      "     |      `size` is the number of elements in the storage. If `shared` is `False`,\n",
      "     |      then the file must contain at least `size * sizeof(Type)` bytes\n",
      "     |      (`Type` is the type of storage). If `shared` is `True` the file will be\n",
      "     |      created if needed.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          filename (str): file name to map\n",
      "     |          shared (bool): whether to share memory\n",
      "     |          size (int): number of elements in the storage\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.storage._StorageBase:\n",
      "     |  \n",
      "     |  __copy__(self)\n",
      "     |  \n",
      "     |  __deepcopy__(self, memo)\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      helper for pickle\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __sizeof__(self)\n",
      "     |      __sizeof__() -> int\n",
      "     |      size of object in memory, in bytes\n",
      "     |  \n",
      "     |  __str__(self)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  byte(self)\n",
      "     |      Casts this storage to byte type\n",
      "     |  \n",
      "     |  char(self)\n",
      "     |      Casts this storage to char type\n",
      "     |  \n",
      "     |  clone(self)\n",
      "     |      Returns a copy of this storage\n",
      "     |  \n",
      "     |  cpu(self)\n",
      "     |      Returns a CPU copy of this storage if it's not already on the CPU\n",
      "     |  \n",
      "     |  cuda = _cuda(self, device=None, non_blocking=False, **kwargs)\n",
      "     |      Returns a copy of this object in CUDA memory.\n",
      "     |      \n",
      "     |      If this object is already in CUDA memory and on the correct device, then\n",
      "     |      no copy is performed and the original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          device (int): The destination GPU id. Defaults to the current device.\n",
      "     |          non_blocking (bool): If ``True`` and the source is in pinned memory,\n",
      "     |              the copy will be asynchronous with respect to the host. Otherwise,\n",
      "     |              the argument has no effect.\n",
      "     |          **kwargs: For compatibility, may contain the key ``async`` in place of\n",
      "     |              the ``non_blocking`` argument.\n",
      "     |  \n",
      "     |  double(self)\n",
      "     |      Casts this storage to double type\n",
      "     |  \n",
      "     |  float(self)\n",
      "     |      Casts this storage to float type\n",
      "     |  \n",
      "     |  half(self)\n",
      "     |      Casts this storage to half type\n",
      "     |  \n",
      "     |  int(self)\n",
      "     |      Casts this storage to int type\n",
      "     |  \n",
      "     |  long(self)\n",
      "     |      Casts this storage to long type\n",
      "     |  \n",
      "     |  pin_memory(self)\n",
      "     |      Copies the storage to pinned memory, if it's not already pinned.\n",
      "     |  \n",
      "     |  share_memory_(self)\n",
      "     |      Moves the storage to shared memory.\n",
      "     |      \n",
      "     |      This is a no-op for storages already in shared memory and for CUDA\n",
      "     |      storages, which do not need to be moved for sharing across processes.\n",
      "     |      Storages in shared memory cannot be resized.\n",
      "     |      \n",
      "     |      Returns: self\n",
      "     |  \n",
      "     |  short(self)\n",
      "     |      Casts this storage to short type\n",
      "     |  \n",
      "     |  tolist(self)\n",
      "     |      Returns a list containing the elements of this storage\n",
      "     |  \n",
      "     |  type = _type(self, dtype=None, non_blocking=False, **kwargs)\n",
      "     |      Returns the type if `dtype` is not provided, else casts this object to\n",
      "     |      the specified type.\n",
      "     |      \n",
      "     |      If this is already of the correct type, no copy is performed and the\n",
      "     |      original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (type or string): The desired type\n",
      "     |          non_blocking (bool): If ``True``, and the source is in pinned memory\n",
      "     |              and destination is on the GPU or vice versa, the copy is performed\n",
      "     |              asynchronously with respect to the host. Otherwise, the argument\n",
      "     |              has no effect.\n",
      "     |          **kwargs: For compatibility, may contain the key ``async`` in place of\n",
      "     |              the ``non_blocking`` argument. The ``async`` arg is deprecated.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.storage._StorageBase:\n",
      "     |  \n",
      "     |  is_cuda = False\n",
      "     |  \n",
      "     |  is_sparse = False\n",
      "    \n",
      "    class CharTensor(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __abs__ = abs(...)\n",
      "     |  \n",
      "     |  __add__(...)\n",
      "     |  \n",
      "     |  __and__(...)\n",
      "     |  \n",
      "     |  __array__(self, dtype=None)\n",
      "     |      # Numpy array interface, to support `numpy.asarray(tensor) -> ndarray`\n",
      "     |  \n",
      "     |  __array_wrap__(self, array)\n",
      "     |      # Wrap Numpy array again in a suitable tensor when done, to support e.g.\n",
      "     |      # `numpy.sin(tensor) -> tensor` or `numpy.greater(tensor, 0) -> ByteTensor`\n",
      "     |  \n",
      "     |  __bool__(...)\n",
      "     |  \n",
      "     |  __deepcopy__(self, memo)\n",
      "     |  \n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |  \n",
      "     |  __dir__(self)\n",
      "     |      __dir__() -> list\n",
      "     |      default dir() implementation\n",
      "     |  \n",
      "     |  __div__(...)\n",
      "     |  \n",
      "     |  __eq__ = eq(...)\n",
      "     |  \n",
      "     |  __float__(...)\n",
      "     |  \n",
      "     |  __format__(self, format_spec)\n",
      "     |      default object formatter\n",
      "     |  \n",
      "     |  __ge__ = ge(...)\n",
      "     |  \n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |  \n",
      "     |  __gt__ = gt(...)\n",
      "     |  \n",
      "     |  __hash__(self)\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __iadd__(...)\n",
      "     |  \n",
      "     |  __iand__(...)\n",
      "     |  \n",
      "     |  __idiv__(...)\n",
      "     |  \n",
      "     |  __ilshift__(...)\n",
      "     |  \n",
      "     |  __imul__(...)\n",
      "     |  \n",
      "     |  __index__(...)\n",
      "     |  \n",
      "     |  __int__(...)\n",
      "     |  \n",
      "     |  __invert__(...)\n",
      "     |  \n",
      "     |  __ior__(...)\n",
      "     |  \n",
      "     |  __ipow__(self, other)\n",
      "     |  \n",
      "     |  __irshift__(...)\n",
      "     |  \n",
      "     |  __isub__(...)\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |  \n",
      "     |  __itruediv__ = __idiv__(...)\n",
      "     |  \n",
      "     |  __ixor__(...)\n",
      "     |  \n",
      "     |  __le__ = le(...)\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |      Return len(self).\n",
      "     |  \n",
      "     |  __long__(...)\n",
      "     |  \n",
      "     |  __lshift__(...)\n",
      "     |  \n",
      "     |  __lt__ = lt(...)\n",
      "     |  \n",
      "     |  __matmul__(...)\n",
      "     |  \n",
      "     |  __mod__(...)\n",
      "     |  \n",
      "     |  __mul__(...)\n",
      "     |  \n",
      "     |  __ne__ = ne(...)\n",
      "     |  \n",
      "     |  __neg__ = neg(...)\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from tensortype\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  __nonzero__(...)\n",
      "     |  \n",
      "     |  __or__(...)\n",
      "     |  \n",
      "     |  __pow__ = pow(...)\n",
      "     |  \n",
      "     |  __radd__(...)\n",
      "     |  \n",
      "     |  __rdiv__(self, other)\n",
      "     |  \n",
      "     |  __reduce_ex__(self, proto)\n",
      "     |      helper for pickle\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __rmul__(...)\n",
      "     |  \n",
      "     |  __rpow__(self, other)\n",
      "     |  \n",
      "     |  __rshift__(...)\n",
      "     |  \n",
      "     |  __rsub__(self, other)\n",
      "     |  \n",
      "     |  __rtruediv__ = __rdiv__(self, other)\n",
      "     |  \n",
      "     |  __setitem__(self, key, value, /)\n",
      "     |      Set self[key] to value.\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |  \n",
      "     |  __sub__(...)\n",
      "     |  \n",
      "     |  __truediv__(...)\n",
      "     |  \n",
      "     |  __xor__(...)\n",
      "     |  \n",
      "     |  abs(...)\n",
      "     |      abs() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.abs`\n",
      "     |  \n",
      "     |  abs_(...)\n",
      "     |      abs_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.abs`\n",
      "     |  \n",
      "     |  acos(...)\n",
      "     |      acos() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.acos`\n",
      "     |  \n",
      "     |  acos_(...)\n",
      "     |      acos_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.acos`\n",
      "     |  \n",
      "     |  add(...)\n",
      "     |      add(value) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.add`\n",
      "     |  \n",
      "     |  add_(...)\n",
      "     |      add_(value) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.add`\n",
      "     |  \n",
      "     |  addbmm(...)\n",
      "     |      addbmm(beta=1, mat, alpha=1, batch1, batch2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addbmm`\n",
      "     |  \n",
      "     |  addbmm_(...)\n",
      "     |      addbmm_(beta=1, mat, alpha=1, batch1, batch2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addbmm`\n",
      "     |  \n",
      "     |  addcdiv(...)\n",
      "     |      addcdiv(value=1, tensor1, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addcdiv`\n",
      "     |  \n",
      "     |  addcdiv_(...)\n",
      "     |      addcdiv_(value=1, tensor1, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addcdiv`\n",
      "     |  \n",
      "     |  addcmul(...)\n",
      "     |      addcmul(value=1, tensor1, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addcmul`\n",
      "     |  \n",
      "     |  addcmul_(...)\n",
      "     |      addcmul_(value=1, tensor1, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addcmul`\n",
      "     |  \n",
      "     |  addmm(...)\n",
      "     |      addmm(beta=1, mat, alpha=1, mat1, mat2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addmm`\n",
      "     |  \n",
      "     |  addmm_(...)\n",
      "     |      addmm_(beta=1, mat, alpha=1, mat1, mat2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addmm`\n",
      "     |  \n",
      "     |  addmv(...)\n",
      "     |      addmv(beta=1, tensor, alpha=1, mat, vec) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addmv`\n",
      "     |  \n",
      "     |  addmv_(...)\n",
      "     |      addmv_(beta=1, tensor, alpha=1, mat, vec) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addmv`\n",
      "     |  \n",
      "     |  addr(...)\n",
      "     |      addr(beta=1, alpha=1, vec1, vec2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addr`\n",
      "     |  \n",
      "     |  addr_(...)\n",
      "     |      addr_(beta=1, alpha=1, vec1, vec2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addr`\n",
      "     |  \n",
      "     |  all(...)\n",
      "     |      all() -> bool\n",
      "     |      \n",
      "     |      Returns ``True`` if all elements in the tensor are non-zero, ``False`` otherwise.\n",
      "     |  \n",
      "     |  allclose(...)\n",
      "     |  \n",
      "     |  any(...)\n",
      "     |      any() -> bool\n",
      "     |      \n",
      "     |      Returns ``True`` if any elements in the tensor are non-zero, ``False`` otherwise.\n",
      "     |  \n",
      "     |  apply_(...)\n",
      "     |      apply_(callable) -> Tensor\n",
      "     |      \n",
      "     |      Applies the function :attr:`callable` to each element in the tensor, replacing\n",
      "     |      each element with the value returned by :attr:`callable`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          This function only works with CPU tensors and should not be used in code\n",
      "     |          sections that require high performance.\n",
      "     |  \n",
      "     |  argmax(self, dim=None, keepdim=False)\n",
      "     |      See :func:`torch.argmax`\n",
      "     |  \n",
      "     |  argmin(self, dim=None, keepdim=False)\n",
      "     |      See :func:`torch.argmin`\n",
      "     |  \n",
      "     |  as_strided(...)\n",
      "     |  \n",
      "     |  as_strided_(...)\n",
      "     |  \n",
      "     |  asin(...)\n",
      "     |      asin() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.asin`\n",
      "     |  \n",
      "     |  asin_(...)\n",
      "     |      asin_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.asin`\n",
      "     |  \n",
      "     |  atan(...)\n",
      "     |      atan() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.atan`\n",
      "     |  \n",
      "     |  atan2(...)\n",
      "     |      atan2(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.atan2`\n",
      "     |  \n",
      "     |  atan2_(...)\n",
      "     |      atan2_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.atan2`\n",
      "     |  \n",
      "     |  atan_(...)\n",
      "     |      atan_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.atan`\n",
      "     |  \n",
      "     |  backward(self, gradient=None, retain_graph=None, create_graph=False)\n",
      "     |      Computes the gradient of current tensor w.r.t. graph leaves.\n",
      "     |      \n",
      "     |      The graph is differentiated using the chain rule. If the tensor is\n",
      "     |      non-scalar (i.e. its data has more than one element) and requires\n",
      "     |      gradient, the function additionally requires specifying ``gradient``.\n",
      "     |      It should be a tensor of matching type and location, that contains\n",
      "     |      the gradient of the differentiated function w.r.t. ``self``.\n",
      "     |      \n",
      "     |      This function accumulates gradients in the leaves - you might need to\n",
      "     |      zero them before calling it.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          gradient (Tensor or None): Gradient w.r.t. the\n",
      "     |              tensor. If it is a tensor, it will be automatically converted\n",
      "     |              to a Tensor that does not require grad unless ``create_graph`` is True.\n",
      "     |              None values can be specified for scalar Tensors or ones that\n",
      "     |              don't require grad. If a None value would be acceptable then\n",
      "     |              this argument is optional.\n",
      "     |          retain_graph (bool, optional): If ``False``, the graph used to compute\n",
      "     |              the grads will be freed. Note that in nearly all cases setting\n",
      "     |              this option to True is not needed and often can be worked around\n",
      "     |              in a much more efficient way. Defaults to the value of\n",
      "     |              ``create_graph``.\n",
      "     |          create_graph (bool, optional): If ``True``, graph of the derivative will\n",
      "     |              be constructed, allowing to compute higher order derivative\n",
      "     |              products. Defaults to ``False``.\n",
      "     |  \n",
      "     |  baddbmm(...)\n",
      "     |      baddbmm(beta=1, alpha=1, batch1, batch2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.baddbmm`\n",
      "     |  \n",
      "     |  baddbmm_(...)\n",
      "     |      baddbmm_(beta=1, alpha=1, batch1, batch2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.baddbmm`\n",
      "     |  \n",
      "     |  bernoulli(...)\n",
      "     |      bernoulli() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bernoulli`\n",
      "     |  \n",
      "     |  bernoulli_(...)\n",
      "     |      bernoulli_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.bernoulli`\n",
      "     |  \n",
      "     |  bmm(...)\n",
      "     |      bmm(batch2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bmm`\n",
      "     |  \n",
      "     |  btrifact(self, info=None, pivot=True)\n",
      "     |      See :func:`torch.btrifact`\n",
      "     |  \n",
      "     |  btrifact_with_info(...)\n",
      "     |      btrifact_with_info(pivot=True) -> (Tensor, Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.btrifact_with_info`\n",
      "     |  \n",
      "     |  btrisolve(...)\n",
      "     |  \n",
      "     |  byte(...)\n",
      "     |      byte() -> Tensor\n",
      "     |      \n",
      "     |      ``self.byte()`` is equivalent to ``self.to(torch.uint8)``. See :func:`to`.\n",
      "     |  \n",
      "     |  cauchy_(...)\n",
      "     |      cauchy_(median=0, sigma=1, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills the tensor with numbers drawn from the Cauchy distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(x) = \\dfrac{1}{\\pi} \\dfrac{\\sigma}{(x - median)^2 + \\sigma^2}\n",
      "     |  \n",
      "     |  ceil(...)\n",
      "     |      ceil() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ceil`\n",
      "     |  \n",
      "     |  ceil_(...)\n",
      "     |      ceil_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ceil`\n",
      "     |  \n",
      "     |  char(...)\n",
      "     |      char() -> Tensor\n",
      "     |      \n",
      "     |      ``self.char()`` is equivalent to ``self.to(torch.int8)``. See :func:`to`.\n",
      "     |  \n",
      "     |  chunk(...)\n",
      "     |      chunk(chunks, dim=0) -> List of Tensors\n",
      "     |      \n",
      "     |      See :func:`torch.chunk`\n",
      "     |  \n",
      "     |  clamp(...)\n",
      "     |      clamp(min, max) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.clamp`\n",
      "     |  \n",
      "     |  clamp_(...)\n",
      "     |      clamp_(min, max) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.clamp`\n",
      "     |  \n",
      "     |  clone(...)\n",
      "     |      clone() -> Tensor\n",
      "     |      \n",
      "     |      Returns a copy of the :attr:`self` tensor. The copy has the same size and data\n",
      "     |      type as :attr:`self`.\n",
      "     |  \n",
      "     |  coalesce(...)\n",
      "     |  \n",
      "     |  contiguous(...)\n",
      "     |      contiguous() -> Tensor\n",
      "     |      \n",
      "     |      Returns a contiguous tensor containing the same data as :attr:`self` tensor. If\n",
      "     |      :attr:`self` tensor is contiguous, this function returns the :attr:`self`\n",
      "     |      tensor.\n",
      "     |  \n",
      "     |  conv_tbc(...)\n",
      "     |  \n",
      "     |  copy_(...)\n",
      "     |      copy_(src, non_blocking=False) -> Tensor\n",
      "     |      \n",
      "     |      Copies the elements from :attr:`src` into :attr:`self` tensor and returns\n",
      "     |      :attr:`self`.\n",
      "     |      \n",
      "     |      The :attr:`src` tensor must be :ref:`broadcastable <broadcasting-semantics>`\n",
      "     |      with the :attr:`self` tensor. It may be of a different data type or reside on a\n",
      "     |      different device.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          src (Tensor): the source tensor to copy from\n",
      "     |          non_blocking (bool): if ``True`` and this copy is between CPU and GPU,\n",
      "     |              the copy may occur asynchronously with respect to the host. For other\n",
      "     |              cases, this argument has no effect.\n",
      "     |  \n",
      "     |  cos(...)\n",
      "     |      cos() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cos`\n",
      "     |  \n",
      "     |  cos_(...)\n",
      "     |      cos_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.cos`\n",
      "     |  \n",
      "     |  cosh(...)\n",
      "     |      cosh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cosh`\n",
      "     |  \n",
      "     |  cosh_(...)\n",
      "     |      cosh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.cosh`\n",
      "     |  \n",
      "     |  cpu(...)\n",
      "     |  \n",
      "     |  cross(...)\n",
      "     |      cross(other, dim=-1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cross`\n",
      "     |  \n",
      "     |  cuda(...)\n",
      "     |      cuda(device=None, non_blocking=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a copy of this object in CUDA memory.\n",
      "     |      \n",
      "     |      If this object is already in CUDA memory and on the correct device,\n",
      "     |      then no copy is performed and the original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          device (:class:`torch.device`): The destination GPU device.\n",
      "     |              Defaults to the current CUDA device.\n",
      "     |          non_blocking (bool): If ``True`` and the source is in pinned memory,\n",
      "     |              the copy will be asynchronous with respect to the host.\n",
      "     |              Otherwise, the argument has no effect. Default: ``False``.\n",
      "     |  \n",
      "     |  cumprod(...)\n",
      "     |      cumprod(dim) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cumprod`\n",
      "     |  \n",
      "     |  cumsum(...)\n",
      "     |      cumsum(dim) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cumsum`\n",
      "     |  \n",
      "     |  data_ptr(...)\n",
      "     |      data_ptr() -> int\n",
      "     |      \n",
      "     |      Returns the address of the first element of :attr:`self` tensor.\n",
      "     |  \n",
      "     |  det(...)\n",
      "     |      det() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.det`\n",
      "     |  \n",
      "     |  detach(...)\n",
      "     |      Returns a new Tensor, detached from the current graph.\n",
      "     |      \n",
      "     |      The result will never require gradient.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |        Returned Tensor uses the same data tensor as the original one.\n",
      "     |        In-place modifications on either of them will be seen, and may trigger\n",
      "     |        errors in correctness checks.\n",
      "     |  \n",
      "     |  detach_(...)\n",
      "     |      Detaches the Tensor from the graph that created it, making it a leaf.\n",
      "     |      Views cannot be detached in-place.\n",
      "     |  \n",
      "     |  diag(...)\n",
      "     |      diag(diagonal=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diag`\n",
      "     |  \n",
      "     |  digamma(...)\n",
      "     |  \n",
      "     |  digamma_(...)\n",
      "     |  \n",
      "     |  dim(...)\n",
      "     |      dim() -> int\n",
      "     |      \n",
      "     |      Returns the number of dimensions of :attr:`self` tensor.\n",
      "     |  \n",
      "     |  dist(...)\n",
      "     |      dist(other, p=2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.dist`\n",
      "     |  \n",
      "     |  div(...)\n",
      "     |      div(value) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.div`\n",
      "     |  \n",
      "     |  div_(...)\n",
      "     |      div_(value) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.div`\n",
      "     |  \n",
      "     |  dot(...)\n",
      "     |      dot(tensor2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.dot`\n",
      "     |  \n",
      "     |  double(...)\n",
      "     |      double() -> Tensor\n",
      "     |      \n",
      "     |      ``self.double()`` is equivalent to ``self.to(torch.float64)``. See :func:`to`.\n",
      "     |  \n",
      "     |  eig(...)\n",
      "     |      eig(eigenvectors=False) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.eig`\n",
      "     |  \n",
      "     |  element_size(...)\n",
      "     |      element_size() -> int\n",
      "     |      \n",
      "     |      Returns the size in bytes of an individual element.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> torch.tensor([]).element_size()\n",
      "     |          4\n",
      "     |          >>> torch.tensor([], dtype=torch.uint8).element_size()\n",
      "     |          1\n",
      "     |  \n",
      "     |  eq(...)\n",
      "     |      eq(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.eq`\n",
      "     |  \n",
      "     |  eq_(...)\n",
      "     |      eq_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.eq`\n",
      "     |  \n",
      "     |  equal(...)\n",
      "     |      equal(other) -> bool\n",
      "     |      \n",
      "     |      See :func:`torch.equal`\n",
      "     |  \n",
      "     |  erf(...)\n",
      "     |      erf() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.erf`\n",
      "     |  \n",
      "     |  erf_(...)\n",
      "     |  \n",
      "     |  erfinv(...)\n",
      "     |      erfinv() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.erfinv`\n",
      "     |  \n",
      "     |  erfinv_(...)\n",
      "     |  \n",
      "     |  exp(...)\n",
      "     |      exp() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.exp`\n",
      "     |  \n",
      "     |  exp_(...)\n",
      "     |      exp_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.exp`\n",
      "     |  \n",
      "     |  expand(...)\n",
      "     |      expand(*sizes) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new view of the :attr:`self` tensor with singleton dimensions expanded\n",
      "     |      to a larger size.\n",
      "     |      \n",
      "     |      Passing -1 as the size for a dimension means not changing the size of\n",
      "     |      that dimension.\n",
      "     |      \n",
      "     |      Tensor can be also expanded to a larger number of dimensions, and the\n",
      "     |      new ones will be appended at the front. For the new dimensions, the\n",
      "     |      size cannot be set to -1.\n",
      "     |      \n",
      "     |      Expanding a tensor does not allocate new memory, but only creates a\n",
      "     |      new view on the existing tensor where a dimension of size one is\n",
      "     |      expanded to a larger size by setting the ``stride`` to 0. Any dimension\n",
      "     |      of size 1 can be expanded to an arbitrary value without allocating new\n",
      "     |      memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *sizes (torch.Size or int...): the desired expanded size\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1], [2], [3]])\n",
      "     |          >>> x.size()\n",
      "     |          torch.Size([3, 1])\n",
      "     |          >>> x.expand(3, 4)\n",
      "     |          tensor([[ 1,  1,  1,  1],\n",
      "     |                  [ 2,  2,  2,  2],\n",
      "     |                  [ 3,  3,  3,  3]])\n",
      "     |          >>> x.expand(-1, 4)   # -1 means not changing the size of that dimension\n",
      "     |          tensor([[ 1,  1,  1,  1],\n",
      "     |                  [ 2,  2,  2,  2],\n",
      "     |                  [ 3,  3,  3,  3]])\n",
      "     |  \n",
      "     |  expand_as(self, tensor)\n",
      "     |  \n",
      "     |  expm1(...)\n",
      "     |      expm1() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.expm1`\n",
      "     |  \n",
      "     |  expm1_(...)\n",
      "     |      expm1_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.expm1`\n",
      "     |  \n",
      "     |  exponential_(...)\n",
      "     |      exponential_(lambd=1, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with elements drawn from the exponential distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(x) = \\lambda e^{-\\lambda x}\n",
      "     |  \n",
      "     |  fft(...)\n",
      "     |      fft(signal_ndim, normalized=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fft`\n",
      "     |  \n",
      "     |  fill_(...)\n",
      "     |      fill_(value) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with the specified value.\n",
      "     |  \n",
      "     |  float(...)\n",
      "     |      float() -> Tensor\n",
      "     |      \n",
      "     |      ``self.float()`` is equivalent to ``self.to(torch.float32)``. See :func:`to`.\n",
      "     |  \n",
      "     |  floor(...)\n",
      "     |      floor() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.floor`\n",
      "     |  \n",
      "     |  floor_(...)\n",
      "     |      floor_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.floor`\n",
      "     |  \n",
      "     |  fmod(...)\n",
      "     |      fmod(divisor) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fmod`\n",
      "     |  \n",
      "     |  fmod_(...)\n",
      "     |      fmod_(divisor) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.fmod`\n",
      "     |  \n",
      "     |  frac(...)\n",
      "     |      frac() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.frac`\n",
      "     |  \n",
      "     |  frac_(...)\n",
      "     |      frac_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.frac`\n",
      "     |  \n",
      "     |  gather(...)\n",
      "     |      gather(dim, index) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.gather`\n",
      "     |  \n",
      "     |  ge(...)\n",
      "     |      ge(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ge`\n",
      "     |  \n",
      "     |  ge_(...)\n",
      "     |      ge_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ge`\n",
      "     |  \n",
      "     |  gels(...)\n",
      "     |      gels(A) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.gels`\n",
      "     |  \n",
      "     |  geometric_(...)\n",
      "     |      geometric_(p, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with elements drawn from the geometric distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(X=k) = (1 - p)^{k - 1} p\n",
      "     |  \n",
      "     |  geqrf(...)\n",
      "     |      geqrf() -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.geqrf`\n",
      "     |  \n",
      "     |  ger(...)\n",
      "     |      ger(vec2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ger`\n",
      "     |  \n",
      "     |  gesv(...)\n",
      "     |      gesv(A) -> Tensor, Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.gesv`\n",
      "     |  \n",
      "     |  get_device(...)\n",
      "     |  \n",
      "     |  gt(...)\n",
      "     |      gt(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.gt`\n",
      "     |  \n",
      "     |  gt_(...)\n",
      "     |      gt_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.gt`\n",
      "     |  \n",
      "     |  half(...)\n",
      "     |      half() -> Tensor\n",
      "     |      \n",
      "     |      ``self.half()`` is equivalent to ``self.to(torch.float16)``. See :func:`to`.\n",
      "     |  \n",
      "     |  histc(...)\n",
      "     |      histc(bins=100, min=0, max=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.histc`\n",
      "     |  \n",
      "     |  ifft(...)\n",
      "     |      ifft(signal_ndim, normalized=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ifft`\n",
      "     |  \n",
      "     |  index(...)\n",
      "     |      index(m) -> Tensor\n",
      "     |      \n",
      "     |      Selects elements from :attr:`self` tensor using a binary mask or along a given\n",
      "     |      dimension. The expression ``tensor.index(m)`` is equivalent to ``tensor[m]``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          m (int or ByteTensor or slice): the dimension or mask used to select elements\n",
      "     |  \n",
      "     |  index_add(self, dim, index, tensor)\n",
      "     |  \n",
      "     |  index_add_(...)\n",
      "     |      index_add_(dim, index, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Accumulate the elements of :attr:`tensor` into the :attr:`self` tensor by adding\n",
      "     |      to the indices in the order given in :attr:`index`. For example, if ``dim == 0``\n",
      "     |      and ``index[i] == j``, then the ``i``\\ th row of :attr:`tensor` is added to the\n",
      "     |      ``j``\\ th row of :attr:`self`.\n",
      "     |      \n",
      "     |      The :attr:`dim`\\ th dimension of :attr:`tensor` must have the same size as the\n",
      "     |      length of :attr:`index` (which must be a vector), and all other dimensions must\n",
      "     |      match :attr:`self`, or an error will be raised.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension along which to index\n",
      "     |          index (LongTensor): indices of :attr:`tensor` to select from\n",
      "     |          tensor (Tensor): the tensor containing values to add\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.ones(5, 3)\n",
      "     |          >>> t = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
      "     |          >>> index = torch.tensor([0, 4, 2])\n",
      "     |          >>> x.index_add_(0, index, t)\n",
      "     |          tensor([[  2.,   3.,   4.],\n",
      "     |                  [  1.,   1.,   1.],\n",
      "     |                  [  8.,   9.,  10.],\n",
      "     |                  [  1.,   1.,   1.],\n",
      "     |                  [  5.,   6.,   7.]])\n",
      "     |  \n",
      "     |  index_copy(self, dim, index, tensor)\n",
      "     |  \n",
      "     |  index_copy_(...)\n",
      "     |      index_copy_(dim, index, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Copies the elements of :attr:`tensor` into the :attr:`self` tensor by selecting\n",
      "     |      the indices in the order given in :attr:`index`. For example, if ``dim == 0``\n",
      "     |      and ``index[i] == j``, then the ``i``\\ th row of :attr:`tensor` is copied to the\n",
      "     |      ``j``\\ th row of :attr:`self`.\n",
      "     |      \n",
      "     |      The :attr:`dim`\\ th dimension of :attr:`tensor` must have the same size as the\n",
      "     |      length of :attr:`index` (which must be a vector), and all other dimensions must\n",
      "     |      match :attr:`self`, or an error will be raised.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension along which to index\n",
      "     |          index (LongTensor): indices of :attr:`tensor` to select from\n",
      "     |          tensor (Tensor): the tensor containing values to copy\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.zeros(5, 3)\n",
      "     |          >>> t = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
      "     |          >>> index = torch.tensor([0, 4, 2])\n",
      "     |          >>> x.index_copy_(0, index, t)\n",
      "     |          tensor([[ 1.,  2.,  3.],\n",
      "     |                  [ 0.,  0.,  0.],\n",
      "     |                  [ 7.,  8.,  9.],\n",
      "     |                  [ 0.,  0.,  0.],\n",
      "     |                  [ 4.,  5.,  6.]])\n",
      "     |  \n",
      "     |  index_fill(self, dim, index, value)\n",
      "     |  \n",
      "     |  index_fill_(...)\n",
      "     |      index_fill_(dim, index, val) -> Tensor\n",
      "     |      \n",
      "     |      Fills the elements of the :attr:`self` tensor with value :attr:`val` by\n",
      "     |      selecting the indices in the order given in :attr:`index`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension along which to index\n",
      "     |          index (LongTensor): indices of :attr:`self` tensor to fill in\n",
      "     |          val (float): the value to fill with\n",
      "     |      \n",
      "     |      Example::\n",
      "     |          >>> x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
      "     |          >>> index = torch.tensor([0, 2])\n",
      "     |          >>> x.index_fill_(1, index, -1)\n",
      "     |          tensor([[-1.,  2., -1.],\n",
      "     |                  [-1.,  5., -1.],\n",
      "     |                  [-1.,  8., -1.]])\n",
      "     |  \n",
      "     |  index_put_(...)\n",
      "     |      index_put_(indices, value) -> Tensor\n",
      "     |      \n",
      "     |      Puts values from the tensor :attr:`value` into the tensor :attr:`self` using\n",
      "     |      the indices specified in :attr:`indices` (which is a tuple of Tensors). The\n",
      "     |      expression ``tensor.index_put_(indices, value)`` is equivalent to\n",
      "     |      ``tensor[indices] = value``. Returns :attr:`self`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          indices (tuple of LongTensor): tensors used to index into `self`.\n",
      "     |          value (Tensor): tensor of same dtype as `self`.\n",
      "     |  \n",
      "     |  index_select(...)\n",
      "     |      index_select(dim, index) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.index_select`\n",
      "     |  \n",
      "     |  int(...)\n",
      "     |      int() -> Tensor\n",
      "     |      \n",
      "     |      ``self.int()`` is equivalent to ``self.to(torch.int32)``. See :func:`to`.\n",
      "     |  \n",
      "     |  inverse(...)\n",
      "     |      inverse() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.inverse`\n",
      "     |  \n",
      "     |  irfft(...)\n",
      "     |      irfft(signal_ndim, normalized=False, onesided=True, signal_sizes=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.irfft`\n",
      "     |  \n",
      "     |  is_coalesced(...)\n",
      "     |  \n",
      "     |  is_contiguous(...)\n",
      "     |      is_contiguous() -> bool\n",
      "     |      \n",
      "     |      Returns True if :attr:`self` tensor is contiguous in memory in C order.\n",
      "     |  \n",
      "     |  is_distributed(...)\n",
      "     |  \n",
      "     |  is_floating_point(...)\n",
      "     |  \n",
      "     |  is_nonzero(...)\n",
      "     |  \n",
      "     |  is_pinned(self)\n",
      "     |      Returns true if this tensor resides in pinned memory\n",
      "     |  \n",
      "     |  is_same_size(...)\n",
      "     |  \n",
      "     |  is_set_to(...)\n",
      "     |      is_set_to(tensor) -> bool\n",
      "     |      \n",
      "     |      Returns True if this object refers to the same ``THTensor`` object from the\n",
      "     |      Torch C API as the given tensor.\n",
      "     |  \n",
      "     |  is_shared(self)\n",
      "     |      Checks if tensor is in shared memory.\n",
      "     |      \n",
      "     |      This is always ``True`` for CUDA tensors.\n",
      "     |  \n",
      "     |  is_signed(...)\n",
      "     |  \n",
      "     |  isclose(...)\n",
      "     |  \n",
      "     |  item(...)\n",
      "     |      item() -> number\n",
      "     |      \n",
      "     |      Returns the value of this tensor as a standard Python number. This only works\n",
      "     |      for tensors with one element.\n",
      "     |      \n",
      "     |      This operation is not differentiable.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([1.0])\n",
      "     |          >>> x.item()\n",
      "     |          1.0\n",
      "     |  \n",
      "     |  kthvalue(...)\n",
      "     |      kthvalue(k, dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.kthvalue`\n",
      "     |  \n",
      "     |  le(...)\n",
      "     |      le(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.le`\n",
      "     |  \n",
      "     |  le_(...)\n",
      "     |      le_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.le`\n",
      "     |  \n",
      "     |  lerp(...)\n",
      "     |      lerp(start, end, weight) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lerp`\n",
      "     |  \n",
      "     |  lerp_(...)\n",
      "     |      lerp_(start, end, weight) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lerp`\n",
      "     |  \n",
      "     |  lgamma(...)\n",
      "     |  \n",
      "     |  lgamma_(...)\n",
      "     |  \n",
      "     |  log(...)\n",
      "     |      log() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log`\n",
      "     |  \n",
      "     |  log10(...)\n",
      "     |      log10() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log10`\n",
      "     |  \n",
      "     |  log10_(...)\n",
      "     |      log10_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log10`\n",
      "     |  \n",
      "     |  log1p(...)\n",
      "     |      log1p() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log1p`\n",
      "     |  \n",
      "     |  log1p_(...)\n",
      "     |      log1p_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log1p`\n",
      "     |  \n",
      "     |  log2(...)\n",
      "     |      log2() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log2`\n",
      "     |  \n",
      "     |  log2_(...)\n",
      "     |      log2_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log2`\n",
      "     |  \n",
      "     |  log_(...)\n",
      "     |      log_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log`\n",
      "     |  \n",
      "     |  log_normal_(...)\n",
      "     |      log_normal_(mean=1, std=2, *, generator=None)\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with numbers samples from the log-normal distribution\n",
      "     |      parameterized by the given mean (µ) and standard deviation (σ).\n",
      "     |      Note that :attr:`mean` and :attr:`stdv` are the mean and standard deviation of\n",
      "     |      the underlying normal distribution, and not of the returned distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(x) = \\dfrac{1}{x \\sigma \\sqrt{2\\pi}}\\ e^{-\\dfrac{(\\ln x - \\mu)^2}{2\\sigma^2}}\n",
      "     |  \n",
      "     |  logdet(...)\n",
      "     |      logdet() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logdet`\n",
      "     |  \n",
      "     |  long(...)\n",
      "     |      long() -> Tensor\n",
      "     |      \n",
      "     |      ``self.long()`` is equivalent to ``self.to(torch.int64)``. See :func:`to`.\n",
      "     |  \n",
      "     |  lt(...)\n",
      "     |      lt(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lt`\n",
      "     |  \n",
      "     |  lt_(...)\n",
      "     |      lt_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lt`\n",
      "     |  \n",
      "     |  map2_(...)\n",
      "     |  \n",
      "     |  map_(...)\n",
      "     |      map_(tensor, callable)\n",
      "     |      \n",
      "     |      Applies :attr:`callable` for each element in :attr:`self` tensor and the given\n",
      "     |      :attr:`tensor` and stores the results in :attr:`self` tensor. :attr:`self` tensor and\n",
      "     |      the given :attr:`tensor` must be :ref:`broadcastable <broadcasting-semantics>`.\n",
      "     |      \n",
      "     |      The :attr:`callable` should have the signature::\n",
      "     |      \n",
      "     |          def callable(a, b) -> number\n",
      "     |  \n",
      "     |  masked_copy(self, mask, tensor)\n",
      "     |  \n",
      "     |  masked_copy_(self, mask, tensor)\n",
      "     |  \n",
      "     |  masked_fill(self, mask, value)\n",
      "     |  \n",
      "     |  masked_fill_(...)\n",
      "     |      masked_fill_(mask, value)\n",
      "     |      \n",
      "     |      Fills elements of :attr:`self` tensor with :attr:`value` where :attr:`mask` is\n",
      "     |      one. The shape of :attr:`mask` must be\n",
      "     |      :ref:`broadcastable <broadcasting-semantics>` with the shape of the underlying\n",
      "     |      tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          mask (ByteTensor): the binary mask\n",
      "     |          value (float): the value to fill in with\n",
      "     |  \n",
      "     |  masked_scatter(self, mask, tensor)\n",
      "     |  \n",
      "     |  masked_scatter_(...)\n",
      "     |      masked_scatter_(mask, source)\n",
      "     |      \n",
      "     |      Copies elements from :attr:`source` into :attr:`self` tensor at positions where\n",
      "     |      the :attr:`mask` is one.\n",
      "     |      The shape of :attr:`mask` must be :ref:`broadcastable <broadcasting-semantics>`\n",
      "     |      with the shape of the underlying tensor. The :attr:`source` should have at least\n",
      "     |      as many elements as the number of ones in :attr:`mask`\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          mask (ByteTensor): the binary mask\n",
      "     |          source (Tensor): the tensor to copy from\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The :attr:`mask` operates on the :attr:`self` tensor, not on the given\n",
      "     |          :attr:`source` tensor.\n",
      "     |  \n",
      "     |  masked_select(...)\n",
      "     |      masked_select(mask) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.masked_select`\n",
      "     |  \n",
      "     |  matmul(...)\n",
      "     |      matmul(tensor2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.matmul`\n",
      "     |  \n",
      "     |  max(...)\n",
      "     |      max(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.max`\n",
      "     |  \n",
      "     |  mean(...)\n",
      "     |      mean(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.mean`\n",
      "     |  \n",
      "     |  median(...)\n",
      "     |      median(dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.median`\n",
      "     |  \n",
      "     |  min(...)\n",
      "     |      min(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.min`\n",
      "     |  \n",
      "     |  mm(...)\n",
      "     |      mm(mat2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mm`\n",
      "     |  \n",
      "     |  mode(...)\n",
      "     |      mode(dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.mode`\n",
      "     |  \n",
      "     |  mul(...)\n",
      "     |      mul(value) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mul`\n",
      "     |  \n",
      "     |  mul_(...)\n",
      "     |      mul_(value)\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.mul`\n",
      "     |  \n",
      "     |  multinomial(...)\n",
      "     |      multinomial(num_samples, replacement=False, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.multinomial`\n",
      "     |  \n",
      "     |  mv(...)\n",
      "     |      mv(vec) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mv`\n",
      "     |  \n",
      "     |  narrow(...)\n",
      "     |      narrow(dimension, start, length) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new tensor that is a narrowed version of :attr:`self` tensor. The\n",
      "     |      dimension :attr:`dim` is narrowed from :attr:`start` to :attr:`start + length`. The\n",
      "     |      returned tensor and :attr:`self` tensor share the same underlying storage.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dimension (int): the dimension along which to narrow\n",
      "     |          start (int): the starting dimension\n",
      "     |          length (int): the distance to the ending dimension\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
      "     |          >>> x.narrow(0, 0, 2)\n",
      "     |          tensor([[ 1,  2,  3],\n",
      "     |                  [ 4,  5,  6]])\n",
      "     |          >>> x.narrow(1, 1, 2)\n",
      "     |          tensor([[ 2,  3],\n",
      "     |                  [ 5,  6],\n",
      "     |                  [ 8,  9]])\n",
      "     |  \n",
      "     |  ndimension(...)\n",
      "     |      ndimension() -> int\n",
      "     |      \n",
      "     |      Alias for :meth:`~Tensor.dim()`\n",
      "     |  \n",
      "     |  ne(...)\n",
      "     |      ne(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ne`\n",
      "     |  \n",
      "     |  ne_(...)\n",
      "     |      ne_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ne`\n",
      "     |  \n",
      "     |  neg(...)\n",
      "     |      neg() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.neg`\n",
      "     |  \n",
      "     |  neg_(...)\n",
      "     |      neg_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.neg`\n",
      "     |  \n",
      "     |  nelement(...)\n",
      "     |      nelement() -> int\n",
      "     |      \n",
      "     |      Alias for :meth:`~Tensor.numel`\n",
      "     |  \n",
      "     |  new(...)\n",
      "     |  \n",
      "     |  new_empty(...)\n",
      "     |      new_empty(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with uninitialized data.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones(())\n",
      "     |          >>> tensor.new_empty((2, 3))\n",
      "     |          tensor([[ 5.8182e-18,  4.5765e-41, -1.0545e+30],\n",
      "     |                  [ 3.0949e-41,  4.4842e-44,  0.0000e+00]])\n",
      "     |  \n",
      "     |  new_full(...)\n",
      "     |      new_full(size, fill_value, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with :attr:`fill_value`.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          fill_value (scalar): the number to fill the output tensor with.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones((2,), dtype=torch.float64)\n",
      "     |          >>> tensor.new_full((3, 4), 3.141592)\n",
      "     |          tensor([[ 3.1416,  3.1416,  3.1416,  3.1416],\n",
      "     |                  [ 3.1416,  3.1416,  3.1416,  3.1416],\n",
      "     |                  [ 3.1416,  3.1416,  3.1416,  3.1416]], dtype=torch.float64)\n",
      "     |  \n",
      "     |  new_ones(...)\n",
      "     |      new_ones(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with ``1``.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (int...): a list, tuple, or :class:`torch.Size` of integers defining the\n",
      "     |              shape of the output tensor.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.tensor((), dtype=torch.int32)\n",
      "     |          >>> tensor.new_ones((2, 3))\n",
      "     |          tensor([[ 1,  1,  1],\n",
      "     |                  [ 1,  1,  1]], dtype=torch.int32)\n",
      "     |  \n",
      "     |  new_tensor(...)\n",
      "     |      new_tensor(data, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new Tensor with :attr:`data` as the tensor data.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          :func:`new_tensor` always copies :attr:`data`. If you have a Tensor\n",
      "     |          ``data`` and want to avoid a copy, use :func:`torch.Tensor.requires_grad_`\n",
      "     |          or :func:`torch.Tensor.detach`.\n",
      "     |          If you have a numpy array and want to avoid a copy, use\n",
      "     |          :func:`torch.from_numpy`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          data (array_like): The returned Tensor copies :attr:`data`.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones((2,), dtype=torch.int8)\n",
      "     |          >>> data = [[0, 1], [2, 3]]\n",
      "     |          >>> tensor.new_tensor(data)\n",
      "     |          tensor([[ 0,  1],\n",
      "     |                  [ 2,  3]], dtype=torch.int8)\n",
      "     |  \n",
      "     |  new_zeros(...)\n",
      "     |      new_zeros(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with ``0``.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (int...): a list, tuple, or :class:`torch.Size` of integers defining the\n",
      "     |              shape of the output tensor.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.tensor((), dtype=torch.float64)\n",
      "     |          >>> tensor.new_ones((2, 3))\n",
      "     |          tensor([[ 1.,  1.,  1.],\n",
      "     |                  [ 1.,  1.,  1.]], dtype=torch.float64)\n",
      "     |  \n",
      "     |  nonzero(...)\n",
      "     |      nonzero() -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.nonzero`\n",
      "     |  \n",
      "     |  norm(...)\n",
      "     |      norm(p=2, dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.norm`\n",
      "     |  \n",
      "     |  normal_(...)\n",
      "     |      normal_(mean=0, std=1, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with elements samples from the normal distribution\n",
      "     |      parameterized by :attr:`mean` and :attr:`std`.\n",
      "     |  \n",
      "     |  numel(...)\n",
      "     |      numel() -> int\n",
      "     |      \n",
      "     |      See :func:`torch.numel`\n",
      "     |  \n",
      "     |  numpy(...)\n",
      "     |      numpy() -> numpy.ndarray\n",
      "     |      \n",
      "     |      Returns :attr:`self` tensor as a NumPy :class:`ndarray`. This tensor and the\n",
      "     |      returned :class:`ndarray` share the same underlying storage. Changes to\n",
      "     |      :attr:`self` tensor will be reflected in the :class:`ndarray` and vice versa.\n",
      "     |  \n",
      "     |  orgqr(...)\n",
      "     |      orgqr(input2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.orgqr`\n",
      "     |  \n",
      "     |  ormqr(...)\n",
      "     |      ormqr(input2, input3, left=True, transpose=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ormqr`\n",
      "     |  \n",
      "     |  permute(...)\n",
      "     |  \n",
      "     |  pin_memory(...)\n",
      "     |  \n",
      "     |  polygamma(...)\n",
      "     |  \n",
      "     |  polygamma_(...)\n",
      "     |  \n",
      "     |  potrf(...)\n",
      "     |      potrf(upper=True) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.potrf`\n",
      "     |  \n",
      "     |  potri(...)\n",
      "     |      potri(upper=True) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.potri`\n",
      "     |  \n",
      "     |  potrs(...)\n",
      "     |      potrs(input2, upper=True) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.potrs`\n",
      "     |  \n",
      "     |  pow(...)\n",
      "     |      pow(exponent) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.pow`\n",
      "     |  \n",
      "     |  pow_(...)\n",
      "     |      pow_(exponent) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.pow`\n",
      "     |  \n",
      "     |  prod(...)\n",
      "     |      prod(dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.prod`\n",
      "     |  \n",
      "     |  pstrf(...)\n",
      "     |      pstrf(upper=True, tol=-1) -> (Tensor, IntTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.pstrf`\n",
      "     |  \n",
      "     |  put_(...)\n",
      "     |      put_(indices, tensor, accumulate=False) -> Tensor\n",
      "     |      \n",
      "     |      Copies the elements from :attr:`tensor` into the positions specified by\n",
      "     |      indices. For the purpose of indexing, the :attr:`self` tensor is treated as if\n",
      "     |      it were a 1-D tensor.\n",
      "     |      \n",
      "     |      If :attr:`accumulate` is ``True``, the elements in :attr:`tensor` are added to\n",
      "     |      :attr:`self`. If accumulate is ``False``, the behavior is undefined if indices\n",
      "     |      contain duplicate elements.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          indices (LongTensor): the indices into self\n",
      "     |          tensor (Tensor): the tensor containing values to copy from\n",
      "     |          accumulate (bool): whether to accumulate into self\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> src = torch.tensor([[4, 3, 5],\n",
      "     |                                  [6, 7, 8]])\n",
      "     |          >>> src.put_(torch.tensor([1, 3]), torch.tensor([9, 10]))\n",
      "     |          tensor([[  4,   9,   5],\n",
      "     |                  [ 10,   7,   8]])\n",
      "     |  \n",
      "     |  qr(...)\n",
      "     |      qr() -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.qr`\n",
      "     |  \n",
      "     |  random_(...)\n",
      "     |      random_(from=0, to=None, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with numbers sampled from the discrete uniform\n",
      "     |      distribution over ``[from, to - 1]``. If not specified, the values are usually\n",
      "     |      only bounded by :attr:`self` tensor's data type. However, for floating point\n",
      "     |      types, if unspecified, range will be ``[0, 2^mantissa]`` to ensure that every\n",
      "     |      value is representable. For example, `torch.tensor(1, dtype=torch.double).random_()`\n",
      "     |      will be uniform in ``[0, 2^53]``.\n",
      "     |  \n",
      "     |  reciprocal(...)\n",
      "     |      reciprocal() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.reciprocal`\n",
      "     |  \n",
      "     |  reciprocal_(...)\n",
      "     |      reciprocal_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.reciprocal`\n",
      "     |  \n",
      "     |  record_stream(...)\n",
      "     |  \n",
      "     |  register_hook(self, hook)\n",
      "     |      Registers a backward hook.\n",
      "     |      \n",
      "     |      The hook will be called every time a gradient with respect to the\n",
      "     |      Tensor is computed. The hook should have the following signature::\n",
      "     |      \n",
      "     |          hook(grad) -> Tensor or None\n",
      "     |      \n",
      "     |      The hook should not modify its argument, but it can optionally return\n",
      "     |      a new gradient which will be used in place of :attr:`grad`.\n",
      "     |      \n",
      "     |      This function returns a handle with a method ``handle.remove()``\n",
      "     |      that removes the hook from the module.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          >>> v = torch.tensor([0., 0., 0.], requires_grad=True)\n",
      "     |          >>> h = v.register_hook(lambda grad: grad * 2)  # double the gradient\n",
      "     |          >>> v.backward(torch.tensor([1., 2., 3.]))\n",
      "     |          >>> v.grad\n",
      "     |      \n",
      "     |           2\n",
      "     |           4\n",
      "     |           6\n",
      "     |          [torch.FloatTensor of size (3,)]\n",
      "     |      \n",
      "     |          >>> h.remove()  # removes the hook\n",
      "     |  \n",
      "     |  reinforce(self, reward)\n",
      "     |  \n",
      "     |  relu(...)\n",
      "     |  \n",
      "     |  relu_(...)\n",
      "     |  \n",
      "     |  remainder(...)\n",
      "     |      remainder(divisor) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.remainder`\n",
      "     |  \n",
      "     |  remainder_(...)\n",
      "     |      remainder_(divisor) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.remainder`\n",
      "     |  \n",
      "     |  renorm(...)\n",
      "     |      renorm(p, dim, maxnorm) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.renorm`\n",
      "     |  \n",
      "     |  renorm_(...)\n",
      "     |      renorm_(p, dim, maxnorm) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.renorm`\n",
      "     |  \n",
      "     |  repeat(...)\n",
      "     |      repeat(*sizes) -> Tensor\n",
      "     |      \n",
      "     |      Repeats this tensor along the specified dimensions.\n",
      "     |      \n",
      "     |      Unlike :meth:`~Tensor.expand`, this function copies the tensor's data.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          sizes (torch.Size or int...): The number of times to repeat this tensor along each\n",
      "     |              dimension\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([1, 2, 3])\n",
      "     |          >>> x.repeat(4, 2)\n",
      "     |          tensor([[ 1,  2,  3,  1,  2,  3],\n",
      "     |                  [ 1,  2,  3,  1,  2,  3],\n",
      "     |                  [ 1,  2,  3,  1,  2,  3],\n",
      "     |                  [ 1,  2,  3,  1,  2,  3]])\n",
      "     |          >>> x.repeat(4, 2, 1).size()\n",
      "     |          torch.Size([4, 2, 3])\n",
      "     |  \n",
      "     |  requires_grad_(...)\n",
      "     |      requires_grad_(requires_grad=True) -> Tensor\n",
      "     |      \n",
      "     |      Change if autograd should record operations on this tensor: sets this tensor's\n",
      "     |      :attr:`requires_grad` attribute in-place. Returns this tensor.\n",
      "     |      \n",
      "     |      :func:`require_grad_`'s main use case is to tell autograd to begin recording\n",
      "     |      operations on a Tensor ``tensor``. If ``tensor`` has ``requires_grad=False``\n",
      "     |      (because it was obtained through a DataLoader, or required preprocessing or\n",
      "     |      initialization), ``tensor.requires_grad_()`` makes it so that autograd will\n",
      "     |      begin to record operations on ``tensor``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          requires_grad (bool): If autograd should record operations on this tensor.\n",
      "     |              Default: ``True``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> # Let's say we want to preprocess some saved weights and use\n",
      "     |          >>> # the result as new weights.\n",
      "     |          >>> saved_weights = [0.1, 0.2, 0.3, 0.25]\n",
      "     |          >>> loaded_weights = torch.tensor(saved_weights)\n",
      "     |          >>> weights = preprocess(loaded_weights)  # some function\n",
      "     |          >>> weights\n",
      "     |          tensor([-0.5503,  0.4926, -2.1158, -0.8303])\n",
      "     |      \n",
      "     |          >>> # Now, start to record operations done to weights\n",
      "     |          >>> weights.requires_grad_()\n",
      "     |          >>> out = weights.pow(2).sum()\n",
      "     |          >>> out.backward()\n",
      "     |          >>> weights.grad\n",
      "     |          tensor([-1.1007,  0.9853, -4.2316, -1.6606])\n",
      "     |  \n",
      "     |  reshape(...)\n",
      "     |      reshape(*shape) -> Tensor\n",
      "     |      \n",
      "     |      Returns a tensor with the same data and number of elements as :attr:`self`,\n",
      "     |      but with the specified shape.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          shape (tuple of ints or int...): the desired shape\n",
      "     |      \n",
      "     |      See :func:`torch.reshape`\n",
      "     |  \n",
      "     |  resize(self, *sizes)\n",
      "     |  \n",
      "     |  resize_(...)\n",
      "     |      resize_(*sizes) -> Tensor\n",
      "     |      \n",
      "     |      Resizes :attr:`self` tensor to the specified size. If the number of elements is\n",
      "     |      larger than the current storage size, then the underlying storage is resized\n",
      "     |      to fit the new number of elements. If the number of elements is smaller, the\n",
      "     |      underlying storage is not changed. Existing elements are preserved but any new\n",
      "     |      memory is uninitialized.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          sizes (torch.Size or int...): the desired size\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1, 2], [3, 4], [5, 6]])\n",
      "     |          >>> x.resize_(2, 2)\n",
      "     |          tensor([[ 1,  2],\n",
      "     |                  [ 3,  4]])\n",
      "     |  \n",
      "     |  resize_as(self, tensor)\n",
      "     |  \n",
      "     |  resize_as_(...)\n",
      "     |      resize_as_(tensor) -> Tensor\n",
      "     |      \n",
      "     |      Resizes the :attr:`self` tensor to be the same size as the specified\n",
      "     |      :attr:`tensor`. This is equivalent to ``self.resize_(tensor.size())``.\n",
      "     |  \n",
      "     |  retain_grad(self)\n",
      "     |      Enables .grad attribute for non-leaf Tensors.\n",
      "     |  \n",
      "     |  rfft(...)\n",
      "     |      rfft(signal_ndim, normalized=False, onesided=True) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.rfft`\n",
      "     |  \n",
      "     |  round(...)\n",
      "     |      round() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.round`\n",
      "     |  \n",
      "     |  round_(...)\n",
      "     |      round_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.round`\n",
      "     |  \n",
      "     |  rsqrt(...)\n",
      "     |      rsqrt() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.rsqrt`\n",
      "     |  \n",
      "     |  rsqrt_(...)\n",
      "     |      rsqrt_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.rsqrt`\n",
      "     |  \n",
      "     |  scatter(self, dim, index, source)\n",
      "     |  \n",
      "     |  scatter_(...)\n",
      "     |      scatter_(dim, index, src) -> Tensor\n",
      "     |      \n",
      "     |      Writes all values from the tensor :attr:`src` into :attr:`self` at the indices\n",
      "     |      specified in the :attr:`index` tensor. For each value in :attr:`src`, its output\n",
      "     |      index is specified by its index in :attr:`src` for dimension != :attr:`dim` and\n",
      "     |      by the corresponding value in :attr:`index` for dimension = :attr:`dim`.\n",
      "     |      \n",
      "     |      For a 3-D tensor, :attr:`self` is updated as::\n",
      "     |      \n",
      "     |          self[index[i][j][k]][j][k] = src[i][j][k]  # if dim == 0\n",
      "     |          self[i][index[i][j][k]][k] = src[i][j][k]  # if dim == 1\n",
      "     |          self[i][j][index[i][j][k]] = src[i][j][k]  # if dim == 2\n",
      "     |      \n",
      "     |      This is the reverse operation of the manner described in :meth:`~Tensor.gather`.\n",
      "     |      \n",
      "     |      :attr:`self`, :attr:`index` and :attr:`src` should have same number of\n",
      "     |      dimensions. It is also required that `index->size[d] <= src->size[d]` for all\n",
      "     |      dimension `d`, and that `index->size[d] <= real->size[d]` for all dimensions\n",
      "     |      `d != dim`.\n",
      "     |      \n",
      "     |      Moreover, as for :meth:`~Tensor.gather`, the values of :attr:`index` must be\n",
      "     |      between `0` and `(self.size(dim) -1)` inclusive, and all values in a row along\n",
      "     |      the specified dimension :attr:`dim` must be unique.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          input (Tensor): the source tensor\n",
      "     |          dim (int): the axis along which to index\n",
      "     |          index (LongTensor): the indices of elements to scatter\n",
      "     |          src (Tensor or float): the source element(s) to scatter\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.rand(2, 5)\n",
      "     |          >>> x\n",
      "     |          tensor([[ 0.3992,  0.2908,  0.9044,  0.4850,  0.6004],\n",
      "     |                  [ 0.5735,  0.9006,  0.6797,  0.4152,  0.1732]])\n",
      "     |          >>> torch.zeros(3, 5).scatter_(0, torch.tensor([[0, 1, 2, 0, 0], [2, 0, 0, 1, 2]]), x)\n",
      "     |          tensor([[ 0.3992,  0.9006,  0.6797,  0.4850,  0.6004],\n",
      "     |                  [ 0.0000,  0.2908,  0.0000,  0.4152,  0.0000],\n",
      "     |                  [ 0.5735,  0.0000,  0.9044,  0.0000,  0.1732]])\n",
      "     |      \n",
      "     |          >>> z = torch.zeros(2, 4).scatter_(1, torch.tensor([[2], [3]]), 1.23)\n",
      "     |          >>> z\n",
      "     |          tensor([[ 0.0000,  0.0000,  1.2300,  0.0000],\n",
      "     |                  [ 0.0000,  0.0000,  0.0000,  1.2300]])\n",
      "     |  \n",
      "     |  scatter_add(self, dim, index, source)\n",
      "     |  \n",
      "     |  scatter_add_(...)\n",
      "     |  \n",
      "     |  select(...)\n",
      "     |      select(dim, index) -> Tensor\n",
      "     |      \n",
      "     |      Slices the :attr:`self` tensor along the selected dimension at the given index.\n",
      "     |      This function returns a tensor with the given dimension removed.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the dimension to slice\n",
      "     |          index (int): the index to select with\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          :meth:`select` is equivalent to slicing. For example,\n",
      "     |          ``tensor.select(0, index)`` is equivalent to ``tensor[index]`` and\n",
      "     |          ``tensor.select(2, index)`` is equivalent to ``tensor[:,:,index]``.\n",
      "     |  \n",
      "     |  set_(...)\n",
      "     |      set_(source=None, storage_offset=0, size=None, stride=None) -> Tensor\n",
      "     |      \n",
      "     |      Sets the underlying storage, size, and strides. If :attr:`source` is a tensor,\n",
      "     |      :attr:`self` tensor will share the same storage and have the same size and\n",
      "     |      strides as :attr:`source`. Changes to elements in one tensor will be reflected\n",
      "     |      in the other.\n",
      "     |      \n",
      "     |      If :attr:`source` is a :class:`~torch.Storage`, the method sets the underlying\n",
      "     |      storage, offset, size, and stride.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          source (Tensor or Storage): the tensor or storage to use\n",
      "     |          storage_offset (int, optional): the offset in the storage\n",
      "     |          size (torch.Size, optional): the desired size. Defaults to the size of the source.\n",
      "     |          stride (tuple, optional): the desired stride. Defaults to C-contiguous strides.\n",
      "     |  \n",
      "     |  share_memory_(self)\n",
      "     |      Moves the underlying storage to shared memory.\n",
      "     |      \n",
      "     |      This is a no-op if the underlying storage is already in shared memory\n",
      "     |      and for CUDA tensors. Tensors in shared memory cannot be resized.\n",
      "     |  \n",
      "     |  short(...)\n",
      "     |      short() -> Tensor\n",
      "     |      \n",
      "     |      ``self.short()`` is equivalent to ``self.to(torch.int16)``. See :func:`to`.\n",
      "     |  \n",
      "     |  sigmoid(...)\n",
      "     |      sigmoid() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sigmoid`\n",
      "     |  \n",
      "     |  sigmoid_(...)\n",
      "     |      sigmoid_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sigmoid`\n",
      "     |  \n",
      "     |  sign(...)\n",
      "     |      sign() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sign`\n",
      "     |  \n",
      "     |  sign_(...)\n",
      "     |      sign_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sign`\n",
      "     |  \n",
      "     |  sin(...)\n",
      "     |      sin() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sin`\n",
      "     |  \n",
      "     |  sin_(...)\n",
      "     |      sin_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sin`\n",
      "     |  \n",
      "     |  sinh(...)\n",
      "     |      sinh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sinh`\n",
      "     |  \n",
      "     |  sinh_(...)\n",
      "     |      sinh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sinh`\n",
      "     |  \n",
      "     |  size(...)\n",
      "     |      size() -> torch.Size\n",
      "     |      \n",
      "     |      Returns the size of the :attr:`self` tensor. The returned value is a subclass of\n",
      "     |      :class:`tuple`.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> torch.empty(3, 4, 5).size()\n",
      "     |          torch.Size([3, 4, 5])\n",
      "     |  \n",
      "     |  slice(...)\n",
      "     |  \n",
      "     |  slogdet(...)\n",
      "     |      slogdet() -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.slogdet`\n",
      "     |  \n",
      "     |  smm(...)\n",
      "     |  \n",
      "     |  sort(...)\n",
      "     |      sort(dim=None, descending=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.sort`\n",
      "     |  \n",
      "     |  split(self, split_size, dim=0)\n",
      "     |      See :func:`torch.split`\n",
      "     |  \n",
      "     |  split_with_sizes(...)\n",
      "     |  \n",
      "     |  sqrt(...)\n",
      "     |      sqrt() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sqrt`\n",
      "     |  \n",
      "     |  sqrt_(...)\n",
      "     |      sqrt_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sqrt`\n",
      "     |  \n",
      "     |  squeeze(...)\n",
      "     |      squeeze(dim=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.squeeze`\n",
      "     |  \n",
      "     |  squeeze_(...)\n",
      "     |      squeeze_(dim=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.squeeze`\n",
      "     |  \n",
      "     |  sspaddmm(...)\n",
      "     |  \n",
      "     |  std(...)\n",
      "     |      std(dim=None, unbiased=True, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.std`\n",
      "     |  \n",
      "     |  stft(...)\n",
      "     |      stft(frame_length, hop, fft_size=None, return_onesided=True, window=None, pad_end=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.stft`\n",
      "     |  \n",
      "     |  storage(...)\n",
      "     |      storage() -> torch.Storage\n",
      "     |      \n",
      "     |      Returns the underlying storage\n",
      "     |  \n",
      "     |  storage_offset(...)\n",
      "     |      storage_offset() -> int\n",
      "     |      \n",
      "     |      Returns :attr:`self` tensor's offset in the underlying storage in terms of\n",
      "     |      number of storage elements (not bytes).\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([1, 2, 3, 4, 5])\n",
      "     |          >>> x.storage_offset()\n",
      "     |          0\n",
      "     |          >>> x[3:].storage_offset()\n",
      "     |          3\n",
      "     |  \n",
      "     |  storage_type(...)\n",
      "     |  \n",
      "     |  stride(...)\n",
      "     |      stride(dim) -> tuple or int\n",
      "     |      \n",
      "     |      Returns the stride of :attr:`self` tensor.\n",
      "     |      \n",
      "     |      Stride is the jump necessary to go from one element to the next one in the\n",
      "     |      specified dimension :attr:`dim`. A tuple of all strides is returned when no\n",
      "     |      argument is passed in. Otherwise, an integer value is returned as the stride in\n",
      "     |      the particular dimension :attr:`dim`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int, optional): the desired dimension in which stride is required\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1, 2, 3, 4, 5], [6, 7, 8, 9, 10]])\n",
      "     |          >>> x.stride()\n",
      "     |          (5, 1)\n",
      "     |          >>>x.stride(0)\n",
      "     |          5\n",
      "     |          >>> x.stride(-1)\n",
      "     |          1\n",
      "     |  \n",
      "     |  sub(...)\n",
      "     |      sub(value, other) -> Tensor\n",
      "     |      \n",
      "     |      Subtracts a scalar or tensor from :attr:`self` tensor. If both :attr:`value` and\n",
      "     |      :attr:`other` are specified, each element of :attr:`other` is scaled by\n",
      "     |      :attr:`value` before being used.\n",
      "     |      \n",
      "     |      When :attr:`other` is a tensor, the shape of :attr:`other` must be\n",
      "     |      :ref:`broadcastable <broadcasting-semantics>` with the shape of the underlying\n",
      "     |      tensor.\n",
      "     |  \n",
      "     |  sub_(...)\n",
      "     |      sub_(x) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sub`\n",
      "     |  \n",
      "     |  sum(...)\n",
      "     |      sum(dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sum`\n",
      "     |  \n",
      "     |  svd(...)\n",
      "     |      svd(some=True) -> (Tensor, Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.svd`\n",
      "     |  \n",
      "     |  symeig(...)\n",
      "     |      symeig(eigenvectors=False, upper=True) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.symeig`\n",
      "     |  \n",
      "     |  t(...)\n",
      "     |      t() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.t`\n",
      "     |  \n",
      "     |  t_(...)\n",
      "     |      t_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.t`\n",
      "     |  \n",
      "     |  take(...)\n",
      "     |      take(indices) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.take`\n",
      "     |  \n",
      "     |  tan(...)\n",
      "     |  \n",
      "     |  tan_(...)\n",
      "     |      tan_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.tan`\n",
      "     |  \n",
      "     |  tanh(...)\n",
      "     |      tanh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tanh`\n",
      "     |  \n",
      "     |  tanh_(...)\n",
      "     |      tanh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.tanh`\n",
      "     |  \n",
      "     |  to(...)\n",
      "     |      to(*args, **kwargs) -> Tensor\n",
      "     |      \n",
      "     |      Performs Tensor dtype and/or device conversion. A :class:`torch.dtype` and :class:`torch.device` are\n",
      "     |      inferred from the arguments of ``self.to(*args, **kwargs)``.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          If the ``self`` Tensor already\n",
      "     |          has the correct :class:`torch.dtype` and :class:`torch.device`, then ``self`` is returned.\n",
      "     |          Otherwise, the returned tensor is a copy of ``self`` with the desired\n",
      "     |          :class:`torch.dtype` and :class:`torch.device`.\n",
      "     |      \n",
      "     |      Here are the ways to call ``to``:\n",
      "     |      \n",
      "     |      .. function:: to(dtype) -> Tensor\n",
      "     |      \n",
      "     |          Returns a Tensor with the specified :attr:`dtype`\n",
      "     |      \n",
      "     |      .. function:: to(device, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |          Returns a Tensor with the specified :attr:`device` and (optional)\n",
      "     |          :attr:`dtype`. If :attr:`dtype` is ``None`` it is inferred to be ``self.dtype``.\n",
      "     |      \n",
      "     |      .. function:: to(other) -> Tensor\n",
      "     |      \n",
      "     |          Returns a Tensor with same :class:`torch.dtype` and :class:`torch.device` as the Tensor\n",
      "     |          :attr:`other`.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.randn(2, 2)  # Initially dtype=float32, device=cpu\n",
      "     |          >>> tensor.to(torch.float64)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], dtype=torch.float64)\n",
      "     |      \n",
      "     |          >>> cuda0 = torch.device('cuda:0')\n",
      "     |          >>> tensor.to(cuda0)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], device='cuda:0')\n",
      "     |      \n",
      "     |          >>> tensor.to(cuda0, dtype=torch.float64)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], dtype=torch.float64, device='cuda:0')\n",
      "     |      \n",
      "     |          >>> other = torch.randn((), dtype=torch.float64, device=cuda0)\n",
      "     |          >>> tensor.to(other)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], dtype=torch.float64, device='cuda:0')\n",
      "     |  \n",
      "     |  to_dense(...)\n",
      "     |  \n",
      "     |  tolist(...)\n",
      "     |  \n",
      "     |  topk(...)\n",
      "     |      topk(k, dim=None, largest=True, sorted=True) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.topk`\n",
      "     |  \n",
      "     |  trace(...)\n",
      "     |      trace() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.trace`\n",
      "     |  \n",
      "     |  transpose(...)\n",
      "     |      transpose(dim0, dim1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.transpose`\n",
      "     |  \n",
      "     |  transpose_(...)\n",
      "     |      transpose_(dim0, dim1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.transpose`\n",
      "     |  \n",
      "     |  tril(...)\n",
      "     |      tril(k=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tril`\n",
      "     |  \n",
      "     |  tril_(...)\n",
      "     |      tril_(k=0) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.tril`\n",
      "     |  \n",
      "     |  triu(...)\n",
      "     |      triu(k=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.triu`\n",
      "     |  \n",
      "     |  triu_(...)\n",
      "     |      triu_(k=0) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.triu`\n",
      "     |  \n",
      "     |  trtrs(...)\n",
      "     |      trtrs(A, upper=True, transpose=False, unitriangular=False) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.trtrs`\n",
      "     |  \n",
      "     |  trunc(...)\n",
      "     |      trunc() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.trunc`\n",
      "     |  \n",
      "     |  trunc_(...)\n",
      "     |      trunc_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.trunc`\n",
      "     |  \n",
      "     |  type(...)\n",
      "     |      type(dtype=None, non_blocking=False, **kwargs) -> str or Tensor\n",
      "     |      Returns the type if `dtype` is not provided, else casts this object to\n",
      "     |      the specified type.\n",
      "     |      \n",
      "     |      If this is already of the correct type, no copy is performed and the\n",
      "     |      original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (type or string): The desired type\n",
      "     |          non_blocking (bool): If ``True``, and the source is in pinned memory\n",
      "     |              and destination is on the GPU or vice versa, the copy is performed\n",
      "     |              asynchronously with respect to the host. Otherwise, the argument\n",
      "     |              has no effect.\n",
      "     |          **kwargs: For compatibility, may contain the key ``async`` in place of\n",
      "     |              the ``non_blocking`` argument. The ``async`` arg is deprecated.\n",
      "     |  \n",
      "     |  type_as(...)\n",
      "     |      type_as(tensor) -> Tensor\n",
      "     |      \n",
      "     |      Returns this tensor cast to the type of the given tensor.\n",
      "     |      \n",
      "     |      This is a no-op if the tensor is already of the correct type. This is\n",
      "     |      equivalent to::\n",
      "     |      \n",
      "     |          self.type(tensor.type())\n",
      "     |      \n",
      "     |      Params:\n",
      "     |          tensor (Tensor): the tensor which has the desired type\n",
      "     |  \n",
      "     |  unfold(...)\n",
      "     |      unfold(dim, size, step) -> Tensor\n",
      "     |      \n",
      "     |      Returns a tensor which contains all slices of size :attr:`size` from\n",
      "     |      :attr:`self` tensor in the dimension :attr:`dim`.\n",
      "     |      \n",
      "     |      Step between two slices is given by :attr:`step`.\n",
      "     |      \n",
      "     |      If `sizedim` is the size of dimension dim for :attr:`self`, the size of\n",
      "     |      dimension :attr:`dim` in the returned tensor will be\n",
      "     |      `(sizedim - size) / step + 1`.\n",
      "     |      \n",
      "     |      An additional dimension of size size is appended in the returned tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension in which unfolding happens\n",
      "     |          size (int): the size of each slice that is unfolded\n",
      "     |          step (int): the step between each slice\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.arange(1, 8)\n",
      "     |          >>> x\n",
      "     |          tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.])\n",
      "     |          >>> x.unfold(0, 2, 1)\n",
      "     |          tensor([[ 1.,  2.],\n",
      "     |                  [ 2.,  3.],\n",
      "     |                  [ 3.,  4.],\n",
      "     |                  [ 4.,  5.],\n",
      "     |                  [ 5.,  6.],\n",
      "     |                  [ 6.,  7.]])\n",
      "     |          >>> x.unfold(0, 2, 2)\n",
      "     |          tensor([[ 1.,  2.],\n",
      "     |                  [ 3.,  4.],\n",
      "     |                  [ 5.,  6.]])\n",
      "     |  \n",
      "     |  uniform_(...)\n",
      "     |      uniform_(from=0, to=1) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with numbers sampled from the continuous uniform\n",
      "     |      distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |          P(x) = \\dfrac{1}{\\text{to} - \\text{from}}\n",
      "     |  \n",
      "     |  unique(self, sorted=False, return_inverse=False)\n",
      "     |      Returns the unique scalar elements of the tensor as a 1-D tensor.\n",
      "     |      \n",
      "     |      See :func:`torch.unique`\n",
      "     |  \n",
      "     |  unsqueeze(...)\n",
      "     |      unsqueeze(dim) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.unsqueeze`\n",
      "     |  \n",
      "     |  unsqueeze_(...)\n",
      "     |      unsqueeze_(dim) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.unsqueeze`\n",
      "     |  \n",
      "     |  var(...)\n",
      "     |      var(dim=None, unbiased=True, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.var`\n",
      "     |  \n",
      "     |  view(...)\n",
      "     |      view(*args) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new tensor with the same data as the :attr:`self` tensor but of a\n",
      "     |      different size.\n",
      "     |      \n",
      "     |      The returned tensor shares the same data and must have the same number\n",
      "     |      of elements, but may have a different size. For a tensor to be viewed, the new\n",
      "     |      view size must be compatible with its original size and stride, i.e., each new\n",
      "     |      view dimension must either be a subspace of an original dimension, or only span\n",
      "     |      across original dimensions :math:`d, d+1, \\dots, d+k` that satisfy the following\n",
      "     |      contiguity-like condition that :math:`\\forall i = 0, \\dots, k-1`,\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |        stride[i] = stride[i+1] \\times size[i+1]\n",
      "     |      \n",
      "     |      Otherwise, :func:`contiguous` needs to be called before the tensor can be\n",
      "     |      viewed.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          args (torch.Size or int...): the desired size\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.randn(4, 4)\n",
      "     |          >>> x.size()\n",
      "     |          torch.Size([4, 4])\n",
      "     |          >>> y = x.view(16)\n",
      "     |          >>> y.size()\n",
      "     |          torch.Size([16])\n",
      "     |          >>> z = x.view(-1, 8)  # the size -1 is inferred from other dimensions\n",
      "     |          >>> z.size()\n",
      "     |          torch.Size([2, 8])\n",
      "     |  \n",
      "     |  view_as(self, tensor)\n",
      "     |      view_as(other) -> Tensor\n",
      "     |      \n",
      "     |      View this tensor as the same size as :attr:`other`.\n",
      "     |      ``self.view_as(other)`` is equivalent to ``self.view(other.size())``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          other (:class:`torch.Tensor`): The result tensor has the same size\n",
      "     |              as :attr:`other.size()`.\n",
      "     |  \n",
      "     |  where(...)\n",
      "     |      where(condition, y) -> Tensor\n",
      "     |      \n",
      "     |      ``self.where(condition, y)`` is equivalent to ``torch.where(condition, self, y)``.\n",
      "     |      See :func:`torch.where`\n",
      "     |  \n",
      "     |  zero_(...)\n",
      "     |      zero_() -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with zeros.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  data\n",
      "     |  \n",
      "     |  device\n",
      "     |  \n",
      "     |  grad\n",
      "     |  \n",
      "     |  grad_fn\n",
      "     |  \n",
      "     |  is_leaf\n",
      "     |  \n",
      "     |  name\n",
      "     |  \n",
      "     |  output_nr\n",
      "     |  \n",
      "     |  requires_grad\n",
      "     |  \n",
      "     |  shape\n",
      "     |  \n",
      "     |  volatile\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  dtype = torch.int8\n",
      "     |  \n",
      "     |  is_cuda = False\n",
      "     |  \n",
      "     |  is_sparse = False\n",
      "     |  \n",
      "     |  layout = torch.strided\n",
      "    \n",
      "    class CompiledFunction(pybind11_builtins.pybind11_object)\n",
      "     |  Method resolution order:\n",
      "     |      CompiledFunction\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __call__(...)\n",
      "     |      __call__(*args) -> object\n",
      "     |  \n",
      "     |  __init__(...)\n",
      "     |      __init__(self: torch._C.CompiledFunction, arg0: int, arg1: bool, arg2: bool, arg3: object, arg4: str) -> None\n",
      "     |  \n",
      "     |  clear_cache(...)\n",
      "     |      clear_cache(self: torch._C.CompiledFunction) -> None\n",
      "     |  \n",
      "     |  graph_for(...)\n",
      "     |      graph_for(*args) -> object\n",
      "     |  \n",
      "     |  has_trace_for(...)\n",
      "     |      has_trace_for(*args) -> bool\n",
      "     |  \n",
      "     |  jit_debug_info(...)\n",
      "     |      jit_debug_info(self: torch._C.CompiledFunction) -> str\n",
      "     |  \n",
      "     |  set_captured_vars(...)\n",
      "     |      set_captured_vars(self: torch._C.CompiledFunction, arg0: List[torch::autograd::Variable]) -> None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |  \n",
      "     |  enabled\n",
      "     |  \n",
      "     |  hits\n",
      "     |  \n",
      "     |  misses\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class DoubleStorage(torch._C.DoubleStorageBase, torch.storage._StorageBase)\n",
      "     |  Method resolution order:\n",
      "     |      DoubleStorage\n",
      "     |      torch._C.DoubleStorageBase\n",
      "     |      torch.storage._StorageBase\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch._C.DoubleStorageBase:\n",
      "     |  \n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |  \n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |  \n",
      "     |  __len__(self, /)\n",
      "     |      Return len(self).\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  __setitem__(self, key, value, /)\n",
      "     |      Set self[key] to value.\n",
      "     |  \n",
      "     |  copy_(...)\n",
      "     |  \n",
      "     |  data_ptr(...)\n",
      "     |  \n",
      "     |  element_size(...)\n",
      "     |  \n",
      "     |  fill_(...)\n",
      "     |  \n",
      "     |  is_pinned(...)\n",
      "     |  \n",
      "     |  is_shared(...)\n",
      "     |  \n",
      "     |  new(...)\n",
      "     |  \n",
      "     |  resize_(...)\n",
      "     |  \n",
      "     |  size(...)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from torch._C.DoubleStorageBase:\n",
      "     |  \n",
      "     |  from_buffer(...)\n",
      "     |  \n",
      "     |  from_file(...)\n",
      "     |      from_file(filename, shared=False, size=0) -> Storage\n",
      "     |      \n",
      "     |      If `shared` is `True`, then memory is shared between all processes.\n",
      "     |      All changes are written to the file. If `shared` is `False`, then the changes on\n",
      "     |      the storage do not affect the file.\n",
      "     |      \n",
      "     |      `size` is the number of elements in the storage. If `shared` is `False`,\n",
      "     |      then the file must contain at least `size * sizeof(Type)` bytes\n",
      "     |      (`Type` is the type of storage). If `shared` is `True` the file will be\n",
      "     |      created if needed.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          filename (str): file name to map\n",
      "     |          shared (bool): whether to share memory\n",
      "     |          size (int): number of elements in the storage\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.storage._StorageBase:\n",
      "     |  \n",
      "     |  __copy__(self)\n",
      "     |  \n",
      "     |  __deepcopy__(self, memo)\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      helper for pickle\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __sizeof__(self)\n",
      "     |      __sizeof__() -> int\n",
      "     |      size of object in memory, in bytes\n",
      "     |  \n",
      "     |  __str__(self)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  byte(self)\n",
      "     |      Casts this storage to byte type\n",
      "     |  \n",
      "     |  char(self)\n",
      "     |      Casts this storage to char type\n",
      "     |  \n",
      "     |  clone(self)\n",
      "     |      Returns a copy of this storage\n",
      "     |  \n",
      "     |  cpu(self)\n",
      "     |      Returns a CPU copy of this storage if it's not already on the CPU\n",
      "     |  \n",
      "     |  cuda = _cuda(self, device=None, non_blocking=False, **kwargs)\n",
      "     |      Returns a copy of this object in CUDA memory.\n",
      "     |      \n",
      "     |      If this object is already in CUDA memory and on the correct device, then\n",
      "     |      no copy is performed and the original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          device (int): The destination GPU id. Defaults to the current device.\n",
      "     |          non_blocking (bool): If ``True`` and the source is in pinned memory,\n",
      "     |              the copy will be asynchronous with respect to the host. Otherwise,\n",
      "     |              the argument has no effect.\n",
      "     |          **kwargs: For compatibility, may contain the key ``async`` in place of\n",
      "     |              the ``non_blocking`` argument.\n",
      "     |  \n",
      "     |  double(self)\n",
      "     |      Casts this storage to double type\n",
      "     |  \n",
      "     |  float(self)\n",
      "     |      Casts this storage to float type\n",
      "     |  \n",
      "     |  half(self)\n",
      "     |      Casts this storage to half type\n",
      "     |  \n",
      "     |  int(self)\n",
      "     |      Casts this storage to int type\n",
      "     |  \n",
      "     |  long(self)\n",
      "     |      Casts this storage to long type\n",
      "     |  \n",
      "     |  pin_memory(self)\n",
      "     |      Copies the storage to pinned memory, if it's not already pinned.\n",
      "     |  \n",
      "     |  share_memory_(self)\n",
      "     |      Moves the storage to shared memory.\n",
      "     |      \n",
      "     |      This is a no-op for storages already in shared memory and for CUDA\n",
      "     |      storages, which do not need to be moved for sharing across processes.\n",
      "     |      Storages in shared memory cannot be resized.\n",
      "     |      \n",
      "     |      Returns: self\n",
      "     |  \n",
      "     |  short(self)\n",
      "     |      Casts this storage to short type\n",
      "     |  \n",
      "     |  tolist(self)\n",
      "     |      Returns a list containing the elements of this storage\n",
      "     |  \n",
      "     |  type = _type(self, dtype=None, non_blocking=False, **kwargs)\n",
      "     |      Returns the type if `dtype` is not provided, else casts this object to\n",
      "     |      the specified type.\n",
      "     |      \n",
      "     |      If this is already of the correct type, no copy is performed and the\n",
      "     |      original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (type or string): The desired type\n",
      "     |          non_blocking (bool): If ``True``, and the source is in pinned memory\n",
      "     |              and destination is on the GPU or vice versa, the copy is performed\n",
      "     |              asynchronously with respect to the host. Otherwise, the argument\n",
      "     |              has no effect.\n",
      "     |          **kwargs: For compatibility, may contain the key ``async`` in place of\n",
      "     |              the ``non_blocking`` argument. The ``async`` arg is deprecated.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.storage._StorageBase:\n",
      "     |  \n",
      "     |  is_cuda = False\n",
      "     |  \n",
      "     |  is_sparse = False\n",
      "    \n",
      "    class DoubleTensor(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __abs__ = abs(...)\n",
      "     |  \n",
      "     |  __add__(...)\n",
      "     |  \n",
      "     |  __and__(...)\n",
      "     |  \n",
      "     |  __array__(self, dtype=None)\n",
      "     |      # Numpy array interface, to support `numpy.asarray(tensor) -> ndarray`\n",
      "     |  \n",
      "     |  __array_wrap__(self, array)\n",
      "     |      # Wrap Numpy array again in a suitable tensor when done, to support e.g.\n",
      "     |      # `numpy.sin(tensor) -> tensor` or `numpy.greater(tensor, 0) -> ByteTensor`\n",
      "     |  \n",
      "     |  __bool__(...)\n",
      "     |  \n",
      "     |  __deepcopy__(self, memo)\n",
      "     |  \n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |  \n",
      "     |  __dir__(self)\n",
      "     |      __dir__() -> list\n",
      "     |      default dir() implementation\n",
      "     |  \n",
      "     |  __div__(...)\n",
      "     |  \n",
      "     |  __eq__ = eq(...)\n",
      "     |  \n",
      "     |  __float__(...)\n",
      "     |  \n",
      "     |  __format__(self, format_spec)\n",
      "     |      default object formatter\n",
      "     |  \n",
      "     |  __ge__ = ge(...)\n",
      "     |  \n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |  \n",
      "     |  __gt__ = gt(...)\n",
      "     |  \n",
      "     |  __hash__(self)\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __iadd__(...)\n",
      "     |  \n",
      "     |  __iand__(...)\n",
      "     |  \n",
      "     |  __idiv__(...)\n",
      "     |  \n",
      "     |  __ilshift__(...)\n",
      "     |  \n",
      "     |  __imul__(...)\n",
      "     |  \n",
      "     |  __index__(...)\n",
      "     |  \n",
      "     |  __int__(...)\n",
      "     |  \n",
      "     |  __invert__(...)\n",
      "     |  \n",
      "     |  __ior__(...)\n",
      "     |  \n",
      "     |  __ipow__(self, other)\n",
      "     |  \n",
      "     |  __irshift__(...)\n",
      "     |  \n",
      "     |  __isub__(...)\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |  \n",
      "     |  __itruediv__ = __idiv__(...)\n",
      "     |  \n",
      "     |  __ixor__(...)\n",
      "     |  \n",
      "     |  __le__ = le(...)\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |      Return len(self).\n",
      "     |  \n",
      "     |  __long__(...)\n",
      "     |  \n",
      "     |  __lshift__(...)\n",
      "     |  \n",
      "     |  __lt__ = lt(...)\n",
      "     |  \n",
      "     |  __matmul__(...)\n",
      "     |  \n",
      "     |  __mod__(...)\n",
      "     |  \n",
      "     |  __mul__(...)\n",
      "     |  \n",
      "     |  __ne__ = ne(...)\n",
      "     |  \n",
      "     |  __neg__ = neg(...)\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from tensortype\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  __nonzero__(...)\n",
      "     |  \n",
      "     |  __or__(...)\n",
      "     |  \n",
      "     |  __pow__ = pow(...)\n",
      "     |  \n",
      "     |  __radd__(...)\n",
      "     |  \n",
      "     |  __rdiv__(self, other)\n",
      "     |  \n",
      "     |  __reduce_ex__(self, proto)\n",
      "     |      helper for pickle\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __rmul__(...)\n",
      "     |  \n",
      "     |  __rpow__(self, other)\n",
      "     |  \n",
      "     |  __rshift__(...)\n",
      "     |  \n",
      "     |  __rsub__(self, other)\n",
      "     |  \n",
      "     |  __rtruediv__ = __rdiv__(self, other)\n",
      "     |  \n",
      "     |  __setitem__(self, key, value, /)\n",
      "     |      Set self[key] to value.\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |  \n",
      "     |  __sub__(...)\n",
      "     |  \n",
      "     |  __truediv__(...)\n",
      "     |  \n",
      "     |  __xor__(...)\n",
      "     |  \n",
      "     |  abs(...)\n",
      "     |      abs() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.abs`\n",
      "     |  \n",
      "     |  abs_(...)\n",
      "     |      abs_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.abs`\n",
      "     |  \n",
      "     |  acos(...)\n",
      "     |      acos() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.acos`\n",
      "     |  \n",
      "     |  acos_(...)\n",
      "     |      acos_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.acos`\n",
      "     |  \n",
      "     |  add(...)\n",
      "     |      add(value) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.add`\n",
      "     |  \n",
      "     |  add_(...)\n",
      "     |      add_(value) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.add`\n",
      "     |  \n",
      "     |  addbmm(...)\n",
      "     |      addbmm(beta=1, mat, alpha=1, batch1, batch2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addbmm`\n",
      "     |  \n",
      "     |  addbmm_(...)\n",
      "     |      addbmm_(beta=1, mat, alpha=1, batch1, batch2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addbmm`\n",
      "     |  \n",
      "     |  addcdiv(...)\n",
      "     |      addcdiv(value=1, tensor1, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addcdiv`\n",
      "     |  \n",
      "     |  addcdiv_(...)\n",
      "     |      addcdiv_(value=1, tensor1, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addcdiv`\n",
      "     |  \n",
      "     |  addcmul(...)\n",
      "     |      addcmul(value=1, tensor1, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addcmul`\n",
      "     |  \n",
      "     |  addcmul_(...)\n",
      "     |      addcmul_(value=1, tensor1, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addcmul`\n",
      "     |  \n",
      "     |  addmm(...)\n",
      "     |      addmm(beta=1, mat, alpha=1, mat1, mat2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addmm`\n",
      "     |  \n",
      "     |  addmm_(...)\n",
      "     |      addmm_(beta=1, mat, alpha=1, mat1, mat2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addmm`\n",
      "     |  \n",
      "     |  addmv(...)\n",
      "     |      addmv(beta=1, tensor, alpha=1, mat, vec) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addmv`\n",
      "     |  \n",
      "     |  addmv_(...)\n",
      "     |      addmv_(beta=1, tensor, alpha=1, mat, vec) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addmv`\n",
      "     |  \n",
      "     |  addr(...)\n",
      "     |      addr(beta=1, alpha=1, vec1, vec2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addr`\n",
      "     |  \n",
      "     |  addr_(...)\n",
      "     |      addr_(beta=1, alpha=1, vec1, vec2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addr`\n",
      "     |  \n",
      "     |  all(...)\n",
      "     |      all() -> bool\n",
      "     |      \n",
      "     |      Returns ``True`` if all elements in the tensor are non-zero, ``False`` otherwise.\n",
      "     |  \n",
      "     |  allclose(...)\n",
      "     |  \n",
      "     |  any(...)\n",
      "     |      any() -> bool\n",
      "     |      \n",
      "     |      Returns ``True`` if any elements in the tensor are non-zero, ``False`` otherwise.\n",
      "     |  \n",
      "     |  apply_(...)\n",
      "     |      apply_(callable) -> Tensor\n",
      "     |      \n",
      "     |      Applies the function :attr:`callable` to each element in the tensor, replacing\n",
      "     |      each element with the value returned by :attr:`callable`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          This function only works with CPU tensors and should not be used in code\n",
      "     |          sections that require high performance.\n",
      "     |  \n",
      "     |  argmax(self, dim=None, keepdim=False)\n",
      "     |      See :func:`torch.argmax`\n",
      "     |  \n",
      "     |  argmin(self, dim=None, keepdim=False)\n",
      "     |      See :func:`torch.argmin`\n",
      "     |  \n",
      "     |  as_strided(...)\n",
      "     |  \n",
      "     |  as_strided_(...)\n",
      "     |  \n",
      "     |  asin(...)\n",
      "     |      asin() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.asin`\n",
      "     |  \n",
      "     |  asin_(...)\n",
      "     |      asin_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.asin`\n",
      "     |  \n",
      "     |  atan(...)\n",
      "     |      atan() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.atan`\n",
      "     |  \n",
      "     |  atan2(...)\n",
      "     |      atan2(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.atan2`\n",
      "     |  \n",
      "     |  atan2_(...)\n",
      "     |      atan2_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.atan2`\n",
      "     |  \n",
      "     |  atan_(...)\n",
      "     |      atan_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.atan`\n",
      "     |  \n",
      "     |  backward(self, gradient=None, retain_graph=None, create_graph=False)\n",
      "     |      Computes the gradient of current tensor w.r.t. graph leaves.\n",
      "     |      \n",
      "     |      The graph is differentiated using the chain rule. If the tensor is\n",
      "     |      non-scalar (i.e. its data has more than one element) and requires\n",
      "     |      gradient, the function additionally requires specifying ``gradient``.\n",
      "     |      It should be a tensor of matching type and location, that contains\n",
      "     |      the gradient of the differentiated function w.r.t. ``self``.\n",
      "     |      \n",
      "     |      This function accumulates gradients in the leaves - you might need to\n",
      "     |      zero them before calling it.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          gradient (Tensor or None): Gradient w.r.t. the\n",
      "     |              tensor. If it is a tensor, it will be automatically converted\n",
      "     |              to a Tensor that does not require grad unless ``create_graph`` is True.\n",
      "     |              None values can be specified for scalar Tensors or ones that\n",
      "     |              don't require grad. If a None value would be acceptable then\n",
      "     |              this argument is optional.\n",
      "     |          retain_graph (bool, optional): If ``False``, the graph used to compute\n",
      "     |              the grads will be freed. Note that in nearly all cases setting\n",
      "     |              this option to True is not needed and often can be worked around\n",
      "     |              in a much more efficient way. Defaults to the value of\n",
      "     |              ``create_graph``.\n",
      "     |          create_graph (bool, optional): If ``True``, graph of the derivative will\n",
      "     |              be constructed, allowing to compute higher order derivative\n",
      "     |              products. Defaults to ``False``.\n",
      "     |  \n",
      "     |  baddbmm(...)\n",
      "     |      baddbmm(beta=1, alpha=1, batch1, batch2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.baddbmm`\n",
      "     |  \n",
      "     |  baddbmm_(...)\n",
      "     |      baddbmm_(beta=1, alpha=1, batch1, batch2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.baddbmm`\n",
      "     |  \n",
      "     |  bernoulli(...)\n",
      "     |      bernoulli() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bernoulli`\n",
      "     |  \n",
      "     |  bernoulli_(...)\n",
      "     |      bernoulli_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.bernoulli`\n",
      "     |  \n",
      "     |  bmm(...)\n",
      "     |      bmm(batch2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bmm`\n",
      "     |  \n",
      "     |  btrifact(self, info=None, pivot=True)\n",
      "     |      See :func:`torch.btrifact`\n",
      "     |  \n",
      "     |  btrifact_with_info(...)\n",
      "     |      btrifact_with_info(pivot=True) -> (Tensor, Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.btrifact_with_info`\n",
      "     |  \n",
      "     |  btrisolve(...)\n",
      "     |  \n",
      "     |  byte(...)\n",
      "     |      byte() -> Tensor\n",
      "     |      \n",
      "     |      ``self.byte()`` is equivalent to ``self.to(torch.uint8)``. See :func:`to`.\n",
      "     |  \n",
      "     |  cauchy_(...)\n",
      "     |      cauchy_(median=0, sigma=1, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills the tensor with numbers drawn from the Cauchy distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(x) = \\dfrac{1}{\\pi} \\dfrac{\\sigma}{(x - median)^2 + \\sigma^2}\n",
      "     |  \n",
      "     |  ceil(...)\n",
      "     |      ceil() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ceil`\n",
      "     |  \n",
      "     |  ceil_(...)\n",
      "     |      ceil_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ceil`\n",
      "     |  \n",
      "     |  char(...)\n",
      "     |      char() -> Tensor\n",
      "     |      \n",
      "     |      ``self.char()`` is equivalent to ``self.to(torch.int8)``. See :func:`to`.\n",
      "     |  \n",
      "     |  chunk(...)\n",
      "     |      chunk(chunks, dim=0) -> List of Tensors\n",
      "     |      \n",
      "     |      See :func:`torch.chunk`\n",
      "     |  \n",
      "     |  clamp(...)\n",
      "     |      clamp(min, max) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.clamp`\n",
      "     |  \n",
      "     |  clamp_(...)\n",
      "     |      clamp_(min, max) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.clamp`\n",
      "     |  \n",
      "     |  clone(...)\n",
      "     |      clone() -> Tensor\n",
      "     |      \n",
      "     |      Returns a copy of the :attr:`self` tensor. The copy has the same size and data\n",
      "     |      type as :attr:`self`.\n",
      "     |  \n",
      "     |  coalesce(...)\n",
      "     |  \n",
      "     |  contiguous(...)\n",
      "     |      contiguous() -> Tensor\n",
      "     |      \n",
      "     |      Returns a contiguous tensor containing the same data as :attr:`self` tensor. If\n",
      "     |      :attr:`self` tensor is contiguous, this function returns the :attr:`self`\n",
      "     |      tensor.\n",
      "     |  \n",
      "     |  conv_tbc(...)\n",
      "     |  \n",
      "     |  copy_(...)\n",
      "     |      copy_(src, non_blocking=False) -> Tensor\n",
      "     |      \n",
      "     |      Copies the elements from :attr:`src` into :attr:`self` tensor and returns\n",
      "     |      :attr:`self`.\n",
      "     |      \n",
      "     |      The :attr:`src` tensor must be :ref:`broadcastable <broadcasting-semantics>`\n",
      "     |      with the :attr:`self` tensor. It may be of a different data type or reside on a\n",
      "     |      different device.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          src (Tensor): the source tensor to copy from\n",
      "     |          non_blocking (bool): if ``True`` and this copy is between CPU and GPU,\n",
      "     |              the copy may occur asynchronously with respect to the host. For other\n",
      "     |              cases, this argument has no effect.\n",
      "     |  \n",
      "     |  cos(...)\n",
      "     |      cos() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cos`\n",
      "     |  \n",
      "     |  cos_(...)\n",
      "     |      cos_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.cos`\n",
      "     |  \n",
      "     |  cosh(...)\n",
      "     |      cosh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cosh`\n",
      "     |  \n",
      "     |  cosh_(...)\n",
      "     |      cosh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.cosh`\n",
      "     |  \n",
      "     |  cpu(...)\n",
      "     |  \n",
      "     |  cross(...)\n",
      "     |      cross(other, dim=-1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cross`\n",
      "     |  \n",
      "     |  cuda(...)\n",
      "     |      cuda(device=None, non_blocking=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a copy of this object in CUDA memory.\n",
      "     |      \n",
      "     |      If this object is already in CUDA memory and on the correct device,\n",
      "     |      then no copy is performed and the original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          device (:class:`torch.device`): The destination GPU device.\n",
      "     |              Defaults to the current CUDA device.\n",
      "     |          non_blocking (bool): If ``True`` and the source is in pinned memory,\n",
      "     |              the copy will be asynchronous with respect to the host.\n",
      "     |              Otherwise, the argument has no effect. Default: ``False``.\n",
      "     |  \n",
      "     |  cumprod(...)\n",
      "     |      cumprod(dim) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cumprod`\n",
      "     |  \n",
      "     |  cumsum(...)\n",
      "     |      cumsum(dim) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cumsum`\n",
      "     |  \n",
      "     |  data_ptr(...)\n",
      "     |      data_ptr() -> int\n",
      "     |      \n",
      "     |      Returns the address of the first element of :attr:`self` tensor.\n",
      "     |  \n",
      "     |  det(...)\n",
      "     |      det() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.det`\n",
      "     |  \n",
      "     |  detach(...)\n",
      "     |      Returns a new Tensor, detached from the current graph.\n",
      "     |      \n",
      "     |      The result will never require gradient.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |        Returned Tensor uses the same data tensor as the original one.\n",
      "     |        In-place modifications on either of them will be seen, and may trigger\n",
      "     |        errors in correctness checks.\n",
      "     |  \n",
      "     |  detach_(...)\n",
      "     |      Detaches the Tensor from the graph that created it, making it a leaf.\n",
      "     |      Views cannot be detached in-place.\n",
      "     |  \n",
      "     |  diag(...)\n",
      "     |      diag(diagonal=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diag`\n",
      "     |  \n",
      "     |  digamma(...)\n",
      "     |  \n",
      "     |  digamma_(...)\n",
      "     |  \n",
      "     |  dim(...)\n",
      "     |      dim() -> int\n",
      "     |      \n",
      "     |      Returns the number of dimensions of :attr:`self` tensor.\n",
      "     |  \n",
      "     |  dist(...)\n",
      "     |      dist(other, p=2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.dist`\n",
      "     |  \n",
      "     |  div(...)\n",
      "     |      div(value) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.div`\n",
      "     |  \n",
      "     |  div_(...)\n",
      "     |      div_(value) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.div`\n",
      "     |  \n",
      "     |  dot(...)\n",
      "     |      dot(tensor2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.dot`\n",
      "     |  \n",
      "     |  double(...)\n",
      "     |      double() -> Tensor\n",
      "     |      \n",
      "     |      ``self.double()`` is equivalent to ``self.to(torch.float64)``. See :func:`to`.\n",
      "     |  \n",
      "     |  eig(...)\n",
      "     |      eig(eigenvectors=False) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.eig`\n",
      "     |  \n",
      "     |  element_size(...)\n",
      "     |      element_size() -> int\n",
      "     |      \n",
      "     |      Returns the size in bytes of an individual element.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> torch.tensor([]).element_size()\n",
      "     |          4\n",
      "     |          >>> torch.tensor([], dtype=torch.uint8).element_size()\n",
      "     |          1\n",
      "     |  \n",
      "     |  eq(...)\n",
      "     |      eq(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.eq`\n",
      "     |  \n",
      "     |  eq_(...)\n",
      "     |      eq_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.eq`\n",
      "     |  \n",
      "     |  equal(...)\n",
      "     |      equal(other) -> bool\n",
      "     |      \n",
      "     |      See :func:`torch.equal`\n",
      "     |  \n",
      "     |  erf(...)\n",
      "     |      erf() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.erf`\n",
      "     |  \n",
      "     |  erf_(...)\n",
      "     |  \n",
      "     |  erfinv(...)\n",
      "     |      erfinv() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.erfinv`\n",
      "     |  \n",
      "     |  erfinv_(...)\n",
      "     |  \n",
      "     |  exp(...)\n",
      "     |      exp() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.exp`\n",
      "     |  \n",
      "     |  exp_(...)\n",
      "     |      exp_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.exp`\n",
      "     |  \n",
      "     |  expand(...)\n",
      "     |      expand(*sizes) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new view of the :attr:`self` tensor with singleton dimensions expanded\n",
      "     |      to a larger size.\n",
      "     |      \n",
      "     |      Passing -1 as the size for a dimension means not changing the size of\n",
      "     |      that dimension.\n",
      "     |      \n",
      "     |      Tensor can be also expanded to a larger number of dimensions, and the\n",
      "     |      new ones will be appended at the front. For the new dimensions, the\n",
      "     |      size cannot be set to -1.\n",
      "     |      \n",
      "     |      Expanding a tensor does not allocate new memory, but only creates a\n",
      "     |      new view on the existing tensor where a dimension of size one is\n",
      "     |      expanded to a larger size by setting the ``stride`` to 0. Any dimension\n",
      "     |      of size 1 can be expanded to an arbitrary value without allocating new\n",
      "     |      memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *sizes (torch.Size or int...): the desired expanded size\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1], [2], [3]])\n",
      "     |          >>> x.size()\n",
      "     |          torch.Size([3, 1])\n",
      "     |          >>> x.expand(3, 4)\n",
      "     |          tensor([[ 1,  1,  1,  1],\n",
      "     |                  [ 2,  2,  2,  2],\n",
      "     |                  [ 3,  3,  3,  3]])\n",
      "     |          >>> x.expand(-1, 4)   # -1 means not changing the size of that dimension\n",
      "     |          tensor([[ 1,  1,  1,  1],\n",
      "     |                  [ 2,  2,  2,  2],\n",
      "     |                  [ 3,  3,  3,  3]])\n",
      "     |  \n",
      "     |  expand_as(self, tensor)\n",
      "     |  \n",
      "     |  expm1(...)\n",
      "     |      expm1() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.expm1`\n",
      "     |  \n",
      "     |  expm1_(...)\n",
      "     |      expm1_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.expm1`\n",
      "     |  \n",
      "     |  exponential_(...)\n",
      "     |      exponential_(lambd=1, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with elements drawn from the exponential distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(x) = \\lambda e^{-\\lambda x}\n",
      "     |  \n",
      "     |  fft(...)\n",
      "     |      fft(signal_ndim, normalized=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fft`\n",
      "     |  \n",
      "     |  fill_(...)\n",
      "     |      fill_(value) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with the specified value.\n",
      "     |  \n",
      "     |  float(...)\n",
      "     |      float() -> Tensor\n",
      "     |      \n",
      "     |      ``self.float()`` is equivalent to ``self.to(torch.float32)``. See :func:`to`.\n",
      "     |  \n",
      "     |  floor(...)\n",
      "     |      floor() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.floor`\n",
      "     |  \n",
      "     |  floor_(...)\n",
      "     |      floor_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.floor`\n",
      "     |  \n",
      "     |  fmod(...)\n",
      "     |      fmod(divisor) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fmod`\n",
      "     |  \n",
      "     |  fmod_(...)\n",
      "     |      fmod_(divisor) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.fmod`\n",
      "     |  \n",
      "     |  frac(...)\n",
      "     |      frac() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.frac`\n",
      "     |  \n",
      "     |  frac_(...)\n",
      "     |      frac_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.frac`\n",
      "     |  \n",
      "     |  gather(...)\n",
      "     |      gather(dim, index) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.gather`\n",
      "     |  \n",
      "     |  ge(...)\n",
      "     |      ge(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ge`\n",
      "     |  \n",
      "     |  ge_(...)\n",
      "     |      ge_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ge`\n",
      "     |  \n",
      "     |  gels(...)\n",
      "     |      gels(A) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.gels`\n",
      "     |  \n",
      "     |  geometric_(...)\n",
      "     |      geometric_(p, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with elements drawn from the geometric distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(X=k) = (1 - p)^{k - 1} p\n",
      "     |  \n",
      "     |  geqrf(...)\n",
      "     |      geqrf() -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.geqrf`\n",
      "     |  \n",
      "     |  ger(...)\n",
      "     |      ger(vec2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ger`\n",
      "     |  \n",
      "     |  gesv(...)\n",
      "     |      gesv(A) -> Tensor, Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.gesv`\n",
      "     |  \n",
      "     |  get_device(...)\n",
      "     |  \n",
      "     |  gt(...)\n",
      "     |      gt(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.gt`\n",
      "     |  \n",
      "     |  gt_(...)\n",
      "     |      gt_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.gt`\n",
      "     |  \n",
      "     |  half(...)\n",
      "     |      half() -> Tensor\n",
      "     |      \n",
      "     |      ``self.half()`` is equivalent to ``self.to(torch.float16)``. See :func:`to`.\n",
      "     |  \n",
      "     |  histc(...)\n",
      "     |      histc(bins=100, min=0, max=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.histc`\n",
      "     |  \n",
      "     |  ifft(...)\n",
      "     |      ifft(signal_ndim, normalized=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ifft`\n",
      "     |  \n",
      "     |  index(...)\n",
      "     |      index(m) -> Tensor\n",
      "     |      \n",
      "     |      Selects elements from :attr:`self` tensor using a binary mask or along a given\n",
      "     |      dimension. The expression ``tensor.index(m)`` is equivalent to ``tensor[m]``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          m (int or ByteTensor or slice): the dimension or mask used to select elements\n",
      "     |  \n",
      "     |  index_add(self, dim, index, tensor)\n",
      "     |  \n",
      "     |  index_add_(...)\n",
      "     |      index_add_(dim, index, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Accumulate the elements of :attr:`tensor` into the :attr:`self` tensor by adding\n",
      "     |      to the indices in the order given in :attr:`index`. For example, if ``dim == 0``\n",
      "     |      and ``index[i] == j``, then the ``i``\\ th row of :attr:`tensor` is added to the\n",
      "     |      ``j``\\ th row of :attr:`self`.\n",
      "     |      \n",
      "     |      The :attr:`dim`\\ th dimension of :attr:`tensor` must have the same size as the\n",
      "     |      length of :attr:`index` (which must be a vector), and all other dimensions must\n",
      "     |      match :attr:`self`, or an error will be raised.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension along which to index\n",
      "     |          index (LongTensor): indices of :attr:`tensor` to select from\n",
      "     |          tensor (Tensor): the tensor containing values to add\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.ones(5, 3)\n",
      "     |          >>> t = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
      "     |          >>> index = torch.tensor([0, 4, 2])\n",
      "     |          >>> x.index_add_(0, index, t)\n",
      "     |          tensor([[  2.,   3.,   4.],\n",
      "     |                  [  1.,   1.,   1.],\n",
      "     |                  [  8.,   9.,  10.],\n",
      "     |                  [  1.,   1.,   1.],\n",
      "     |                  [  5.,   6.,   7.]])\n",
      "     |  \n",
      "     |  index_copy(self, dim, index, tensor)\n",
      "     |  \n",
      "     |  index_copy_(...)\n",
      "     |      index_copy_(dim, index, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Copies the elements of :attr:`tensor` into the :attr:`self` tensor by selecting\n",
      "     |      the indices in the order given in :attr:`index`. For example, if ``dim == 0``\n",
      "     |      and ``index[i] == j``, then the ``i``\\ th row of :attr:`tensor` is copied to the\n",
      "     |      ``j``\\ th row of :attr:`self`.\n",
      "     |      \n",
      "     |      The :attr:`dim`\\ th dimension of :attr:`tensor` must have the same size as the\n",
      "     |      length of :attr:`index` (which must be a vector), and all other dimensions must\n",
      "     |      match :attr:`self`, or an error will be raised.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension along which to index\n",
      "     |          index (LongTensor): indices of :attr:`tensor` to select from\n",
      "     |          tensor (Tensor): the tensor containing values to copy\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.zeros(5, 3)\n",
      "     |          >>> t = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
      "     |          >>> index = torch.tensor([0, 4, 2])\n",
      "     |          >>> x.index_copy_(0, index, t)\n",
      "     |          tensor([[ 1.,  2.,  3.],\n",
      "     |                  [ 0.,  0.,  0.],\n",
      "     |                  [ 7.,  8.,  9.],\n",
      "     |                  [ 0.,  0.,  0.],\n",
      "     |                  [ 4.,  5.,  6.]])\n",
      "     |  \n",
      "     |  index_fill(self, dim, index, value)\n",
      "     |  \n",
      "     |  index_fill_(...)\n",
      "     |      index_fill_(dim, index, val) -> Tensor\n",
      "     |      \n",
      "     |      Fills the elements of the :attr:`self` tensor with value :attr:`val` by\n",
      "     |      selecting the indices in the order given in :attr:`index`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension along which to index\n",
      "     |          index (LongTensor): indices of :attr:`self` tensor to fill in\n",
      "     |          val (float): the value to fill with\n",
      "     |      \n",
      "     |      Example::\n",
      "     |          >>> x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
      "     |          >>> index = torch.tensor([0, 2])\n",
      "     |          >>> x.index_fill_(1, index, -1)\n",
      "     |          tensor([[-1.,  2., -1.],\n",
      "     |                  [-1.,  5., -1.],\n",
      "     |                  [-1.,  8., -1.]])\n",
      "     |  \n",
      "     |  index_put_(...)\n",
      "     |      index_put_(indices, value) -> Tensor\n",
      "     |      \n",
      "     |      Puts values from the tensor :attr:`value` into the tensor :attr:`self` using\n",
      "     |      the indices specified in :attr:`indices` (which is a tuple of Tensors). The\n",
      "     |      expression ``tensor.index_put_(indices, value)`` is equivalent to\n",
      "     |      ``tensor[indices] = value``. Returns :attr:`self`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          indices (tuple of LongTensor): tensors used to index into `self`.\n",
      "     |          value (Tensor): tensor of same dtype as `self`.\n",
      "     |  \n",
      "     |  index_select(...)\n",
      "     |      index_select(dim, index) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.index_select`\n",
      "     |  \n",
      "     |  int(...)\n",
      "     |      int() -> Tensor\n",
      "     |      \n",
      "     |      ``self.int()`` is equivalent to ``self.to(torch.int32)``. See :func:`to`.\n",
      "     |  \n",
      "     |  inverse(...)\n",
      "     |      inverse() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.inverse`\n",
      "     |  \n",
      "     |  irfft(...)\n",
      "     |      irfft(signal_ndim, normalized=False, onesided=True, signal_sizes=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.irfft`\n",
      "     |  \n",
      "     |  is_coalesced(...)\n",
      "     |  \n",
      "     |  is_contiguous(...)\n",
      "     |      is_contiguous() -> bool\n",
      "     |      \n",
      "     |      Returns True if :attr:`self` tensor is contiguous in memory in C order.\n",
      "     |  \n",
      "     |  is_distributed(...)\n",
      "     |  \n",
      "     |  is_floating_point(...)\n",
      "     |  \n",
      "     |  is_nonzero(...)\n",
      "     |  \n",
      "     |  is_pinned(self)\n",
      "     |      Returns true if this tensor resides in pinned memory\n",
      "     |  \n",
      "     |  is_same_size(...)\n",
      "     |  \n",
      "     |  is_set_to(...)\n",
      "     |      is_set_to(tensor) -> bool\n",
      "     |      \n",
      "     |      Returns True if this object refers to the same ``THTensor`` object from the\n",
      "     |      Torch C API as the given tensor.\n",
      "     |  \n",
      "     |  is_shared(self)\n",
      "     |      Checks if tensor is in shared memory.\n",
      "     |      \n",
      "     |      This is always ``True`` for CUDA tensors.\n",
      "     |  \n",
      "     |  is_signed(...)\n",
      "     |  \n",
      "     |  isclose(...)\n",
      "     |  \n",
      "     |  item(...)\n",
      "     |      item() -> number\n",
      "     |      \n",
      "     |      Returns the value of this tensor as a standard Python number. This only works\n",
      "     |      for tensors with one element.\n",
      "     |      \n",
      "     |      This operation is not differentiable.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([1.0])\n",
      "     |          >>> x.item()\n",
      "     |          1.0\n",
      "     |  \n",
      "     |  kthvalue(...)\n",
      "     |      kthvalue(k, dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.kthvalue`\n",
      "     |  \n",
      "     |  le(...)\n",
      "     |      le(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.le`\n",
      "     |  \n",
      "     |  le_(...)\n",
      "     |      le_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.le`\n",
      "     |  \n",
      "     |  lerp(...)\n",
      "     |      lerp(start, end, weight) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lerp`\n",
      "     |  \n",
      "     |  lerp_(...)\n",
      "     |      lerp_(start, end, weight) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lerp`\n",
      "     |  \n",
      "     |  lgamma(...)\n",
      "     |  \n",
      "     |  lgamma_(...)\n",
      "     |  \n",
      "     |  log(...)\n",
      "     |      log() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log`\n",
      "     |  \n",
      "     |  log10(...)\n",
      "     |      log10() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log10`\n",
      "     |  \n",
      "     |  log10_(...)\n",
      "     |      log10_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log10`\n",
      "     |  \n",
      "     |  log1p(...)\n",
      "     |      log1p() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log1p`\n",
      "     |  \n",
      "     |  log1p_(...)\n",
      "     |      log1p_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log1p`\n",
      "     |  \n",
      "     |  log2(...)\n",
      "     |      log2() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log2`\n",
      "     |  \n",
      "     |  log2_(...)\n",
      "     |      log2_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log2`\n",
      "     |  \n",
      "     |  log_(...)\n",
      "     |      log_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log`\n",
      "     |  \n",
      "     |  log_normal_(...)\n",
      "     |      log_normal_(mean=1, std=2, *, generator=None)\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with numbers samples from the log-normal distribution\n",
      "     |      parameterized by the given mean (µ) and standard deviation (σ).\n",
      "     |      Note that :attr:`mean` and :attr:`stdv` are the mean and standard deviation of\n",
      "     |      the underlying normal distribution, and not of the returned distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(x) = \\dfrac{1}{x \\sigma \\sqrt{2\\pi}}\\ e^{-\\dfrac{(\\ln x - \\mu)^2}{2\\sigma^2}}\n",
      "     |  \n",
      "     |  logdet(...)\n",
      "     |      logdet() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logdet`\n",
      "     |  \n",
      "     |  long(...)\n",
      "     |      long() -> Tensor\n",
      "     |      \n",
      "     |      ``self.long()`` is equivalent to ``self.to(torch.int64)``. See :func:`to`.\n",
      "     |  \n",
      "     |  lt(...)\n",
      "     |      lt(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lt`\n",
      "     |  \n",
      "     |  lt_(...)\n",
      "     |      lt_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lt`\n",
      "     |  \n",
      "     |  map2_(...)\n",
      "     |  \n",
      "     |  map_(...)\n",
      "     |      map_(tensor, callable)\n",
      "     |      \n",
      "     |      Applies :attr:`callable` for each element in :attr:`self` tensor and the given\n",
      "     |      :attr:`tensor` and stores the results in :attr:`self` tensor. :attr:`self` tensor and\n",
      "     |      the given :attr:`tensor` must be :ref:`broadcastable <broadcasting-semantics>`.\n",
      "     |      \n",
      "     |      The :attr:`callable` should have the signature::\n",
      "     |      \n",
      "     |          def callable(a, b) -> number\n",
      "     |  \n",
      "     |  masked_copy(self, mask, tensor)\n",
      "     |  \n",
      "     |  masked_copy_(self, mask, tensor)\n",
      "     |  \n",
      "     |  masked_fill(self, mask, value)\n",
      "     |  \n",
      "     |  masked_fill_(...)\n",
      "     |      masked_fill_(mask, value)\n",
      "     |      \n",
      "     |      Fills elements of :attr:`self` tensor with :attr:`value` where :attr:`mask` is\n",
      "     |      one. The shape of :attr:`mask` must be\n",
      "     |      :ref:`broadcastable <broadcasting-semantics>` with the shape of the underlying\n",
      "     |      tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          mask (ByteTensor): the binary mask\n",
      "     |          value (float): the value to fill in with\n",
      "     |  \n",
      "     |  masked_scatter(self, mask, tensor)\n",
      "     |  \n",
      "     |  masked_scatter_(...)\n",
      "     |      masked_scatter_(mask, source)\n",
      "     |      \n",
      "     |      Copies elements from :attr:`source` into :attr:`self` tensor at positions where\n",
      "     |      the :attr:`mask` is one.\n",
      "     |      The shape of :attr:`mask` must be :ref:`broadcastable <broadcasting-semantics>`\n",
      "     |      with the shape of the underlying tensor. The :attr:`source` should have at least\n",
      "     |      as many elements as the number of ones in :attr:`mask`\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          mask (ByteTensor): the binary mask\n",
      "     |          source (Tensor): the tensor to copy from\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The :attr:`mask` operates on the :attr:`self` tensor, not on the given\n",
      "     |          :attr:`source` tensor.\n",
      "     |  \n",
      "     |  masked_select(...)\n",
      "     |      masked_select(mask) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.masked_select`\n",
      "     |  \n",
      "     |  matmul(...)\n",
      "     |      matmul(tensor2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.matmul`\n",
      "     |  \n",
      "     |  max(...)\n",
      "     |      max(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.max`\n",
      "     |  \n",
      "     |  mean(...)\n",
      "     |      mean(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.mean`\n",
      "     |  \n",
      "     |  median(...)\n",
      "     |      median(dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.median`\n",
      "     |  \n",
      "     |  min(...)\n",
      "     |      min(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.min`\n",
      "     |  \n",
      "     |  mm(...)\n",
      "     |      mm(mat2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mm`\n",
      "     |  \n",
      "     |  mode(...)\n",
      "     |      mode(dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.mode`\n",
      "     |  \n",
      "     |  mul(...)\n",
      "     |      mul(value) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mul`\n",
      "     |  \n",
      "     |  mul_(...)\n",
      "     |      mul_(value)\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.mul`\n",
      "     |  \n",
      "     |  multinomial(...)\n",
      "     |      multinomial(num_samples, replacement=False, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.multinomial`\n",
      "     |  \n",
      "     |  mv(...)\n",
      "     |      mv(vec) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mv`\n",
      "     |  \n",
      "     |  narrow(...)\n",
      "     |      narrow(dimension, start, length) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new tensor that is a narrowed version of :attr:`self` tensor. The\n",
      "     |      dimension :attr:`dim` is narrowed from :attr:`start` to :attr:`start + length`. The\n",
      "     |      returned tensor and :attr:`self` tensor share the same underlying storage.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dimension (int): the dimension along which to narrow\n",
      "     |          start (int): the starting dimension\n",
      "     |          length (int): the distance to the ending dimension\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
      "     |          >>> x.narrow(0, 0, 2)\n",
      "     |          tensor([[ 1,  2,  3],\n",
      "     |                  [ 4,  5,  6]])\n",
      "     |          >>> x.narrow(1, 1, 2)\n",
      "     |          tensor([[ 2,  3],\n",
      "     |                  [ 5,  6],\n",
      "     |                  [ 8,  9]])\n",
      "     |  \n",
      "     |  ndimension(...)\n",
      "     |      ndimension() -> int\n",
      "     |      \n",
      "     |      Alias for :meth:`~Tensor.dim()`\n",
      "     |  \n",
      "     |  ne(...)\n",
      "     |      ne(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ne`\n",
      "     |  \n",
      "     |  ne_(...)\n",
      "     |      ne_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ne`\n",
      "     |  \n",
      "     |  neg(...)\n",
      "     |      neg() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.neg`\n",
      "     |  \n",
      "     |  neg_(...)\n",
      "     |      neg_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.neg`\n",
      "     |  \n",
      "     |  nelement(...)\n",
      "     |      nelement() -> int\n",
      "     |      \n",
      "     |      Alias for :meth:`~Tensor.numel`\n",
      "     |  \n",
      "     |  new(...)\n",
      "     |  \n",
      "     |  new_empty(...)\n",
      "     |      new_empty(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with uninitialized data.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones(())\n",
      "     |          >>> tensor.new_empty((2, 3))\n",
      "     |          tensor([[ 5.8182e-18,  4.5765e-41, -1.0545e+30],\n",
      "     |                  [ 3.0949e-41,  4.4842e-44,  0.0000e+00]])\n",
      "     |  \n",
      "     |  new_full(...)\n",
      "     |      new_full(size, fill_value, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with :attr:`fill_value`.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          fill_value (scalar): the number to fill the output tensor with.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones((2,), dtype=torch.float64)\n",
      "     |          >>> tensor.new_full((3, 4), 3.141592)\n",
      "     |          tensor([[ 3.1416,  3.1416,  3.1416,  3.1416],\n",
      "     |                  [ 3.1416,  3.1416,  3.1416,  3.1416],\n",
      "     |                  [ 3.1416,  3.1416,  3.1416,  3.1416]], dtype=torch.float64)\n",
      "     |  \n",
      "     |  new_ones(...)\n",
      "     |      new_ones(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with ``1``.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (int...): a list, tuple, or :class:`torch.Size` of integers defining the\n",
      "     |              shape of the output tensor.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.tensor((), dtype=torch.int32)\n",
      "     |          >>> tensor.new_ones((2, 3))\n",
      "     |          tensor([[ 1,  1,  1],\n",
      "     |                  [ 1,  1,  1]], dtype=torch.int32)\n",
      "     |  \n",
      "     |  new_tensor(...)\n",
      "     |      new_tensor(data, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new Tensor with :attr:`data` as the tensor data.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          :func:`new_tensor` always copies :attr:`data`. If you have a Tensor\n",
      "     |          ``data`` and want to avoid a copy, use :func:`torch.Tensor.requires_grad_`\n",
      "     |          or :func:`torch.Tensor.detach`.\n",
      "     |          If you have a numpy array and want to avoid a copy, use\n",
      "     |          :func:`torch.from_numpy`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          data (array_like): The returned Tensor copies :attr:`data`.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones((2,), dtype=torch.int8)\n",
      "     |          >>> data = [[0, 1], [2, 3]]\n",
      "     |          >>> tensor.new_tensor(data)\n",
      "     |          tensor([[ 0,  1],\n",
      "     |                  [ 2,  3]], dtype=torch.int8)\n",
      "     |  \n",
      "     |  new_zeros(...)\n",
      "     |      new_zeros(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with ``0``.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (int...): a list, tuple, or :class:`torch.Size` of integers defining the\n",
      "     |              shape of the output tensor.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.tensor((), dtype=torch.float64)\n",
      "     |          >>> tensor.new_ones((2, 3))\n",
      "     |          tensor([[ 1.,  1.,  1.],\n",
      "     |                  [ 1.,  1.,  1.]], dtype=torch.float64)\n",
      "     |  \n",
      "     |  nonzero(...)\n",
      "     |      nonzero() -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.nonzero`\n",
      "     |  \n",
      "     |  norm(...)\n",
      "     |      norm(p=2, dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.norm`\n",
      "     |  \n",
      "     |  normal_(...)\n",
      "     |      normal_(mean=0, std=1, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with elements samples from the normal distribution\n",
      "     |      parameterized by :attr:`mean` and :attr:`std`.\n",
      "     |  \n",
      "     |  numel(...)\n",
      "     |      numel() -> int\n",
      "     |      \n",
      "     |      See :func:`torch.numel`\n",
      "     |  \n",
      "     |  numpy(...)\n",
      "     |      numpy() -> numpy.ndarray\n",
      "     |      \n",
      "     |      Returns :attr:`self` tensor as a NumPy :class:`ndarray`. This tensor and the\n",
      "     |      returned :class:`ndarray` share the same underlying storage. Changes to\n",
      "     |      :attr:`self` tensor will be reflected in the :class:`ndarray` and vice versa.\n",
      "     |  \n",
      "     |  orgqr(...)\n",
      "     |      orgqr(input2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.orgqr`\n",
      "     |  \n",
      "     |  ormqr(...)\n",
      "     |      ormqr(input2, input3, left=True, transpose=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ormqr`\n",
      "     |  \n",
      "     |  permute(...)\n",
      "     |  \n",
      "     |  pin_memory(...)\n",
      "     |  \n",
      "     |  polygamma(...)\n",
      "     |  \n",
      "     |  polygamma_(...)\n",
      "     |  \n",
      "     |  potrf(...)\n",
      "     |      potrf(upper=True) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.potrf`\n",
      "     |  \n",
      "     |  potri(...)\n",
      "     |      potri(upper=True) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.potri`\n",
      "     |  \n",
      "     |  potrs(...)\n",
      "     |      potrs(input2, upper=True) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.potrs`\n",
      "     |  \n",
      "     |  pow(...)\n",
      "     |      pow(exponent) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.pow`\n",
      "     |  \n",
      "     |  pow_(...)\n",
      "     |      pow_(exponent) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.pow`\n",
      "     |  \n",
      "     |  prod(...)\n",
      "     |      prod(dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.prod`\n",
      "     |  \n",
      "     |  pstrf(...)\n",
      "     |      pstrf(upper=True, tol=-1) -> (Tensor, IntTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.pstrf`\n",
      "     |  \n",
      "     |  put_(...)\n",
      "     |      put_(indices, tensor, accumulate=False) -> Tensor\n",
      "     |      \n",
      "     |      Copies the elements from :attr:`tensor` into the positions specified by\n",
      "     |      indices. For the purpose of indexing, the :attr:`self` tensor is treated as if\n",
      "     |      it were a 1-D tensor.\n",
      "     |      \n",
      "     |      If :attr:`accumulate` is ``True``, the elements in :attr:`tensor` are added to\n",
      "     |      :attr:`self`. If accumulate is ``False``, the behavior is undefined if indices\n",
      "     |      contain duplicate elements.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          indices (LongTensor): the indices into self\n",
      "     |          tensor (Tensor): the tensor containing values to copy from\n",
      "     |          accumulate (bool): whether to accumulate into self\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> src = torch.tensor([[4, 3, 5],\n",
      "     |                                  [6, 7, 8]])\n",
      "     |          >>> src.put_(torch.tensor([1, 3]), torch.tensor([9, 10]))\n",
      "     |          tensor([[  4,   9,   5],\n",
      "     |                  [ 10,   7,   8]])\n",
      "     |  \n",
      "     |  qr(...)\n",
      "     |      qr() -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.qr`\n",
      "     |  \n",
      "     |  random_(...)\n",
      "     |      random_(from=0, to=None, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with numbers sampled from the discrete uniform\n",
      "     |      distribution over ``[from, to - 1]``. If not specified, the values are usually\n",
      "     |      only bounded by :attr:`self` tensor's data type. However, for floating point\n",
      "     |      types, if unspecified, range will be ``[0, 2^mantissa]`` to ensure that every\n",
      "     |      value is representable. For example, `torch.tensor(1, dtype=torch.double).random_()`\n",
      "     |      will be uniform in ``[0, 2^53]``.\n",
      "     |  \n",
      "     |  reciprocal(...)\n",
      "     |      reciprocal() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.reciprocal`\n",
      "     |  \n",
      "     |  reciprocal_(...)\n",
      "     |      reciprocal_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.reciprocal`\n",
      "     |  \n",
      "     |  record_stream(...)\n",
      "     |  \n",
      "     |  register_hook(self, hook)\n",
      "     |      Registers a backward hook.\n",
      "     |      \n",
      "     |      The hook will be called every time a gradient with respect to the\n",
      "     |      Tensor is computed. The hook should have the following signature::\n",
      "     |      \n",
      "     |          hook(grad) -> Tensor or None\n",
      "     |      \n",
      "     |      The hook should not modify its argument, but it can optionally return\n",
      "     |      a new gradient which will be used in place of :attr:`grad`.\n",
      "     |      \n",
      "     |      This function returns a handle with a method ``handle.remove()``\n",
      "     |      that removes the hook from the module.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          >>> v = torch.tensor([0., 0., 0.], requires_grad=True)\n",
      "     |          >>> h = v.register_hook(lambda grad: grad * 2)  # double the gradient\n",
      "     |          >>> v.backward(torch.tensor([1., 2., 3.]))\n",
      "     |          >>> v.grad\n",
      "     |      \n",
      "     |           2\n",
      "     |           4\n",
      "     |           6\n",
      "     |          [torch.FloatTensor of size (3,)]\n",
      "     |      \n",
      "     |          >>> h.remove()  # removes the hook\n",
      "     |  \n",
      "     |  reinforce(self, reward)\n",
      "     |  \n",
      "     |  relu(...)\n",
      "     |  \n",
      "     |  relu_(...)\n",
      "     |  \n",
      "     |  remainder(...)\n",
      "     |      remainder(divisor) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.remainder`\n",
      "     |  \n",
      "     |  remainder_(...)\n",
      "     |      remainder_(divisor) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.remainder`\n",
      "     |  \n",
      "     |  renorm(...)\n",
      "     |      renorm(p, dim, maxnorm) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.renorm`\n",
      "     |  \n",
      "     |  renorm_(...)\n",
      "     |      renorm_(p, dim, maxnorm) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.renorm`\n",
      "     |  \n",
      "     |  repeat(...)\n",
      "     |      repeat(*sizes) -> Tensor\n",
      "     |      \n",
      "     |      Repeats this tensor along the specified dimensions.\n",
      "     |      \n",
      "     |      Unlike :meth:`~Tensor.expand`, this function copies the tensor's data.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          sizes (torch.Size or int...): The number of times to repeat this tensor along each\n",
      "     |              dimension\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([1, 2, 3])\n",
      "     |          >>> x.repeat(4, 2)\n",
      "     |          tensor([[ 1,  2,  3,  1,  2,  3],\n",
      "     |                  [ 1,  2,  3,  1,  2,  3],\n",
      "     |                  [ 1,  2,  3,  1,  2,  3],\n",
      "     |                  [ 1,  2,  3,  1,  2,  3]])\n",
      "     |          >>> x.repeat(4, 2, 1).size()\n",
      "     |          torch.Size([4, 2, 3])\n",
      "     |  \n",
      "     |  requires_grad_(...)\n",
      "     |      requires_grad_(requires_grad=True) -> Tensor\n",
      "     |      \n",
      "     |      Change if autograd should record operations on this tensor: sets this tensor's\n",
      "     |      :attr:`requires_grad` attribute in-place. Returns this tensor.\n",
      "     |      \n",
      "     |      :func:`require_grad_`'s main use case is to tell autograd to begin recording\n",
      "     |      operations on a Tensor ``tensor``. If ``tensor`` has ``requires_grad=False``\n",
      "     |      (because it was obtained through a DataLoader, or required preprocessing or\n",
      "     |      initialization), ``tensor.requires_grad_()`` makes it so that autograd will\n",
      "     |      begin to record operations on ``tensor``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          requires_grad (bool): If autograd should record operations on this tensor.\n",
      "     |              Default: ``True``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> # Let's say we want to preprocess some saved weights and use\n",
      "     |          >>> # the result as new weights.\n",
      "     |          >>> saved_weights = [0.1, 0.2, 0.3, 0.25]\n",
      "     |          >>> loaded_weights = torch.tensor(saved_weights)\n",
      "     |          >>> weights = preprocess(loaded_weights)  # some function\n",
      "     |          >>> weights\n",
      "     |          tensor([-0.5503,  0.4926, -2.1158, -0.8303])\n",
      "     |      \n",
      "     |          >>> # Now, start to record operations done to weights\n",
      "     |          >>> weights.requires_grad_()\n",
      "     |          >>> out = weights.pow(2).sum()\n",
      "     |          >>> out.backward()\n",
      "     |          >>> weights.grad\n",
      "     |          tensor([-1.1007,  0.9853, -4.2316, -1.6606])\n",
      "     |  \n",
      "     |  reshape(...)\n",
      "     |      reshape(*shape) -> Tensor\n",
      "     |      \n",
      "     |      Returns a tensor with the same data and number of elements as :attr:`self`,\n",
      "     |      but with the specified shape.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          shape (tuple of ints or int...): the desired shape\n",
      "     |      \n",
      "     |      See :func:`torch.reshape`\n",
      "     |  \n",
      "     |  resize(self, *sizes)\n",
      "     |  \n",
      "     |  resize_(...)\n",
      "     |      resize_(*sizes) -> Tensor\n",
      "     |      \n",
      "     |      Resizes :attr:`self` tensor to the specified size. If the number of elements is\n",
      "     |      larger than the current storage size, then the underlying storage is resized\n",
      "     |      to fit the new number of elements. If the number of elements is smaller, the\n",
      "     |      underlying storage is not changed. Existing elements are preserved but any new\n",
      "     |      memory is uninitialized.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          sizes (torch.Size or int...): the desired size\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1, 2], [3, 4], [5, 6]])\n",
      "     |          >>> x.resize_(2, 2)\n",
      "     |          tensor([[ 1,  2],\n",
      "     |                  [ 3,  4]])\n",
      "     |  \n",
      "     |  resize_as(self, tensor)\n",
      "     |  \n",
      "     |  resize_as_(...)\n",
      "     |      resize_as_(tensor) -> Tensor\n",
      "     |      \n",
      "     |      Resizes the :attr:`self` tensor to be the same size as the specified\n",
      "     |      :attr:`tensor`. This is equivalent to ``self.resize_(tensor.size())``.\n",
      "     |  \n",
      "     |  retain_grad(self)\n",
      "     |      Enables .grad attribute for non-leaf Tensors.\n",
      "     |  \n",
      "     |  rfft(...)\n",
      "     |      rfft(signal_ndim, normalized=False, onesided=True) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.rfft`\n",
      "     |  \n",
      "     |  round(...)\n",
      "     |      round() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.round`\n",
      "     |  \n",
      "     |  round_(...)\n",
      "     |      round_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.round`\n",
      "     |  \n",
      "     |  rsqrt(...)\n",
      "     |      rsqrt() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.rsqrt`\n",
      "     |  \n",
      "     |  rsqrt_(...)\n",
      "     |      rsqrt_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.rsqrt`\n",
      "     |  \n",
      "     |  scatter(self, dim, index, source)\n",
      "     |  \n",
      "     |  scatter_(...)\n",
      "     |      scatter_(dim, index, src) -> Tensor\n",
      "     |      \n",
      "     |      Writes all values from the tensor :attr:`src` into :attr:`self` at the indices\n",
      "     |      specified in the :attr:`index` tensor. For each value in :attr:`src`, its output\n",
      "     |      index is specified by its index in :attr:`src` for dimension != :attr:`dim` and\n",
      "     |      by the corresponding value in :attr:`index` for dimension = :attr:`dim`.\n",
      "     |      \n",
      "     |      For a 3-D tensor, :attr:`self` is updated as::\n",
      "     |      \n",
      "     |          self[index[i][j][k]][j][k] = src[i][j][k]  # if dim == 0\n",
      "     |          self[i][index[i][j][k]][k] = src[i][j][k]  # if dim == 1\n",
      "     |          self[i][j][index[i][j][k]] = src[i][j][k]  # if dim == 2\n",
      "     |      \n",
      "     |      This is the reverse operation of the manner described in :meth:`~Tensor.gather`.\n",
      "     |      \n",
      "     |      :attr:`self`, :attr:`index` and :attr:`src` should have same number of\n",
      "     |      dimensions. It is also required that `index->size[d] <= src->size[d]` for all\n",
      "     |      dimension `d`, and that `index->size[d] <= real->size[d]` for all dimensions\n",
      "     |      `d != dim`.\n",
      "     |      \n",
      "     |      Moreover, as for :meth:`~Tensor.gather`, the values of :attr:`index` must be\n",
      "     |      between `0` and `(self.size(dim) -1)` inclusive, and all values in a row along\n",
      "     |      the specified dimension :attr:`dim` must be unique.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          input (Tensor): the source tensor\n",
      "     |          dim (int): the axis along which to index\n",
      "     |          index (LongTensor): the indices of elements to scatter\n",
      "     |          src (Tensor or float): the source element(s) to scatter\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.rand(2, 5)\n",
      "     |          >>> x\n",
      "     |          tensor([[ 0.3992,  0.2908,  0.9044,  0.4850,  0.6004],\n",
      "     |                  [ 0.5735,  0.9006,  0.6797,  0.4152,  0.1732]])\n",
      "     |          >>> torch.zeros(3, 5).scatter_(0, torch.tensor([[0, 1, 2, 0, 0], [2, 0, 0, 1, 2]]), x)\n",
      "     |          tensor([[ 0.3992,  0.9006,  0.6797,  0.4850,  0.6004],\n",
      "     |                  [ 0.0000,  0.2908,  0.0000,  0.4152,  0.0000],\n",
      "     |                  [ 0.5735,  0.0000,  0.9044,  0.0000,  0.1732]])\n",
      "     |      \n",
      "     |          >>> z = torch.zeros(2, 4).scatter_(1, torch.tensor([[2], [3]]), 1.23)\n",
      "     |          >>> z\n",
      "     |          tensor([[ 0.0000,  0.0000,  1.2300,  0.0000],\n",
      "     |                  [ 0.0000,  0.0000,  0.0000,  1.2300]])\n",
      "     |  \n",
      "     |  scatter_add(self, dim, index, source)\n",
      "     |  \n",
      "     |  scatter_add_(...)\n",
      "     |  \n",
      "     |  select(...)\n",
      "     |      select(dim, index) -> Tensor\n",
      "     |      \n",
      "     |      Slices the :attr:`self` tensor along the selected dimension at the given index.\n",
      "     |      This function returns a tensor with the given dimension removed.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the dimension to slice\n",
      "     |          index (int): the index to select with\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          :meth:`select` is equivalent to slicing. For example,\n",
      "     |          ``tensor.select(0, index)`` is equivalent to ``tensor[index]`` and\n",
      "     |          ``tensor.select(2, index)`` is equivalent to ``tensor[:,:,index]``.\n",
      "     |  \n",
      "     |  set_(...)\n",
      "     |      set_(source=None, storage_offset=0, size=None, stride=None) -> Tensor\n",
      "     |      \n",
      "     |      Sets the underlying storage, size, and strides. If :attr:`source` is a tensor,\n",
      "     |      :attr:`self` tensor will share the same storage and have the same size and\n",
      "     |      strides as :attr:`source`. Changes to elements in one tensor will be reflected\n",
      "     |      in the other.\n",
      "     |      \n",
      "     |      If :attr:`source` is a :class:`~torch.Storage`, the method sets the underlying\n",
      "     |      storage, offset, size, and stride.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          source (Tensor or Storage): the tensor or storage to use\n",
      "     |          storage_offset (int, optional): the offset in the storage\n",
      "     |          size (torch.Size, optional): the desired size. Defaults to the size of the source.\n",
      "     |          stride (tuple, optional): the desired stride. Defaults to C-contiguous strides.\n",
      "     |  \n",
      "     |  share_memory_(self)\n",
      "     |      Moves the underlying storage to shared memory.\n",
      "     |      \n",
      "     |      This is a no-op if the underlying storage is already in shared memory\n",
      "     |      and for CUDA tensors. Tensors in shared memory cannot be resized.\n",
      "     |  \n",
      "     |  short(...)\n",
      "     |      short() -> Tensor\n",
      "     |      \n",
      "     |      ``self.short()`` is equivalent to ``self.to(torch.int16)``. See :func:`to`.\n",
      "     |  \n",
      "     |  sigmoid(...)\n",
      "     |      sigmoid() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sigmoid`\n",
      "     |  \n",
      "     |  sigmoid_(...)\n",
      "     |      sigmoid_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sigmoid`\n",
      "     |  \n",
      "     |  sign(...)\n",
      "     |      sign() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sign`\n",
      "     |  \n",
      "     |  sign_(...)\n",
      "     |      sign_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sign`\n",
      "     |  \n",
      "     |  sin(...)\n",
      "     |      sin() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sin`\n",
      "     |  \n",
      "     |  sin_(...)\n",
      "     |      sin_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sin`\n",
      "     |  \n",
      "     |  sinh(...)\n",
      "     |      sinh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sinh`\n",
      "     |  \n",
      "     |  sinh_(...)\n",
      "     |      sinh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sinh`\n",
      "     |  \n",
      "     |  size(...)\n",
      "     |      size() -> torch.Size\n",
      "     |      \n",
      "     |      Returns the size of the :attr:`self` tensor. The returned value is a subclass of\n",
      "     |      :class:`tuple`.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> torch.empty(3, 4, 5).size()\n",
      "     |          torch.Size([3, 4, 5])\n",
      "     |  \n",
      "     |  slice(...)\n",
      "     |  \n",
      "     |  slogdet(...)\n",
      "     |      slogdet() -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.slogdet`\n",
      "     |  \n",
      "     |  smm(...)\n",
      "     |  \n",
      "     |  sort(...)\n",
      "     |      sort(dim=None, descending=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.sort`\n",
      "     |  \n",
      "     |  split(self, split_size, dim=0)\n",
      "     |      See :func:`torch.split`\n",
      "     |  \n",
      "     |  split_with_sizes(...)\n",
      "     |  \n",
      "     |  sqrt(...)\n",
      "     |      sqrt() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sqrt`\n",
      "     |  \n",
      "     |  sqrt_(...)\n",
      "     |      sqrt_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sqrt`\n",
      "     |  \n",
      "     |  squeeze(...)\n",
      "     |      squeeze(dim=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.squeeze`\n",
      "     |  \n",
      "     |  squeeze_(...)\n",
      "     |      squeeze_(dim=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.squeeze`\n",
      "     |  \n",
      "     |  sspaddmm(...)\n",
      "     |  \n",
      "     |  std(...)\n",
      "     |      std(dim=None, unbiased=True, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.std`\n",
      "     |  \n",
      "     |  stft(...)\n",
      "     |      stft(frame_length, hop, fft_size=None, return_onesided=True, window=None, pad_end=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.stft`\n",
      "     |  \n",
      "     |  storage(...)\n",
      "     |      storage() -> torch.Storage\n",
      "     |      \n",
      "     |      Returns the underlying storage\n",
      "     |  \n",
      "     |  storage_offset(...)\n",
      "     |      storage_offset() -> int\n",
      "     |      \n",
      "     |      Returns :attr:`self` tensor's offset in the underlying storage in terms of\n",
      "     |      number of storage elements (not bytes).\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([1, 2, 3, 4, 5])\n",
      "     |          >>> x.storage_offset()\n",
      "     |          0\n",
      "     |          >>> x[3:].storage_offset()\n",
      "     |          3\n",
      "     |  \n",
      "     |  storage_type(...)\n",
      "     |  \n",
      "     |  stride(...)\n",
      "     |      stride(dim) -> tuple or int\n",
      "     |      \n",
      "     |      Returns the stride of :attr:`self` tensor.\n",
      "     |      \n",
      "     |      Stride is the jump necessary to go from one element to the next one in the\n",
      "     |      specified dimension :attr:`dim`. A tuple of all strides is returned when no\n",
      "     |      argument is passed in. Otherwise, an integer value is returned as the stride in\n",
      "     |      the particular dimension :attr:`dim`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int, optional): the desired dimension in which stride is required\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1, 2, 3, 4, 5], [6, 7, 8, 9, 10]])\n",
      "     |          >>> x.stride()\n",
      "     |          (5, 1)\n",
      "     |          >>>x.stride(0)\n",
      "     |          5\n",
      "     |          >>> x.stride(-1)\n",
      "     |          1\n",
      "     |  \n",
      "     |  sub(...)\n",
      "     |      sub(value, other) -> Tensor\n",
      "     |      \n",
      "     |      Subtracts a scalar or tensor from :attr:`self` tensor. If both :attr:`value` and\n",
      "     |      :attr:`other` are specified, each element of :attr:`other` is scaled by\n",
      "     |      :attr:`value` before being used.\n",
      "     |      \n",
      "     |      When :attr:`other` is a tensor, the shape of :attr:`other` must be\n",
      "     |      :ref:`broadcastable <broadcasting-semantics>` with the shape of the underlying\n",
      "     |      tensor.\n",
      "     |  \n",
      "     |  sub_(...)\n",
      "     |      sub_(x) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sub`\n",
      "     |  \n",
      "     |  sum(...)\n",
      "     |      sum(dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sum`\n",
      "     |  \n",
      "     |  svd(...)\n",
      "     |      svd(some=True) -> (Tensor, Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.svd`\n",
      "     |  \n",
      "     |  symeig(...)\n",
      "     |      symeig(eigenvectors=False, upper=True) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.symeig`\n",
      "     |  \n",
      "     |  t(...)\n",
      "     |      t() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.t`\n",
      "     |  \n",
      "     |  t_(...)\n",
      "     |      t_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.t`\n",
      "     |  \n",
      "     |  take(...)\n",
      "     |      take(indices) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.take`\n",
      "     |  \n",
      "     |  tan(...)\n",
      "     |  \n",
      "     |  tan_(...)\n",
      "     |      tan_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.tan`\n",
      "     |  \n",
      "     |  tanh(...)\n",
      "     |      tanh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tanh`\n",
      "     |  \n",
      "     |  tanh_(...)\n",
      "     |      tanh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.tanh`\n",
      "     |  \n",
      "     |  to(...)\n",
      "     |      to(*args, **kwargs) -> Tensor\n",
      "     |      \n",
      "     |      Performs Tensor dtype and/or device conversion. A :class:`torch.dtype` and :class:`torch.device` are\n",
      "     |      inferred from the arguments of ``self.to(*args, **kwargs)``.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          If the ``self`` Tensor already\n",
      "     |          has the correct :class:`torch.dtype` and :class:`torch.device`, then ``self`` is returned.\n",
      "     |          Otherwise, the returned tensor is a copy of ``self`` with the desired\n",
      "     |          :class:`torch.dtype` and :class:`torch.device`.\n",
      "     |      \n",
      "     |      Here are the ways to call ``to``:\n",
      "     |      \n",
      "     |      .. function:: to(dtype) -> Tensor\n",
      "     |      \n",
      "     |          Returns a Tensor with the specified :attr:`dtype`\n",
      "     |      \n",
      "     |      .. function:: to(device, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |          Returns a Tensor with the specified :attr:`device` and (optional)\n",
      "     |          :attr:`dtype`. If :attr:`dtype` is ``None`` it is inferred to be ``self.dtype``.\n",
      "     |      \n",
      "     |      .. function:: to(other) -> Tensor\n",
      "     |      \n",
      "     |          Returns a Tensor with same :class:`torch.dtype` and :class:`torch.device` as the Tensor\n",
      "     |          :attr:`other`.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.randn(2, 2)  # Initially dtype=float32, device=cpu\n",
      "     |          >>> tensor.to(torch.float64)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], dtype=torch.float64)\n",
      "     |      \n",
      "     |          >>> cuda0 = torch.device('cuda:0')\n",
      "     |          >>> tensor.to(cuda0)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], device='cuda:0')\n",
      "     |      \n",
      "     |          >>> tensor.to(cuda0, dtype=torch.float64)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], dtype=torch.float64, device='cuda:0')\n",
      "     |      \n",
      "     |          >>> other = torch.randn((), dtype=torch.float64, device=cuda0)\n",
      "     |          >>> tensor.to(other)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], dtype=torch.float64, device='cuda:0')\n",
      "     |  \n",
      "     |  to_dense(...)\n",
      "     |  \n",
      "     |  tolist(...)\n",
      "     |  \n",
      "     |  topk(...)\n",
      "     |      topk(k, dim=None, largest=True, sorted=True) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.topk`\n",
      "     |  \n",
      "     |  trace(...)\n",
      "     |      trace() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.trace`\n",
      "     |  \n",
      "     |  transpose(...)\n",
      "     |      transpose(dim0, dim1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.transpose`\n",
      "     |  \n",
      "     |  transpose_(...)\n",
      "     |      transpose_(dim0, dim1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.transpose`\n",
      "     |  \n",
      "     |  tril(...)\n",
      "     |      tril(k=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tril`\n",
      "     |  \n",
      "     |  tril_(...)\n",
      "     |      tril_(k=0) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.tril`\n",
      "     |  \n",
      "     |  triu(...)\n",
      "     |      triu(k=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.triu`\n",
      "     |  \n",
      "     |  triu_(...)\n",
      "     |      triu_(k=0) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.triu`\n",
      "     |  \n",
      "     |  trtrs(...)\n",
      "     |      trtrs(A, upper=True, transpose=False, unitriangular=False) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.trtrs`\n",
      "     |  \n",
      "     |  trunc(...)\n",
      "     |      trunc() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.trunc`\n",
      "     |  \n",
      "     |  trunc_(...)\n",
      "     |      trunc_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.trunc`\n",
      "     |  \n",
      "     |  type(...)\n",
      "     |      type(dtype=None, non_blocking=False, **kwargs) -> str or Tensor\n",
      "     |      Returns the type if `dtype` is not provided, else casts this object to\n",
      "     |      the specified type.\n",
      "     |      \n",
      "     |      If this is already of the correct type, no copy is performed and the\n",
      "     |      original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (type or string): The desired type\n",
      "     |          non_blocking (bool): If ``True``, and the source is in pinned memory\n",
      "     |              and destination is on the GPU or vice versa, the copy is performed\n",
      "     |              asynchronously with respect to the host. Otherwise, the argument\n",
      "     |              has no effect.\n",
      "     |          **kwargs: For compatibility, may contain the key ``async`` in place of\n",
      "     |              the ``non_blocking`` argument. The ``async`` arg is deprecated.\n",
      "     |  \n",
      "     |  type_as(...)\n",
      "     |      type_as(tensor) -> Tensor\n",
      "     |      \n",
      "     |      Returns this tensor cast to the type of the given tensor.\n",
      "     |      \n",
      "     |      This is a no-op if the tensor is already of the correct type. This is\n",
      "     |      equivalent to::\n",
      "     |      \n",
      "     |          self.type(tensor.type())\n",
      "     |      \n",
      "     |      Params:\n",
      "     |          tensor (Tensor): the tensor which has the desired type\n",
      "     |  \n",
      "     |  unfold(...)\n",
      "     |      unfold(dim, size, step) -> Tensor\n",
      "     |      \n",
      "     |      Returns a tensor which contains all slices of size :attr:`size` from\n",
      "     |      :attr:`self` tensor in the dimension :attr:`dim`.\n",
      "     |      \n",
      "     |      Step between two slices is given by :attr:`step`.\n",
      "     |      \n",
      "     |      If `sizedim` is the size of dimension dim for :attr:`self`, the size of\n",
      "     |      dimension :attr:`dim` in the returned tensor will be\n",
      "     |      `(sizedim - size) / step + 1`.\n",
      "     |      \n",
      "     |      An additional dimension of size size is appended in the returned tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension in which unfolding happens\n",
      "     |          size (int): the size of each slice that is unfolded\n",
      "     |          step (int): the step between each slice\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.arange(1, 8)\n",
      "     |          >>> x\n",
      "     |          tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.])\n",
      "     |          >>> x.unfold(0, 2, 1)\n",
      "     |          tensor([[ 1.,  2.],\n",
      "     |                  [ 2.,  3.],\n",
      "     |                  [ 3.,  4.],\n",
      "     |                  [ 4.,  5.],\n",
      "     |                  [ 5.,  6.],\n",
      "     |                  [ 6.,  7.]])\n",
      "     |          >>> x.unfold(0, 2, 2)\n",
      "     |          tensor([[ 1.,  2.],\n",
      "     |                  [ 3.,  4.],\n",
      "     |                  [ 5.,  6.]])\n",
      "     |  \n",
      "     |  uniform_(...)\n",
      "     |      uniform_(from=0, to=1) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with numbers sampled from the continuous uniform\n",
      "     |      distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |          P(x) = \\dfrac{1}{\\text{to} - \\text{from}}\n",
      "     |  \n",
      "     |  unique(self, sorted=False, return_inverse=False)\n",
      "     |      Returns the unique scalar elements of the tensor as a 1-D tensor.\n",
      "     |      \n",
      "     |      See :func:`torch.unique`\n",
      "     |  \n",
      "     |  unsqueeze(...)\n",
      "     |      unsqueeze(dim) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.unsqueeze`\n",
      "     |  \n",
      "     |  unsqueeze_(...)\n",
      "     |      unsqueeze_(dim) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.unsqueeze`\n",
      "     |  \n",
      "     |  var(...)\n",
      "     |      var(dim=None, unbiased=True, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.var`\n",
      "     |  \n",
      "     |  view(...)\n",
      "     |      view(*args) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new tensor with the same data as the :attr:`self` tensor but of a\n",
      "     |      different size.\n",
      "     |      \n",
      "     |      The returned tensor shares the same data and must have the same number\n",
      "     |      of elements, but may have a different size. For a tensor to be viewed, the new\n",
      "     |      view size must be compatible with its original size and stride, i.e., each new\n",
      "     |      view dimension must either be a subspace of an original dimension, or only span\n",
      "     |      across original dimensions :math:`d, d+1, \\dots, d+k` that satisfy the following\n",
      "     |      contiguity-like condition that :math:`\\forall i = 0, \\dots, k-1`,\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |        stride[i] = stride[i+1] \\times size[i+1]\n",
      "     |      \n",
      "     |      Otherwise, :func:`contiguous` needs to be called before the tensor can be\n",
      "     |      viewed.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          args (torch.Size or int...): the desired size\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.randn(4, 4)\n",
      "     |          >>> x.size()\n",
      "     |          torch.Size([4, 4])\n",
      "     |          >>> y = x.view(16)\n",
      "     |          >>> y.size()\n",
      "     |          torch.Size([16])\n",
      "     |          >>> z = x.view(-1, 8)  # the size -1 is inferred from other dimensions\n",
      "     |          >>> z.size()\n",
      "     |          torch.Size([2, 8])\n",
      "     |  \n",
      "     |  view_as(self, tensor)\n",
      "     |      view_as(other) -> Tensor\n",
      "     |      \n",
      "     |      View this tensor as the same size as :attr:`other`.\n",
      "     |      ``self.view_as(other)`` is equivalent to ``self.view(other.size())``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          other (:class:`torch.Tensor`): The result tensor has the same size\n",
      "     |              as :attr:`other.size()`.\n",
      "     |  \n",
      "     |  where(...)\n",
      "     |      where(condition, y) -> Tensor\n",
      "     |      \n",
      "     |      ``self.where(condition, y)`` is equivalent to ``torch.where(condition, self, y)``.\n",
      "     |      See :func:`torch.where`\n",
      "     |  \n",
      "     |  zero_(...)\n",
      "     |      zero_() -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with zeros.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  data\n",
      "     |  \n",
      "     |  device\n",
      "     |  \n",
      "     |  grad\n",
      "     |  \n",
      "     |  grad_fn\n",
      "     |  \n",
      "     |  is_leaf\n",
      "     |  \n",
      "     |  name\n",
      "     |  \n",
      "     |  output_nr\n",
      "     |  \n",
      "     |  requires_grad\n",
      "     |  \n",
      "     |  shape\n",
      "     |  \n",
      "     |  volatile\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  dtype = torch.float64\n",
      "     |  \n",
      "     |  is_cuda = False\n",
      "     |  \n",
      "     |  is_sparse = False\n",
      "     |  \n",
      "     |  layout = torch.strided\n",
      "    \n",
      "    class FatalError(builtins.Exception)\n",
      "     |  Common base class for all non-exit exceptions.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      FatalError\n",
      "     |      builtins.Exception\n",
      "     |      builtins.BaseException\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.Exception:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.BaseException:\n",
      "     |  \n",
      "     |  __delattr__(self, name, /)\n",
      "     |      Implement delattr(self, name).\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __reduce__(...)\n",
      "     |      helper for pickle\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setattr__(self, name, value, /)\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |  \n",
      "     |  __setstate__(...)\n",
      "     |  \n",
      "     |  __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  with_traceback(...)\n",
      "     |      Exception.with_traceback(tb) --\n",
      "     |      set self.__traceback__ to tb and return self.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from builtins.BaseException:\n",
      "     |  \n",
      "     |  __cause__\n",
      "     |      exception cause\n",
      "     |  \n",
      "     |  __context__\n",
      "     |      exception context\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |  \n",
      "     |  __suppress_context__\n",
      "     |  \n",
      "     |  __traceback__\n",
      "     |  \n",
      "     |  args\n",
      "    \n",
      "    class FloatStorage(torch._C.FloatStorageBase, torch.storage._StorageBase)\n",
      "     |  Method resolution order:\n",
      "     |      FloatStorage\n",
      "     |      torch._C.FloatStorageBase\n",
      "     |      torch.storage._StorageBase\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch._C.FloatStorageBase:\n",
      "     |  \n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |  \n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |  \n",
      "     |  __len__(self, /)\n",
      "     |      Return len(self).\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  __setitem__(self, key, value, /)\n",
      "     |      Set self[key] to value.\n",
      "     |  \n",
      "     |  copy_(...)\n",
      "     |  \n",
      "     |  data_ptr(...)\n",
      "     |  \n",
      "     |  element_size(...)\n",
      "     |  \n",
      "     |  fill_(...)\n",
      "     |  \n",
      "     |  is_pinned(...)\n",
      "     |  \n",
      "     |  is_shared(...)\n",
      "     |  \n",
      "     |  new(...)\n",
      "     |  \n",
      "     |  resize_(...)\n",
      "     |  \n",
      "     |  size(...)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from torch._C.FloatStorageBase:\n",
      "     |  \n",
      "     |  from_buffer(...)\n",
      "     |  \n",
      "     |  from_file(...)\n",
      "     |      from_file(filename, shared=False, size=0) -> Storage\n",
      "     |      \n",
      "     |      If `shared` is `True`, then memory is shared between all processes.\n",
      "     |      All changes are written to the file. If `shared` is `False`, then the changes on\n",
      "     |      the storage do not affect the file.\n",
      "     |      \n",
      "     |      `size` is the number of elements in the storage. If `shared` is `False`,\n",
      "     |      then the file must contain at least `size * sizeof(Type)` bytes\n",
      "     |      (`Type` is the type of storage). If `shared` is `True` the file will be\n",
      "     |      created if needed.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          filename (str): file name to map\n",
      "     |          shared (bool): whether to share memory\n",
      "     |          size (int): number of elements in the storage\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.storage._StorageBase:\n",
      "     |  \n",
      "     |  __copy__(self)\n",
      "     |  \n",
      "     |  __deepcopy__(self, memo)\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      helper for pickle\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __sizeof__(self)\n",
      "     |      __sizeof__() -> int\n",
      "     |      size of object in memory, in bytes\n",
      "     |  \n",
      "     |  __str__(self)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  byte(self)\n",
      "     |      Casts this storage to byte type\n",
      "     |  \n",
      "     |  char(self)\n",
      "     |      Casts this storage to char type\n",
      "     |  \n",
      "     |  clone(self)\n",
      "     |      Returns a copy of this storage\n",
      "     |  \n",
      "     |  cpu(self)\n",
      "     |      Returns a CPU copy of this storage if it's not already on the CPU\n",
      "     |  \n",
      "     |  cuda = _cuda(self, device=None, non_blocking=False, **kwargs)\n",
      "     |      Returns a copy of this object in CUDA memory.\n",
      "     |      \n",
      "     |      If this object is already in CUDA memory and on the correct device, then\n",
      "     |      no copy is performed and the original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          device (int): The destination GPU id. Defaults to the current device.\n",
      "     |          non_blocking (bool): If ``True`` and the source is in pinned memory,\n",
      "     |              the copy will be asynchronous with respect to the host. Otherwise,\n",
      "     |              the argument has no effect.\n",
      "     |          **kwargs: For compatibility, may contain the key ``async`` in place of\n",
      "     |              the ``non_blocking`` argument.\n",
      "     |  \n",
      "     |  double(self)\n",
      "     |      Casts this storage to double type\n",
      "     |  \n",
      "     |  float(self)\n",
      "     |      Casts this storage to float type\n",
      "     |  \n",
      "     |  half(self)\n",
      "     |      Casts this storage to half type\n",
      "     |  \n",
      "     |  int(self)\n",
      "     |      Casts this storage to int type\n",
      "     |  \n",
      "     |  long(self)\n",
      "     |      Casts this storage to long type\n",
      "     |  \n",
      "     |  pin_memory(self)\n",
      "     |      Copies the storage to pinned memory, if it's not already pinned.\n",
      "     |  \n",
      "     |  share_memory_(self)\n",
      "     |      Moves the storage to shared memory.\n",
      "     |      \n",
      "     |      This is a no-op for storages already in shared memory and for CUDA\n",
      "     |      storages, which do not need to be moved for sharing across processes.\n",
      "     |      Storages in shared memory cannot be resized.\n",
      "     |      \n",
      "     |      Returns: self\n",
      "     |  \n",
      "     |  short(self)\n",
      "     |      Casts this storage to short type\n",
      "     |  \n",
      "     |  tolist(self)\n",
      "     |      Returns a list containing the elements of this storage\n",
      "     |  \n",
      "     |  type = _type(self, dtype=None, non_blocking=False, **kwargs)\n",
      "     |      Returns the type if `dtype` is not provided, else casts this object to\n",
      "     |      the specified type.\n",
      "     |      \n",
      "     |      If this is already of the correct type, no copy is performed and the\n",
      "     |      original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (type or string): The desired type\n",
      "     |          non_blocking (bool): If ``True``, and the source is in pinned memory\n",
      "     |              and destination is on the GPU or vice versa, the copy is performed\n",
      "     |              asynchronously with respect to the host. Otherwise, the argument\n",
      "     |              has no effect.\n",
      "     |          **kwargs: For compatibility, may contain the key ``async`` in place of\n",
      "     |              the ``non_blocking`` argument. The ``async`` arg is deprecated.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.storage._StorageBase:\n",
      "     |  \n",
      "     |  is_cuda = False\n",
      "     |  \n",
      "     |  is_sparse = False\n",
      "    \n",
      "    class FloatTensor(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __abs__ = abs(...)\n",
      "     |  \n",
      "     |  __add__(...)\n",
      "     |  \n",
      "     |  __and__(...)\n",
      "     |  \n",
      "     |  __array__(self, dtype=None)\n",
      "     |      # Numpy array interface, to support `numpy.asarray(tensor) -> ndarray`\n",
      "     |  \n",
      "     |  __array_wrap__(self, array)\n",
      "     |      # Wrap Numpy array again in a suitable tensor when done, to support e.g.\n",
      "     |      # `numpy.sin(tensor) -> tensor` or `numpy.greater(tensor, 0) -> ByteTensor`\n",
      "     |  \n",
      "     |  __bool__(...)\n",
      "     |  \n",
      "     |  __deepcopy__(self, memo)\n",
      "     |  \n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |  \n",
      "     |  __dir__(self)\n",
      "     |      __dir__() -> list\n",
      "     |      default dir() implementation\n",
      "     |  \n",
      "     |  __div__(...)\n",
      "     |  \n",
      "     |  __eq__ = eq(...)\n",
      "     |  \n",
      "     |  __float__(...)\n",
      "     |  \n",
      "     |  __format__(self, format_spec)\n",
      "     |      default object formatter\n",
      "     |  \n",
      "     |  __ge__ = ge(...)\n",
      "     |  \n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |  \n",
      "     |  __gt__ = gt(...)\n",
      "     |  \n",
      "     |  __hash__(self)\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __iadd__(...)\n",
      "     |  \n",
      "     |  __iand__(...)\n",
      "     |  \n",
      "     |  __idiv__(...)\n",
      "     |  \n",
      "     |  __ilshift__(...)\n",
      "     |  \n",
      "     |  __imul__(...)\n",
      "     |  \n",
      "     |  __index__(...)\n",
      "     |  \n",
      "     |  __int__(...)\n",
      "     |  \n",
      "     |  __invert__(...)\n",
      "     |  \n",
      "     |  __ior__(...)\n",
      "     |  \n",
      "     |  __ipow__(self, other)\n",
      "     |  \n",
      "     |  __irshift__(...)\n",
      "     |  \n",
      "     |  __isub__(...)\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |  \n",
      "     |  __itruediv__ = __idiv__(...)\n",
      "     |  \n",
      "     |  __ixor__(...)\n",
      "     |  \n",
      "     |  __le__ = le(...)\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |      Return len(self).\n",
      "     |  \n",
      "     |  __long__(...)\n",
      "     |  \n",
      "     |  __lshift__(...)\n",
      "     |  \n",
      "     |  __lt__ = lt(...)\n",
      "     |  \n",
      "     |  __matmul__(...)\n",
      "     |  \n",
      "     |  __mod__(...)\n",
      "     |  \n",
      "     |  __mul__(...)\n",
      "     |  \n",
      "     |  __ne__ = ne(...)\n",
      "     |  \n",
      "     |  __neg__ = neg(...)\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from tensortype\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  __nonzero__(...)\n",
      "     |  \n",
      "     |  __or__(...)\n",
      "     |  \n",
      "     |  __pow__ = pow(...)\n",
      "     |  \n",
      "     |  __radd__(...)\n",
      "     |  \n",
      "     |  __rdiv__(self, other)\n",
      "     |  \n",
      "     |  __reduce_ex__(self, proto)\n",
      "     |      helper for pickle\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __rmul__(...)\n",
      "     |  \n",
      "     |  __rpow__(self, other)\n",
      "     |  \n",
      "     |  __rshift__(...)\n",
      "     |  \n",
      "     |  __rsub__(self, other)\n",
      "     |  \n",
      "     |  __rtruediv__ = __rdiv__(self, other)\n",
      "     |  \n",
      "     |  __setitem__(self, key, value, /)\n",
      "     |      Set self[key] to value.\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |  \n",
      "     |  __sub__(...)\n",
      "     |  \n",
      "     |  __truediv__(...)\n",
      "     |  \n",
      "     |  __xor__(...)\n",
      "     |  \n",
      "     |  abs(...)\n",
      "     |      abs() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.abs`\n",
      "     |  \n",
      "     |  abs_(...)\n",
      "     |      abs_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.abs`\n",
      "     |  \n",
      "     |  acos(...)\n",
      "     |      acos() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.acos`\n",
      "     |  \n",
      "     |  acos_(...)\n",
      "     |      acos_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.acos`\n",
      "     |  \n",
      "     |  add(...)\n",
      "     |      add(value) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.add`\n",
      "     |  \n",
      "     |  add_(...)\n",
      "     |      add_(value) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.add`\n",
      "     |  \n",
      "     |  addbmm(...)\n",
      "     |      addbmm(beta=1, mat, alpha=1, batch1, batch2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addbmm`\n",
      "     |  \n",
      "     |  addbmm_(...)\n",
      "     |      addbmm_(beta=1, mat, alpha=1, batch1, batch2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addbmm`\n",
      "     |  \n",
      "     |  addcdiv(...)\n",
      "     |      addcdiv(value=1, tensor1, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addcdiv`\n",
      "     |  \n",
      "     |  addcdiv_(...)\n",
      "     |      addcdiv_(value=1, tensor1, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addcdiv`\n",
      "     |  \n",
      "     |  addcmul(...)\n",
      "     |      addcmul(value=1, tensor1, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addcmul`\n",
      "     |  \n",
      "     |  addcmul_(...)\n",
      "     |      addcmul_(value=1, tensor1, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addcmul`\n",
      "     |  \n",
      "     |  addmm(...)\n",
      "     |      addmm(beta=1, mat, alpha=1, mat1, mat2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addmm`\n",
      "     |  \n",
      "     |  addmm_(...)\n",
      "     |      addmm_(beta=1, mat, alpha=1, mat1, mat2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addmm`\n",
      "     |  \n",
      "     |  addmv(...)\n",
      "     |      addmv(beta=1, tensor, alpha=1, mat, vec) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addmv`\n",
      "     |  \n",
      "     |  addmv_(...)\n",
      "     |      addmv_(beta=1, tensor, alpha=1, mat, vec) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addmv`\n",
      "     |  \n",
      "     |  addr(...)\n",
      "     |      addr(beta=1, alpha=1, vec1, vec2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addr`\n",
      "     |  \n",
      "     |  addr_(...)\n",
      "     |      addr_(beta=1, alpha=1, vec1, vec2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addr`\n",
      "     |  \n",
      "     |  all(...)\n",
      "     |      all() -> bool\n",
      "     |      \n",
      "     |      Returns ``True`` if all elements in the tensor are non-zero, ``False`` otherwise.\n",
      "     |  \n",
      "     |  allclose(...)\n",
      "     |  \n",
      "     |  any(...)\n",
      "     |      any() -> bool\n",
      "     |      \n",
      "     |      Returns ``True`` if any elements in the tensor are non-zero, ``False`` otherwise.\n",
      "     |  \n",
      "     |  apply_(...)\n",
      "     |      apply_(callable) -> Tensor\n",
      "     |      \n",
      "     |      Applies the function :attr:`callable` to each element in the tensor, replacing\n",
      "     |      each element with the value returned by :attr:`callable`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          This function only works with CPU tensors and should not be used in code\n",
      "     |          sections that require high performance.\n",
      "     |  \n",
      "     |  argmax(self, dim=None, keepdim=False)\n",
      "     |      See :func:`torch.argmax`\n",
      "     |  \n",
      "     |  argmin(self, dim=None, keepdim=False)\n",
      "     |      See :func:`torch.argmin`\n",
      "     |  \n",
      "     |  as_strided(...)\n",
      "     |  \n",
      "     |  as_strided_(...)\n",
      "     |  \n",
      "     |  asin(...)\n",
      "     |      asin() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.asin`\n",
      "     |  \n",
      "     |  asin_(...)\n",
      "     |      asin_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.asin`\n",
      "     |  \n",
      "     |  atan(...)\n",
      "     |      atan() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.atan`\n",
      "     |  \n",
      "     |  atan2(...)\n",
      "     |      atan2(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.atan2`\n",
      "     |  \n",
      "     |  atan2_(...)\n",
      "     |      atan2_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.atan2`\n",
      "     |  \n",
      "     |  atan_(...)\n",
      "     |      atan_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.atan`\n",
      "     |  \n",
      "     |  backward(self, gradient=None, retain_graph=None, create_graph=False)\n",
      "     |      Computes the gradient of current tensor w.r.t. graph leaves.\n",
      "     |      \n",
      "     |      The graph is differentiated using the chain rule. If the tensor is\n",
      "     |      non-scalar (i.e. its data has more than one element) and requires\n",
      "     |      gradient, the function additionally requires specifying ``gradient``.\n",
      "     |      It should be a tensor of matching type and location, that contains\n",
      "     |      the gradient of the differentiated function w.r.t. ``self``.\n",
      "     |      \n",
      "     |      This function accumulates gradients in the leaves - you might need to\n",
      "     |      zero them before calling it.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          gradient (Tensor or None): Gradient w.r.t. the\n",
      "     |              tensor. If it is a tensor, it will be automatically converted\n",
      "     |              to a Tensor that does not require grad unless ``create_graph`` is True.\n",
      "     |              None values can be specified for scalar Tensors or ones that\n",
      "     |              don't require grad. If a None value would be acceptable then\n",
      "     |              this argument is optional.\n",
      "     |          retain_graph (bool, optional): If ``False``, the graph used to compute\n",
      "     |              the grads will be freed. Note that in nearly all cases setting\n",
      "     |              this option to True is not needed and often can be worked around\n",
      "     |              in a much more efficient way. Defaults to the value of\n",
      "     |              ``create_graph``.\n",
      "     |          create_graph (bool, optional): If ``True``, graph of the derivative will\n",
      "     |              be constructed, allowing to compute higher order derivative\n",
      "     |              products. Defaults to ``False``.\n",
      "     |  \n",
      "     |  baddbmm(...)\n",
      "     |      baddbmm(beta=1, alpha=1, batch1, batch2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.baddbmm`\n",
      "     |  \n",
      "     |  baddbmm_(...)\n",
      "     |      baddbmm_(beta=1, alpha=1, batch1, batch2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.baddbmm`\n",
      "     |  \n",
      "     |  bernoulli(...)\n",
      "     |      bernoulli() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bernoulli`\n",
      "     |  \n",
      "     |  bernoulli_(...)\n",
      "     |      bernoulli_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.bernoulli`\n",
      "     |  \n",
      "     |  bmm(...)\n",
      "     |      bmm(batch2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bmm`\n",
      "     |  \n",
      "     |  btrifact(self, info=None, pivot=True)\n",
      "     |      See :func:`torch.btrifact`\n",
      "     |  \n",
      "     |  btrifact_with_info(...)\n",
      "     |      btrifact_with_info(pivot=True) -> (Tensor, Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.btrifact_with_info`\n",
      "     |  \n",
      "     |  btrisolve(...)\n",
      "     |  \n",
      "     |  byte(...)\n",
      "     |      byte() -> Tensor\n",
      "     |      \n",
      "     |      ``self.byte()`` is equivalent to ``self.to(torch.uint8)``. See :func:`to`.\n",
      "     |  \n",
      "     |  cauchy_(...)\n",
      "     |      cauchy_(median=0, sigma=1, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills the tensor with numbers drawn from the Cauchy distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(x) = \\dfrac{1}{\\pi} \\dfrac{\\sigma}{(x - median)^2 + \\sigma^2}\n",
      "     |  \n",
      "     |  ceil(...)\n",
      "     |      ceil() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ceil`\n",
      "     |  \n",
      "     |  ceil_(...)\n",
      "     |      ceil_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ceil`\n",
      "     |  \n",
      "     |  char(...)\n",
      "     |      char() -> Tensor\n",
      "     |      \n",
      "     |      ``self.char()`` is equivalent to ``self.to(torch.int8)``. See :func:`to`.\n",
      "     |  \n",
      "     |  chunk(...)\n",
      "     |      chunk(chunks, dim=0) -> List of Tensors\n",
      "     |      \n",
      "     |      See :func:`torch.chunk`\n",
      "     |  \n",
      "     |  clamp(...)\n",
      "     |      clamp(min, max) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.clamp`\n",
      "     |  \n",
      "     |  clamp_(...)\n",
      "     |      clamp_(min, max) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.clamp`\n",
      "     |  \n",
      "     |  clone(...)\n",
      "     |      clone() -> Tensor\n",
      "     |      \n",
      "     |      Returns a copy of the :attr:`self` tensor. The copy has the same size and data\n",
      "     |      type as :attr:`self`.\n",
      "     |  \n",
      "     |  coalesce(...)\n",
      "     |  \n",
      "     |  contiguous(...)\n",
      "     |      contiguous() -> Tensor\n",
      "     |      \n",
      "     |      Returns a contiguous tensor containing the same data as :attr:`self` tensor. If\n",
      "     |      :attr:`self` tensor is contiguous, this function returns the :attr:`self`\n",
      "     |      tensor.\n",
      "     |  \n",
      "     |  conv_tbc(...)\n",
      "     |  \n",
      "     |  copy_(...)\n",
      "     |      copy_(src, non_blocking=False) -> Tensor\n",
      "     |      \n",
      "     |      Copies the elements from :attr:`src` into :attr:`self` tensor and returns\n",
      "     |      :attr:`self`.\n",
      "     |      \n",
      "     |      The :attr:`src` tensor must be :ref:`broadcastable <broadcasting-semantics>`\n",
      "     |      with the :attr:`self` tensor. It may be of a different data type or reside on a\n",
      "     |      different device.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          src (Tensor): the source tensor to copy from\n",
      "     |          non_blocking (bool): if ``True`` and this copy is between CPU and GPU,\n",
      "     |              the copy may occur asynchronously with respect to the host. For other\n",
      "     |              cases, this argument has no effect.\n",
      "     |  \n",
      "     |  cos(...)\n",
      "     |      cos() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cos`\n",
      "     |  \n",
      "     |  cos_(...)\n",
      "     |      cos_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.cos`\n",
      "     |  \n",
      "     |  cosh(...)\n",
      "     |      cosh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cosh`\n",
      "     |  \n",
      "     |  cosh_(...)\n",
      "     |      cosh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.cosh`\n",
      "     |  \n",
      "     |  cpu(...)\n",
      "     |  \n",
      "     |  cross(...)\n",
      "     |      cross(other, dim=-1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cross`\n",
      "     |  \n",
      "     |  cuda(...)\n",
      "     |      cuda(device=None, non_blocking=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a copy of this object in CUDA memory.\n",
      "     |      \n",
      "     |      If this object is already in CUDA memory and on the correct device,\n",
      "     |      then no copy is performed and the original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          device (:class:`torch.device`): The destination GPU device.\n",
      "     |              Defaults to the current CUDA device.\n",
      "     |          non_blocking (bool): If ``True`` and the source is in pinned memory,\n",
      "     |              the copy will be asynchronous with respect to the host.\n",
      "     |              Otherwise, the argument has no effect. Default: ``False``.\n",
      "     |  \n",
      "     |  cumprod(...)\n",
      "     |      cumprod(dim) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cumprod`\n",
      "     |  \n",
      "     |  cumsum(...)\n",
      "     |      cumsum(dim) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cumsum`\n",
      "     |  \n",
      "     |  data_ptr(...)\n",
      "     |      data_ptr() -> int\n",
      "     |      \n",
      "     |      Returns the address of the first element of :attr:`self` tensor.\n",
      "     |  \n",
      "     |  det(...)\n",
      "     |      det() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.det`\n",
      "     |  \n",
      "     |  detach(...)\n",
      "     |      Returns a new Tensor, detached from the current graph.\n",
      "     |      \n",
      "     |      The result will never require gradient.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |        Returned Tensor uses the same data tensor as the original one.\n",
      "     |        In-place modifications on either of them will be seen, and may trigger\n",
      "     |        errors in correctness checks.\n",
      "     |  \n",
      "     |  detach_(...)\n",
      "     |      Detaches the Tensor from the graph that created it, making it a leaf.\n",
      "     |      Views cannot be detached in-place.\n",
      "     |  \n",
      "     |  diag(...)\n",
      "     |      diag(diagonal=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diag`\n",
      "     |  \n",
      "     |  digamma(...)\n",
      "     |  \n",
      "     |  digamma_(...)\n",
      "     |  \n",
      "     |  dim(...)\n",
      "     |      dim() -> int\n",
      "     |      \n",
      "     |      Returns the number of dimensions of :attr:`self` tensor.\n",
      "     |  \n",
      "     |  dist(...)\n",
      "     |      dist(other, p=2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.dist`\n",
      "     |  \n",
      "     |  div(...)\n",
      "     |      div(value) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.div`\n",
      "     |  \n",
      "     |  div_(...)\n",
      "     |      div_(value) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.div`\n",
      "     |  \n",
      "     |  dot(...)\n",
      "     |      dot(tensor2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.dot`\n",
      "     |  \n",
      "     |  double(...)\n",
      "     |      double() -> Tensor\n",
      "     |      \n",
      "     |      ``self.double()`` is equivalent to ``self.to(torch.float64)``. See :func:`to`.\n",
      "     |  \n",
      "     |  eig(...)\n",
      "     |      eig(eigenvectors=False) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.eig`\n",
      "     |  \n",
      "     |  element_size(...)\n",
      "     |      element_size() -> int\n",
      "     |      \n",
      "     |      Returns the size in bytes of an individual element.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> torch.tensor([]).element_size()\n",
      "     |          4\n",
      "     |          >>> torch.tensor([], dtype=torch.uint8).element_size()\n",
      "     |          1\n",
      "     |  \n",
      "     |  eq(...)\n",
      "     |      eq(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.eq`\n",
      "     |  \n",
      "     |  eq_(...)\n",
      "     |      eq_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.eq`\n",
      "     |  \n",
      "     |  equal(...)\n",
      "     |      equal(other) -> bool\n",
      "     |      \n",
      "     |      See :func:`torch.equal`\n",
      "     |  \n",
      "     |  erf(...)\n",
      "     |      erf() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.erf`\n",
      "     |  \n",
      "     |  erf_(...)\n",
      "     |  \n",
      "     |  erfinv(...)\n",
      "     |      erfinv() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.erfinv`\n",
      "     |  \n",
      "     |  erfinv_(...)\n",
      "     |  \n",
      "     |  exp(...)\n",
      "     |      exp() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.exp`\n",
      "     |  \n",
      "     |  exp_(...)\n",
      "     |      exp_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.exp`\n",
      "     |  \n",
      "     |  expand(...)\n",
      "     |      expand(*sizes) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new view of the :attr:`self` tensor with singleton dimensions expanded\n",
      "     |      to a larger size.\n",
      "     |      \n",
      "     |      Passing -1 as the size for a dimension means not changing the size of\n",
      "     |      that dimension.\n",
      "     |      \n",
      "     |      Tensor can be also expanded to a larger number of dimensions, and the\n",
      "     |      new ones will be appended at the front. For the new dimensions, the\n",
      "     |      size cannot be set to -1.\n",
      "     |      \n",
      "     |      Expanding a tensor does not allocate new memory, but only creates a\n",
      "     |      new view on the existing tensor where a dimension of size one is\n",
      "     |      expanded to a larger size by setting the ``stride`` to 0. Any dimension\n",
      "     |      of size 1 can be expanded to an arbitrary value without allocating new\n",
      "     |      memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *sizes (torch.Size or int...): the desired expanded size\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1], [2], [3]])\n",
      "     |          >>> x.size()\n",
      "     |          torch.Size([3, 1])\n",
      "     |          >>> x.expand(3, 4)\n",
      "     |          tensor([[ 1,  1,  1,  1],\n",
      "     |                  [ 2,  2,  2,  2],\n",
      "     |                  [ 3,  3,  3,  3]])\n",
      "     |          >>> x.expand(-1, 4)   # -1 means not changing the size of that dimension\n",
      "     |          tensor([[ 1,  1,  1,  1],\n",
      "     |                  [ 2,  2,  2,  2],\n",
      "     |                  [ 3,  3,  3,  3]])\n",
      "     |  \n",
      "     |  expand_as(self, tensor)\n",
      "     |  \n",
      "     |  expm1(...)\n",
      "     |      expm1() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.expm1`\n",
      "     |  \n",
      "     |  expm1_(...)\n",
      "     |      expm1_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.expm1`\n",
      "     |  \n",
      "     |  exponential_(...)\n",
      "     |      exponential_(lambd=1, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with elements drawn from the exponential distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(x) = \\lambda e^{-\\lambda x}\n",
      "     |  \n",
      "     |  fft(...)\n",
      "     |      fft(signal_ndim, normalized=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fft`\n",
      "     |  \n",
      "     |  fill_(...)\n",
      "     |      fill_(value) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with the specified value.\n",
      "     |  \n",
      "     |  float(...)\n",
      "     |      float() -> Tensor\n",
      "     |      \n",
      "     |      ``self.float()`` is equivalent to ``self.to(torch.float32)``. See :func:`to`.\n",
      "     |  \n",
      "     |  floor(...)\n",
      "     |      floor() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.floor`\n",
      "     |  \n",
      "     |  floor_(...)\n",
      "     |      floor_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.floor`\n",
      "     |  \n",
      "     |  fmod(...)\n",
      "     |      fmod(divisor) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fmod`\n",
      "     |  \n",
      "     |  fmod_(...)\n",
      "     |      fmod_(divisor) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.fmod`\n",
      "     |  \n",
      "     |  frac(...)\n",
      "     |      frac() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.frac`\n",
      "     |  \n",
      "     |  frac_(...)\n",
      "     |      frac_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.frac`\n",
      "     |  \n",
      "     |  gather(...)\n",
      "     |      gather(dim, index) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.gather`\n",
      "     |  \n",
      "     |  ge(...)\n",
      "     |      ge(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ge`\n",
      "     |  \n",
      "     |  ge_(...)\n",
      "     |      ge_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ge`\n",
      "     |  \n",
      "     |  gels(...)\n",
      "     |      gels(A) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.gels`\n",
      "     |  \n",
      "     |  geometric_(...)\n",
      "     |      geometric_(p, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with elements drawn from the geometric distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(X=k) = (1 - p)^{k - 1} p\n",
      "     |  \n",
      "     |  geqrf(...)\n",
      "     |      geqrf() -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.geqrf`\n",
      "     |  \n",
      "     |  ger(...)\n",
      "     |      ger(vec2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ger`\n",
      "     |  \n",
      "     |  gesv(...)\n",
      "     |      gesv(A) -> Tensor, Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.gesv`\n",
      "     |  \n",
      "     |  get_device(...)\n",
      "     |  \n",
      "     |  gt(...)\n",
      "     |      gt(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.gt`\n",
      "     |  \n",
      "     |  gt_(...)\n",
      "     |      gt_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.gt`\n",
      "     |  \n",
      "     |  half(...)\n",
      "     |      half() -> Tensor\n",
      "     |      \n",
      "     |      ``self.half()`` is equivalent to ``self.to(torch.float16)``. See :func:`to`.\n",
      "     |  \n",
      "     |  histc(...)\n",
      "     |      histc(bins=100, min=0, max=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.histc`\n",
      "     |  \n",
      "     |  ifft(...)\n",
      "     |      ifft(signal_ndim, normalized=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ifft`\n",
      "     |  \n",
      "     |  index(...)\n",
      "     |      index(m) -> Tensor\n",
      "     |      \n",
      "     |      Selects elements from :attr:`self` tensor using a binary mask or along a given\n",
      "     |      dimension. The expression ``tensor.index(m)`` is equivalent to ``tensor[m]``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          m (int or ByteTensor or slice): the dimension or mask used to select elements\n",
      "     |  \n",
      "     |  index_add(self, dim, index, tensor)\n",
      "     |  \n",
      "     |  index_add_(...)\n",
      "     |      index_add_(dim, index, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Accumulate the elements of :attr:`tensor` into the :attr:`self` tensor by adding\n",
      "     |      to the indices in the order given in :attr:`index`. For example, if ``dim == 0``\n",
      "     |      and ``index[i] == j``, then the ``i``\\ th row of :attr:`tensor` is added to the\n",
      "     |      ``j``\\ th row of :attr:`self`.\n",
      "     |      \n",
      "     |      The :attr:`dim`\\ th dimension of :attr:`tensor` must have the same size as the\n",
      "     |      length of :attr:`index` (which must be a vector), and all other dimensions must\n",
      "     |      match :attr:`self`, or an error will be raised.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension along which to index\n",
      "     |          index (LongTensor): indices of :attr:`tensor` to select from\n",
      "     |          tensor (Tensor): the tensor containing values to add\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.ones(5, 3)\n",
      "     |          >>> t = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
      "     |          >>> index = torch.tensor([0, 4, 2])\n",
      "     |          >>> x.index_add_(0, index, t)\n",
      "     |          tensor([[  2.,   3.,   4.],\n",
      "     |                  [  1.,   1.,   1.],\n",
      "     |                  [  8.,   9.,  10.],\n",
      "     |                  [  1.,   1.,   1.],\n",
      "     |                  [  5.,   6.,   7.]])\n",
      "     |  \n",
      "     |  index_copy(self, dim, index, tensor)\n",
      "     |  \n",
      "     |  index_copy_(...)\n",
      "     |      index_copy_(dim, index, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Copies the elements of :attr:`tensor` into the :attr:`self` tensor by selecting\n",
      "     |      the indices in the order given in :attr:`index`. For example, if ``dim == 0``\n",
      "     |      and ``index[i] == j``, then the ``i``\\ th row of :attr:`tensor` is copied to the\n",
      "     |      ``j``\\ th row of :attr:`self`.\n",
      "     |      \n",
      "     |      The :attr:`dim`\\ th dimension of :attr:`tensor` must have the same size as the\n",
      "     |      length of :attr:`index` (which must be a vector), and all other dimensions must\n",
      "     |      match :attr:`self`, or an error will be raised.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension along which to index\n",
      "     |          index (LongTensor): indices of :attr:`tensor` to select from\n",
      "     |          tensor (Tensor): the tensor containing values to copy\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.zeros(5, 3)\n",
      "     |          >>> t = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
      "     |          >>> index = torch.tensor([0, 4, 2])\n",
      "     |          >>> x.index_copy_(0, index, t)\n",
      "     |          tensor([[ 1.,  2.,  3.],\n",
      "     |                  [ 0.,  0.,  0.],\n",
      "     |                  [ 7.,  8.,  9.],\n",
      "     |                  [ 0.,  0.,  0.],\n",
      "     |                  [ 4.,  5.,  6.]])\n",
      "     |  \n",
      "     |  index_fill(self, dim, index, value)\n",
      "     |  \n",
      "     |  index_fill_(...)\n",
      "     |      index_fill_(dim, index, val) -> Tensor\n",
      "     |      \n",
      "     |      Fills the elements of the :attr:`self` tensor with value :attr:`val` by\n",
      "     |      selecting the indices in the order given in :attr:`index`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension along which to index\n",
      "     |          index (LongTensor): indices of :attr:`self` tensor to fill in\n",
      "     |          val (float): the value to fill with\n",
      "     |      \n",
      "     |      Example::\n",
      "     |          >>> x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
      "     |          >>> index = torch.tensor([0, 2])\n",
      "     |          >>> x.index_fill_(1, index, -1)\n",
      "     |          tensor([[-1.,  2., -1.],\n",
      "     |                  [-1.,  5., -1.],\n",
      "     |                  [-1.,  8., -1.]])\n",
      "     |  \n",
      "     |  index_put_(...)\n",
      "     |      index_put_(indices, value) -> Tensor\n",
      "     |      \n",
      "     |      Puts values from the tensor :attr:`value` into the tensor :attr:`self` using\n",
      "     |      the indices specified in :attr:`indices` (which is a tuple of Tensors). The\n",
      "     |      expression ``tensor.index_put_(indices, value)`` is equivalent to\n",
      "     |      ``tensor[indices] = value``. Returns :attr:`self`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          indices (tuple of LongTensor): tensors used to index into `self`.\n",
      "     |          value (Tensor): tensor of same dtype as `self`.\n",
      "     |  \n",
      "     |  index_select(...)\n",
      "     |      index_select(dim, index) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.index_select`\n",
      "     |  \n",
      "     |  int(...)\n",
      "     |      int() -> Tensor\n",
      "     |      \n",
      "     |      ``self.int()`` is equivalent to ``self.to(torch.int32)``. See :func:`to`.\n",
      "     |  \n",
      "     |  inverse(...)\n",
      "     |      inverse() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.inverse`\n",
      "     |  \n",
      "     |  irfft(...)\n",
      "     |      irfft(signal_ndim, normalized=False, onesided=True, signal_sizes=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.irfft`\n",
      "     |  \n",
      "     |  is_coalesced(...)\n",
      "     |  \n",
      "     |  is_contiguous(...)\n",
      "     |      is_contiguous() -> bool\n",
      "     |      \n",
      "     |      Returns True if :attr:`self` tensor is contiguous in memory in C order.\n",
      "     |  \n",
      "     |  is_distributed(...)\n",
      "     |  \n",
      "     |  is_floating_point(...)\n",
      "     |  \n",
      "     |  is_nonzero(...)\n",
      "     |  \n",
      "     |  is_pinned(self)\n",
      "     |      Returns true if this tensor resides in pinned memory\n",
      "     |  \n",
      "     |  is_same_size(...)\n",
      "     |  \n",
      "     |  is_set_to(...)\n",
      "     |      is_set_to(tensor) -> bool\n",
      "     |      \n",
      "     |      Returns True if this object refers to the same ``THTensor`` object from the\n",
      "     |      Torch C API as the given tensor.\n",
      "     |  \n",
      "     |  is_shared(self)\n",
      "     |      Checks if tensor is in shared memory.\n",
      "     |      \n",
      "     |      This is always ``True`` for CUDA tensors.\n",
      "     |  \n",
      "     |  is_signed(...)\n",
      "     |  \n",
      "     |  isclose(...)\n",
      "     |  \n",
      "     |  item(...)\n",
      "     |      item() -> number\n",
      "     |      \n",
      "     |      Returns the value of this tensor as a standard Python number. This only works\n",
      "     |      for tensors with one element.\n",
      "     |      \n",
      "     |      This operation is not differentiable.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([1.0])\n",
      "     |          >>> x.item()\n",
      "     |          1.0\n",
      "     |  \n",
      "     |  kthvalue(...)\n",
      "     |      kthvalue(k, dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.kthvalue`\n",
      "     |  \n",
      "     |  le(...)\n",
      "     |      le(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.le`\n",
      "     |  \n",
      "     |  le_(...)\n",
      "     |      le_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.le`\n",
      "     |  \n",
      "     |  lerp(...)\n",
      "     |      lerp(start, end, weight) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lerp`\n",
      "     |  \n",
      "     |  lerp_(...)\n",
      "     |      lerp_(start, end, weight) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lerp`\n",
      "     |  \n",
      "     |  lgamma(...)\n",
      "     |  \n",
      "     |  lgamma_(...)\n",
      "     |  \n",
      "     |  log(...)\n",
      "     |      log() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log`\n",
      "     |  \n",
      "     |  log10(...)\n",
      "     |      log10() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log10`\n",
      "     |  \n",
      "     |  log10_(...)\n",
      "     |      log10_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log10`\n",
      "     |  \n",
      "     |  log1p(...)\n",
      "     |      log1p() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log1p`\n",
      "     |  \n",
      "     |  log1p_(...)\n",
      "     |      log1p_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log1p`\n",
      "     |  \n",
      "     |  log2(...)\n",
      "     |      log2() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log2`\n",
      "     |  \n",
      "     |  log2_(...)\n",
      "     |      log2_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log2`\n",
      "     |  \n",
      "     |  log_(...)\n",
      "     |      log_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log`\n",
      "     |  \n",
      "     |  log_normal_(...)\n",
      "     |      log_normal_(mean=1, std=2, *, generator=None)\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with numbers samples from the log-normal distribution\n",
      "     |      parameterized by the given mean (µ) and standard deviation (σ).\n",
      "     |      Note that :attr:`mean` and :attr:`stdv` are the mean and standard deviation of\n",
      "     |      the underlying normal distribution, and not of the returned distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(x) = \\dfrac{1}{x \\sigma \\sqrt{2\\pi}}\\ e^{-\\dfrac{(\\ln x - \\mu)^2}{2\\sigma^2}}\n",
      "     |  \n",
      "     |  logdet(...)\n",
      "     |      logdet() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logdet`\n",
      "     |  \n",
      "     |  long(...)\n",
      "     |      long() -> Tensor\n",
      "     |      \n",
      "     |      ``self.long()`` is equivalent to ``self.to(torch.int64)``. See :func:`to`.\n",
      "     |  \n",
      "     |  lt(...)\n",
      "     |      lt(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lt`\n",
      "     |  \n",
      "     |  lt_(...)\n",
      "     |      lt_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lt`\n",
      "     |  \n",
      "     |  map2_(...)\n",
      "     |  \n",
      "     |  map_(...)\n",
      "     |      map_(tensor, callable)\n",
      "     |      \n",
      "     |      Applies :attr:`callable` for each element in :attr:`self` tensor and the given\n",
      "     |      :attr:`tensor` and stores the results in :attr:`self` tensor. :attr:`self` tensor and\n",
      "     |      the given :attr:`tensor` must be :ref:`broadcastable <broadcasting-semantics>`.\n",
      "     |      \n",
      "     |      The :attr:`callable` should have the signature::\n",
      "     |      \n",
      "     |          def callable(a, b) -> number\n",
      "     |  \n",
      "     |  masked_copy(self, mask, tensor)\n",
      "     |  \n",
      "     |  masked_copy_(self, mask, tensor)\n",
      "     |  \n",
      "     |  masked_fill(self, mask, value)\n",
      "     |  \n",
      "     |  masked_fill_(...)\n",
      "     |      masked_fill_(mask, value)\n",
      "     |      \n",
      "     |      Fills elements of :attr:`self` tensor with :attr:`value` where :attr:`mask` is\n",
      "     |      one. The shape of :attr:`mask` must be\n",
      "     |      :ref:`broadcastable <broadcasting-semantics>` with the shape of the underlying\n",
      "     |      tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          mask (ByteTensor): the binary mask\n",
      "     |          value (float): the value to fill in with\n",
      "     |  \n",
      "     |  masked_scatter(self, mask, tensor)\n",
      "     |  \n",
      "     |  masked_scatter_(...)\n",
      "     |      masked_scatter_(mask, source)\n",
      "     |      \n",
      "     |      Copies elements from :attr:`source` into :attr:`self` tensor at positions where\n",
      "     |      the :attr:`mask` is one.\n",
      "     |      The shape of :attr:`mask` must be :ref:`broadcastable <broadcasting-semantics>`\n",
      "     |      with the shape of the underlying tensor. The :attr:`source` should have at least\n",
      "     |      as many elements as the number of ones in :attr:`mask`\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          mask (ByteTensor): the binary mask\n",
      "     |          source (Tensor): the tensor to copy from\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The :attr:`mask` operates on the :attr:`self` tensor, not on the given\n",
      "     |          :attr:`source` tensor.\n",
      "     |  \n",
      "     |  masked_select(...)\n",
      "     |      masked_select(mask) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.masked_select`\n",
      "     |  \n",
      "     |  matmul(...)\n",
      "     |      matmul(tensor2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.matmul`\n",
      "     |  \n",
      "     |  max(...)\n",
      "     |      max(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.max`\n",
      "     |  \n",
      "     |  mean(...)\n",
      "     |      mean(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.mean`\n",
      "     |  \n",
      "     |  median(...)\n",
      "     |      median(dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.median`\n",
      "     |  \n",
      "     |  min(...)\n",
      "     |      min(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.min`\n",
      "     |  \n",
      "     |  mm(...)\n",
      "     |      mm(mat2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mm`\n",
      "     |  \n",
      "     |  mode(...)\n",
      "     |      mode(dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.mode`\n",
      "     |  \n",
      "     |  mul(...)\n",
      "     |      mul(value) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mul`\n",
      "     |  \n",
      "     |  mul_(...)\n",
      "     |      mul_(value)\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.mul`\n",
      "     |  \n",
      "     |  multinomial(...)\n",
      "     |      multinomial(num_samples, replacement=False, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.multinomial`\n",
      "     |  \n",
      "     |  mv(...)\n",
      "     |      mv(vec) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mv`\n",
      "     |  \n",
      "     |  narrow(...)\n",
      "     |      narrow(dimension, start, length) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new tensor that is a narrowed version of :attr:`self` tensor. The\n",
      "     |      dimension :attr:`dim` is narrowed from :attr:`start` to :attr:`start + length`. The\n",
      "     |      returned tensor and :attr:`self` tensor share the same underlying storage.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dimension (int): the dimension along which to narrow\n",
      "     |          start (int): the starting dimension\n",
      "     |          length (int): the distance to the ending dimension\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
      "     |          >>> x.narrow(0, 0, 2)\n",
      "     |          tensor([[ 1,  2,  3],\n",
      "     |                  [ 4,  5,  6]])\n",
      "     |          >>> x.narrow(1, 1, 2)\n",
      "     |          tensor([[ 2,  3],\n",
      "     |                  [ 5,  6],\n",
      "     |                  [ 8,  9]])\n",
      "     |  \n",
      "     |  ndimension(...)\n",
      "     |      ndimension() -> int\n",
      "     |      \n",
      "     |      Alias for :meth:`~Tensor.dim()`\n",
      "     |  \n",
      "     |  ne(...)\n",
      "     |      ne(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ne`\n",
      "     |  \n",
      "     |  ne_(...)\n",
      "     |      ne_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ne`\n",
      "     |  \n",
      "     |  neg(...)\n",
      "     |      neg() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.neg`\n",
      "     |  \n",
      "     |  neg_(...)\n",
      "     |      neg_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.neg`\n",
      "     |  \n",
      "     |  nelement(...)\n",
      "     |      nelement() -> int\n",
      "     |      \n",
      "     |      Alias for :meth:`~Tensor.numel`\n",
      "     |  \n",
      "     |  new(...)\n",
      "     |  \n",
      "     |  new_empty(...)\n",
      "     |      new_empty(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with uninitialized data.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones(())\n",
      "     |          >>> tensor.new_empty((2, 3))\n",
      "     |          tensor([[ 5.8182e-18,  4.5765e-41, -1.0545e+30],\n",
      "     |                  [ 3.0949e-41,  4.4842e-44,  0.0000e+00]])\n",
      "     |  \n",
      "     |  new_full(...)\n",
      "     |      new_full(size, fill_value, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with :attr:`fill_value`.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          fill_value (scalar): the number to fill the output tensor with.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones((2,), dtype=torch.float64)\n",
      "     |          >>> tensor.new_full((3, 4), 3.141592)\n",
      "     |          tensor([[ 3.1416,  3.1416,  3.1416,  3.1416],\n",
      "     |                  [ 3.1416,  3.1416,  3.1416,  3.1416],\n",
      "     |                  [ 3.1416,  3.1416,  3.1416,  3.1416]], dtype=torch.float64)\n",
      "     |  \n",
      "     |  new_ones(...)\n",
      "     |      new_ones(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with ``1``.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (int...): a list, tuple, or :class:`torch.Size` of integers defining the\n",
      "     |              shape of the output tensor.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.tensor((), dtype=torch.int32)\n",
      "     |          >>> tensor.new_ones((2, 3))\n",
      "     |          tensor([[ 1,  1,  1],\n",
      "     |                  [ 1,  1,  1]], dtype=torch.int32)\n",
      "     |  \n",
      "     |  new_tensor(...)\n",
      "     |      new_tensor(data, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new Tensor with :attr:`data` as the tensor data.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          :func:`new_tensor` always copies :attr:`data`. If you have a Tensor\n",
      "     |          ``data`` and want to avoid a copy, use :func:`torch.Tensor.requires_grad_`\n",
      "     |          or :func:`torch.Tensor.detach`.\n",
      "     |          If you have a numpy array and want to avoid a copy, use\n",
      "     |          :func:`torch.from_numpy`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          data (array_like): The returned Tensor copies :attr:`data`.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones((2,), dtype=torch.int8)\n",
      "     |          >>> data = [[0, 1], [2, 3]]\n",
      "     |          >>> tensor.new_tensor(data)\n",
      "     |          tensor([[ 0,  1],\n",
      "     |                  [ 2,  3]], dtype=torch.int8)\n",
      "     |  \n",
      "     |  new_zeros(...)\n",
      "     |      new_zeros(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with ``0``.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (int...): a list, tuple, or :class:`torch.Size` of integers defining the\n",
      "     |              shape of the output tensor.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.tensor((), dtype=torch.float64)\n",
      "     |          >>> tensor.new_ones((2, 3))\n",
      "     |          tensor([[ 1.,  1.,  1.],\n",
      "     |                  [ 1.,  1.,  1.]], dtype=torch.float64)\n",
      "     |  \n",
      "     |  nonzero(...)\n",
      "     |      nonzero() -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.nonzero`\n",
      "     |  \n",
      "     |  norm(...)\n",
      "     |      norm(p=2, dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.norm`\n",
      "     |  \n",
      "     |  normal_(...)\n",
      "     |      normal_(mean=0, std=1, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with elements samples from the normal distribution\n",
      "     |      parameterized by :attr:`mean` and :attr:`std`.\n",
      "     |  \n",
      "     |  numel(...)\n",
      "     |      numel() -> int\n",
      "     |      \n",
      "     |      See :func:`torch.numel`\n",
      "     |  \n",
      "     |  numpy(...)\n",
      "     |      numpy() -> numpy.ndarray\n",
      "     |      \n",
      "     |      Returns :attr:`self` tensor as a NumPy :class:`ndarray`. This tensor and the\n",
      "     |      returned :class:`ndarray` share the same underlying storage. Changes to\n",
      "     |      :attr:`self` tensor will be reflected in the :class:`ndarray` and vice versa.\n",
      "     |  \n",
      "     |  orgqr(...)\n",
      "     |      orgqr(input2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.orgqr`\n",
      "     |  \n",
      "     |  ormqr(...)\n",
      "     |      ormqr(input2, input3, left=True, transpose=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ormqr`\n",
      "     |  \n",
      "     |  permute(...)\n",
      "     |  \n",
      "     |  pin_memory(...)\n",
      "     |  \n",
      "     |  polygamma(...)\n",
      "     |  \n",
      "     |  polygamma_(...)\n",
      "     |  \n",
      "     |  potrf(...)\n",
      "     |      potrf(upper=True) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.potrf`\n",
      "     |  \n",
      "     |  potri(...)\n",
      "     |      potri(upper=True) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.potri`\n",
      "     |  \n",
      "     |  potrs(...)\n",
      "     |      potrs(input2, upper=True) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.potrs`\n",
      "     |  \n",
      "     |  pow(...)\n",
      "     |      pow(exponent) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.pow`\n",
      "     |  \n",
      "     |  pow_(...)\n",
      "     |      pow_(exponent) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.pow`\n",
      "     |  \n",
      "     |  prod(...)\n",
      "     |      prod(dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.prod`\n",
      "     |  \n",
      "     |  pstrf(...)\n",
      "     |      pstrf(upper=True, tol=-1) -> (Tensor, IntTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.pstrf`\n",
      "     |  \n",
      "     |  put_(...)\n",
      "     |      put_(indices, tensor, accumulate=False) -> Tensor\n",
      "     |      \n",
      "     |      Copies the elements from :attr:`tensor` into the positions specified by\n",
      "     |      indices. For the purpose of indexing, the :attr:`self` tensor is treated as if\n",
      "     |      it were a 1-D tensor.\n",
      "     |      \n",
      "     |      If :attr:`accumulate` is ``True``, the elements in :attr:`tensor` are added to\n",
      "     |      :attr:`self`. If accumulate is ``False``, the behavior is undefined if indices\n",
      "     |      contain duplicate elements.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          indices (LongTensor): the indices into self\n",
      "     |          tensor (Tensor): the tensor containing values to copy from\n",
      "     |          accumulate (bool): whether to accumulate into self\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> src = torch.tensor([[4, 3, 5],\n",
      "     |                                  [6, 7, 8]])\n",
      "     |          >>> src.put_(torch.tensor([1, 3]), torch.tensor([9, 10]))\n",
      "     |          tensor([[  4,   9,   5],\n",
      "     |                  [ 10,   7,   8]])\n",
      "     |  \n",
      "     |  qr(...)\n",
      "     |      qr() -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.qr`\n",
      "     |  \n",
      "     |  random_(...)\n",
      "     |      random_(from=0, to=None, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with numbers sampled from the discrete uniform\n",
      "     |      distribution over ``[from, to - 1]``. If not specified, the values are usually\n",
      "     |      only bounded by :attr:`self` tensor's data type. However, for floating point\n",
      "     |      types, if unspecified, range will be ``[0, 2^mantissa]`` to ensure that every\n",
      "     |      value is representable. For example, `torch.tensor(1, dtype=torch.double).random_()`\n",
      "     |      will be uniform in ``[0, 2^53]``.\n",
      "     |  \n",
      "     |  reciprocal(...)\n",
      "     |      reciprocal() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.reciprocal`\n",
      "     |  \n",
      "     |  reciprocal_(...)\n",
      "     |      reciprocal_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.reciprocal`\n",
      "     |  \n",
      "     |  record_stream(...)\n",
      "     |  \n",
      "     |  register_hook(self, hook)\n",
      "     |      Registers a backward hook.\n",
      "     |      \n",
      "     |      The hook will be called every time a gradient with respect to the\n",
      "     |      Tensor is computed. The hook should have the following signature::\n",
      "     |      \n",
      "     |          hook(grad) -> Tensor or None\n",
      "     |      \n",
      "     |      The hook should not modify its argument, but it can optionally return\n",
      "     |      a new gradient which will be used in place of :attr:`grad`.\n",
      "     |      \n",
      "     |      This function returns a handle with a method ``handle.remove()``\n",
      "     |      that removes the hook from the module.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          >>> v = torch.tensor([0., 0., 0.], requires_grad=True)\n",
      "     |          >>> h = v.register_hook(lambda grad: grad * 2)  # double the gradient\n",
      "     |          >>> v.backward(torch.tensor([1., 2., 3.]))\n",
      "     |          >>> v.grad\n",
      "     |      \n",
      "     |           2\n",
      "     |           4\n",
      "     |           6\n",
      "     |          [torch.FloatTensor of size (3,)]\n",
      "     |      \n",
      "     |          >>> h.remove()  # removes the hook\n",
      "     |  \n",
      "     |  reinforce(self, reward)\n",
      "     |  \n",
      "     |  relu(...)\n",
      "     |  \n",
      "     |  relu_(...)\n",
      "     |  \n",
      "     |  remainder(...)\n",
      "     |      remainder(divisor) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.remainder`\n",
      "     |  \n",
      "     |  remainder_(...)\n",
      "     |      remainder_(divisor) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.remainder`\n",
      "     |  \n",
      "     |  renorm(...)\n",
      "     |      renorm(p, dim, maxnorm) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.renorm`\n",
      "     |  \n",
      "     |  renorm_(...)\n",
      "     |      renorm_(p, dim, maxnorm) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.renorm`\n",
      "     |  \n",
      "     |  repeat(...)\n",
      "     |      repeat(*sizes) -> Tensor\n",
      "     |      \n",
      "     |      Repeats this tensor along the specified dimensions.\n",
      "     |      \n",
      "     |      Unlike :meth:`~Tensor.expand`, this function copies the tensor's data.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          sizes (torch.Size or int...): The number of times to repeat this tensor along each\n",
      "     |              dimension\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([1, 2, 3])\n",
      "     |          >>> x.repeat(4, 2)\n",
      "     |          tensor([[ 1,  2,  3,  1,  2,  3],\n",
      "     |                  [ 1,  2,  3,  1,  2,  3],\n",
      "     |                  [ 1,  2,  3,  1,  2,  3],\n",
      "     |                  [ 1,  2,  3,  1,  2,  3]])\n",
      "     |          >>> x.repeat(4, 2, 1).size()\n",
      "     |          torch.Size([4, 2, 3])\n",
      "     |  \n",
      "     |  requires_grad_(...)\n",
      "     |      requires_grad_(requires_grad=True) -> Tensor\n",
      "     |      \n",
      "     |      Change if autograd should record operations on this tensor: sets this tensor's\n",
      "     |      :attr:`requires_grad` attribute in-place. Returns this tensor.\n",
      "     |      \n",
      "     |      :func:`require_grad_`'s main use case is to tell autograd to begin recording\n",
      "     |      operations on a Tensor ``tensor``. If ``tensor`` has ``requires_grad=False``\n",
      "     |      (because it was obtained through a DataLoader, or required preprocessing or\n",
      "     |      initialization), ``tensor.requires_grad_()`` makes it so that autograd will\n",
      "     |      begin to record operations on ``tensor``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          requires_grad (bool): If autograd should record operations on this tensor.\n",
      "     |              Default: ``True``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> # Let's say we want to preprocess some saved weights and use\n",
      "     |          >>> # the result as new weights.\n",
      "     |          >>> saved_weights = [0.1, 0.2, 0.3, 0.25]\n",
      "     |          >>> loaded_weights = torch.tensor(saved_weights)\n",
      "     |          >>> weights = preprocess(loaded_weights)  # some function\n",
      "     |          >>> weights\n",
      "     |          tensor([-0.5503,  0.4926, -2.1158, -0.8303])\n",
      "     |      \n",
      "     |          >>> # Now, start to record operations done to weights\n",
      "     |          >>> weights.requires_grad_()\n",
      "     |          >>> out = weights.pow(2).sum()\n",
      "     |          >>> out.backward()\n",
      "     |          >>> weights.grad\n",
      "     |          tensor([-1.1007,  0.9853, -4.2316, -1.6606])\n",
      "     |  \n",
      "     |  reshape(...)\n",
      "     |      reshape(*shape) -> Tensor\n",
      "     |      \n",
      "     |      Returns a tensor with the same data and number of elements as :attr:`self`,\n",
      "     |      but with the specified shape.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          shape (tuple of ints or int...): the desired shape\n",
      "     |      \n",
      "     |      See :func:`torch.reshape`\n",
      "     |  \n",
      "     |  resize(self, *sizes)\n",
      "     |  \n",
      "     |  resize_(...)\n",
      "     |      resize_(*sizes) -> Tensor\n",
      "     |      \n",
      "     |      Resizes :attr:`self` tensor to the specified size. If the number of elements is\n",
      "     |      larger than the current storage size, then the underlying storage is resized\n",
      "     |      to fit the new number of elements. If the number of elements is smaller, the\n",
      "     |      underlying storage is not changed. Existing elements are preserved but any new\n",
      "     |      memory is uninitialized.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          sizes (torch.Size or int...): the desired size\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1, 2], [3, 4], [5, 6]])\n",
      "     |          >>> x.resize_(2, 2)\n",
      "     |          tensor([[ 1,  2],\n",
      "     |                  [ 3,  4]])\n",
      "     |  \n",
      "     |  resize_as(self, tensor)\n",
      "     |  \n",
      "     |  resize_as_(...)\n",
      "     |      resize_as_(tensor) -> Tensor\n",
      "     |      \n",
      "     |      Resizes the :attr:`self` tensor to be the same size as the specified\n",
      "     |      :attr:`tensor`. This is equivalent to ``self.resize_(tensor.size())``.\n",
      "     |  \n",
      "     |  retain_grad(self)\n",
      "     |      Enables .grad attribute for non-leaf Tensors.\n",
      "     |  \n",
      "     |  rfft(...)\n",
      "     |      rfft(signal_ndim, normalized=False, onesided=True) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.rfft`\n",
      "     |  \n",
      "     |  round(...)\n",
      "     |      round() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.round`\n",
      "     |  \n",
      "     |  round_(...)\n",
      "     |      round_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.round`\n",
      "     |  \n",
      "     |  rsqrt(...)\n",
      "     |      rsqrt() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.rsqrt`\n",
      "     |  \n",
      "     |  rsqrt_(...)\n",
      "     |      rsqrt_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.rsqrt`\n",
      "     |  \n",
      "     |  scatter(self, dim, index, source)\n",
      "     |  \n",
      "     |  scatter_(...)\n",
      "     |      scatter_(dim, index, src) -> Tensor\n",
      "     |      \n",
      "     |      Writes all values from the tensor :attr:`src` into :attr:`self` at the indices\n",
      "     |      specified in the :attr:`index` tensor. For each value in :attr:`src`, its output\n",
      "     |      index is specified by its index in :attr:`src` for dimension != :attr:`dim` and\n",
      "     |      by the corresponding value in :attr:`index` for dimension = :attr:`dim`.\n",
      "     |      \n",
      "     |      For a 3-D tensor, :attr:`self` is updated as::\n",
      "     |      \n",
      "     |          self[index[i][j][k]][j][k] = src[i][j][k]  # if dim == 0\n",
      "     |          self[i][index[i][j][k]][k] = src[i][j][k]  # if dim == 1\n",
      "     |          self[i][j][index[i][j][k]] = src[i][j][k]  # if dim == 2\n",
      "     |      \n",
      "     |      This is the reverse operation of the manner described in :meth:`~Tensor.gather`.\n",
      "     |      \n",
      "     |      :attr:`self`, :attr:`index` and :attr:`src` should have same number of\n",
      "     |      dimensions. It is also required that `index->size[d] <= src->size[d]` for all\n",
      "     |      dimension `d`, and that `index->size[d] <= real->size[d]` for all dimensions\n",
      "     |      `d != dim`.\n",
      "     |      \n",
      "     |      Moreover, as for :meth:`~Tensor.gather`, the values of :attr:`index` must be\n",
      "     |      between `0` and `(self.size(dim) -1)` inclusive, and all values in a row along\n",
      "     |      the specified dimension :attr:`dim` must be unique.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          input (Tensor): the source tensor\n",
      "     |          dim (int): the axis along which to index\n",
      "     |          index (LongTensor): the indices of elements to scatter\n",
      "     |          src (Tensor or float): the source element(s) to scatter\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.rand(2, 5)\n",
      "     |          >>> x\n",
      "     |          tensor([[ 0.3992,  0.2908,  0.9044,  0.4850,  0.6004],\n",
      "     |                  [ 0.5735,  0.9006,  0.6797,  0.4152,  0.1732]])\n",
      "     |          >>> torch.zeros(3, 5).scatter_(0, torch.tensor([[0, 1, 2, 0, 0], [2, 0, 0, 1, 2]]), x)\n",
      "     |          tensor([[ 0.3992,  0.9006,  0.6797,  0.4850,  0.6004],\n",
      "     |                  [ 0.0000,  0.2908,  0.0000,  0.4152,  0.0000],\n",
      "     |                  [ 0.5735,  0.0000,  0.9044,  0.0000,  0.1732]])\n",
      "     |      \n",
      "     |          >>> z = torch.zeros(2, 4).scatter_(1, torch.tensor([[2], [3]]), 1.23)\n",
      "     |          >>> z\n",
      "     |          tensor([[ 0.0000,  0.0000,  1.2300,  0.0000],\n",
      "     |                  [ 0.0000,  0.0000,  0.0000,  1.2300]])\n",
      "     |  \n",
      "     |  scatter_add(self, dim, index, source)\n",
      "     |  \n",
      "     |  scatter_add_(...)\n",
      "     |  \n",
      "     |  select(...)\n",
      "     |      select(dim, index) -> Tensor\n",
      "     |      \n",
      "     |      Slices the :attr:`self` tensor along the selected dimension at the given index.\n",
      "     |      This function returns a tensor with the given dimension removed.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the dimension to slice\n",
      "     |          index (int): the index to select with\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          :meth:`select` is equivalent to slicing. For example,\n",
      "     |          ``tensor.select(0, index)`` is equivalent to ``tensor[index]`` and\n",
      "     |          ``tensor.select(2, index)`` is equivalent to ``tensor[:,:,index]``.\n",
      "     |  \n",
      "     |  set_(...)\n",
      "     |      set_(source=None, storage_offset=0, size=None, stride=None) -> Tensor\n",
      "     |      \n",
      "     |      Sets the underlying storage, size, and strides. If :attr:`source` is a tensor,\n",
      "     |      :attr:`self` tensor will share the same storage and have the same size and\n",
      "     |      strides as :attr:`source`. Changes to elements in one tensor will be reflected\n",
      "     |      in the other.\n",
      "     |      \n",
      "     |      If :attr:`source` is a :class:`~torch.Storage`, the method sets the underlying\n",
      "     |      storage, offset, size, and stride.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          source (Tensor or Storage): the tensor or storage to use\n",
      "     |          storage_offset (int, optional): the offset in the storage\n",
      "     |          size (torch.Size, optional): the desired size. Defaults to the size of the source.\n",
      "     |          stride (tuple, optional): the desired stride. Defaults to C-contiguous strides.\n",
      "     |  \n",
      "     |  share_memory_(self)\n",
      "     |      Moves the underlying storage to shared memory.\n",
      "     |      \n",
      "     |      This is a no-op if the underlying storage is already in shared memory\n",
      "     |      and for CUDA tensors. Tensors in shared memory cannot be resized.\n",
      "     |  \n",
      "     |  short(...)\n",
      "     |      short() -> Tensor\n",
      "     |      \n",
      "     |      ``self.short()`` is equivalent to ``self.to(torch.int16)``. See :func:`to`.\n",
      "     |  \n",
      "     |  sigmoid(...)\n",
      "     |      sigmoid() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sigmoid`\n",
      "     |  \n",
      "     |  sigmoid_(...)\n",
      "     |      sigmoid_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sigmoid`\n",
      "     |  \n",
      "     |  sign(...)\n",
      "     |      sign() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sign`\n",
      "     |  \n",
      "     |  sign_(...)\n",
      "     |      sign_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sign`\n",
      "     |  \n",
      "     |  sin(...)\n",
      "     |      sin() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sin`\n",
      "     |  \n",
      "     |  sin_(...)\n",
      "     |      sin_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sin`\n",
      "     |  \n",
      "     |  sinh(...)\n",
      "     |      sinh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sinh`\n",
      "     |  \n",
      "     |  sinh_(...)\n",
      "     |      sinh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sinh`\n",
      "     |  \n",
      "     |  size(...)\n",
      "     |      size() -> torch.Size\n",
      "     |      \n",
      "     |      Returns the size of the :attr:`self` tensor. The returned value is a subclass of\n",
      "     |      :class:`tuple`.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> torch.empty(3, 4, 5).size()\n",
      "     |          torch.Size([3, 4, 5])\n",
      "     |  \n",
      "     |  slice(...)\n",
      "     |  \n",
      "     |  slogdet(...)\n",
      "     |      slogdet() -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.slogdet`\n",
      "     |  \n",
      "     |  smm(...)\n",
      "     |  \n",
      "     |  sort(...)\n",
      "     |      sort(dim=None, descending=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.sort`\n",
      "     |  \n",
      "     |  split(self, split_size, dim=0)\n",
      "     |      See :func:`torch.split`\n",
      "     |  \n",
      "     |  split_with_sizes(...)\n",
      "     |  \n",
      "     |  sqrt(...)\n",
      "     |      sqrt() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sqrt`\n",
      "     |  \n",
      "     |  sqrt_(...)\n",
      "     |      sqrt_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sqrt`\n",
      "     |  \n",
      "     |  squeeze(...)\n",
      "     |      squeeze(dim=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.squeeze`\n",
      "     |  \n",
      "     |  squeeze_(...)\n",
      "     |      squeeze_(dim=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.squeeze`\n",
      "     |  \n",
      "     |  sspaddmm(...)\n",
      "     |  \n",
      "     |  std(...)\n",
      "     |      std(dim=None, unbiased=True, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.std`\n",
      "     |  \n",
      "     |  stft(...)\n",
      "     |      stft(frame_length, hop, fft_size=None, return_onesided=True, window=None, pad_end=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.stft`\n",
      "     |  \n",
      "     |  storage(...)\n",
      "     |      storage() -> torch.Storage\n",
      "     |      \n",
      "     |      Returns the underlying storage\n",
      "     |  \n",
      "     |  storage_offset(...)\n",
      "     |      storage_offset() -> int\n",
      "     |      \n",
      "     |      Returns :attr:`self` tensor's offset in the underlying storage in terms of\n",
      "     |      number of storage elements (not bytes).\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([1, 2, 3, 4, 5])\n",
      "     |          >>> x.storage_offset()\n",
      "     |          0\n",
      "     |          >>> x[3:].storage_offset()\n",
      "     |          3\n",
      "     |  \n",
      "     |  storage_type(...)\n",
      "     |  \n",
      "     |  stride(...)\n",
      "     |      stride(dim) -> tuple or int\n",
      "     |      \n",
      "     |      Returns the stride of :attr:`self` tensor.\n",
      "     |      \n",
      "     |      Stride is the jump necessary to go from one element to the next one in the\n",
      "     |      specified dimension :attr:`dim`. A tuple of all strides is returned when no\n",
      "     |      argument is passed in. Otherwise, an integer value is returned as the stride in\n",
      "     |      the particular dimension :attr:`dim`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int, optional): the desired dimension in which stride is required\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1, 2, 3, 4, 5], [6, 7, 8, 9, 10]])\n",
      "     |          >>> x.stride()\n",
      "     |          (5, 1)\n",
      "     |          >>>x.stride(0)\n",
      "     |          5\n",
      "     |          >>> x.stride(-1)\n",
      "     |          1\n",
      "     |  \n",
      "     |  sub(...)\n",
      "     |      sub(value, other) -> Tensor\n",
      "     |      \n",
      "     |      Subtracts a scalar or tensor from :attr:`self` tensor. If both :attr:`value` and\n",
      "     |      :attr:`other` are specified, each element of :attr:`other` is scaled by\n",
      "     |      :attr:`value` before being used.\n",
      "     |      \n",
      "     |      When :attr:`other` is a tensor, the shape of :attr:`other` must be\n",
      "     |      :ref:`broadcastable <broadcasting-semantics>` with the shape of the underlying\n",
      "     |      tensor.\n",
      "     |  \n",
      "     |  sub_(...)\n",
      "     |      sub_(x) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sub`\n",
      "     |  \n",
      "     |  sum(...)\n",
      "     |      sum(dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sum`\n",
      "     |  \n",
      "     |  svd(...)\n",
      "     |      svd(some=True) -> (Tensor, Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.svd`\n",
      "     |  \n",
      "     |  symeig(...)\n",
      "     |      symeig(eigenvectors=False, upper=True) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.symeig`\n",
      "     |  \n",
      "     |  t(...)\n",
      "     |      t() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.t`\n",
      "     |  \n",
      "     |  t_(...)\n",
      "     |      t_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.t`\n",
      "     |  \n",
      "     |  take(...)\n",
      "     |      take(indices) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.take`\n",
      "     |  \n",
      "     |  tan(...)\n",
      "     |  \n",
      "     |  tan_(...)\n",
      "     |      tan_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.tan`\n",
      "     |  \n",
      "     |  tanh(...)\n",
      "     |      tanh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tanh`\n",
      "     |  \n",
      "     |  tanh_(...)\n",
      "     |      tanh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.tanh`\n",
      "     |  \n",
      "     |  to(...)\n",
      "     |      to(*args, **kwargs) -> Tensor\n",
      "     |      \n",
      "     |      Performs Tensor dtype and/or device conversion. A :class:`torch.dtype` and :class:`torch.device` are\n",
      "     |      inferred from the arguments of ``self.to(*args, **kwargs)``.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          If the ``self`` Tensor already\n",
      "     |          has the correct :class:`torch.dtype` and :class:`torch.device`, then ``self`` is returned.\n",
      "     |          Otherwise, the returned tensor is a copy of ``self`` with the desired\n",
      "     |          :class:`torch.dtype` and :class:`torch.device`.\n",
      "     |      \n",
      "     |      Here are the ways to call ``to``:\n",
      "     |      \n",
      "     |      .. function:: to(dtype) -> Tensor\n",
      "     |      \n",
      "     |          Returns a Tensor with the specified :attr:`dtype`\n",
      "     |      \n",
      "     |      .. function:: to(device, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |          Returns a Tensor with the specified :attr:`device` and (optional)\n",
      "     |          :attr:`dtype`. If :attr:`dtype` is ``None`` it is inferred to be ``self.dtype``.\n",
      "     |      \n",
      "     |      .. function:: to(other) -> Tensor\n",
      "     |      \n",
      "     |          Returns a Tensor with same :class:`torch.dtype` and :class:`torch.device` as the Tensor\n",
      "     |          :attr:`other`.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.randn(2, 2)  # Initially dtype=float32, device=cpu\n",
      "     |          >>> tensor.to(torch.float64)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], dtype=torch.float64)\n",
      "     |      \n",
      "     |          >>> cuda0 = torch.device('cuda:0')\n",
      "     |          >>> tensor.to(cuda0)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], device='cuda:0')\n",
      "     |      \n",
      "     |          >>> tensor.to(cuda0, dtype=torch.float64)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], dtype=torch.float64, device='cuda:0')\n",
      "     |      \n",
      "     |          >>> other = torch.randn((), dtype=torch.float64, device=cuda0)\n",
      "     |          >>> tensor.to(other)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], dtype=torch.float64, device='cuda:0')\n",
      "     |  \n",
      "     |  to_dense(...)\n",
      "     |  \n",
      "     |  tolist(...)\n",
      "     |  \n",
      "     |  topk(...)\n",
      "     |      topk(k, dim=None, largest=True, sorted=True) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.topk`\n",
      "     |  \n",
      "     |  trace(...)\n",
      "     |      trace() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.trace`\n",
      "     |  \n",
      "     |  transpose(...)\n",
      "     |      transpose(dim0, dim1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.transpose`\n",
      "     |  \n",
      "     |  transpose_(...)\n",
      "     |      transpose_(dim0, dim1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.transpose`\n",
      "     |  \n",
      "     |  tril(...)\n",
      "     |      tril(k=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tril`\n",
      "     |  \n",
      "     |  tril_(...)\n",
      "     |      tril_(k=0) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.tril`\n",
      "     |  \n",
      "     |  triu(...)\n",
      "     |      triu(k=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.triu`\n",
      "     |  \n",
      "     |  triu_(...)\n",
      "     |      triu_(k=0) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.triu`\n",
      "     |  \n",
      "     |  trtrs(...)\n",
      "     |      trtrs(A, upper=True, transpose=False, unitriangular=False) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.trtrs`\n",
      "     |  \n",
      "     |  trunc(...)\n",
      "     |      trunc() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.trunc`\n",
      "     |  \n",
      "     |  trunc_(...)\n",
      "     |      trunc_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.trunc`\n",
      "     |  \n",
      "     |  type(...)\n",
      "     |      type(dtype=None, non_blocking=False, **kwargs) -> str or Tensor\n",
      "     |      Returns the type if `dtype` is not provided, else casts this object to\n",
      "     |      the specified type.\n",
      "     |      \n",
      "     |      If this is already of the correct type, no copy is performed and the\n",
      "     |      original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (type or string): The desired type\n",
      "     |          non_blocking (bool): If ``True``, and the source is in pinned memory\n",
      "     |              and destination is on the GPU or vice versa, the copy is performed\n",
      "     |              asynchronously with respect to the host. Otherwise, the argument\n",
      "     |              has no effect.\n",
      "     |          **kwargs: For compatibility, may contain the key ``async`` in place of\n",
      "     |              the ``non_blocking`` argument. The ``async`` arg is deprecated.\n",
      "     |  \n",
      "     |  type_as(...)\n",
      "     |      type_as(tensor) -> Tensor\n",
      "     |      \n",
      "     |      Returns this tensor cast to the type of the given tensor.\n",
      "     |      \n",
      "     |      This is a no-op if the tensor is already of the correct type. This is\n",
      "     |      equivalent to::\n",
      "     |      \n",
      "     |          self.type(tensor.type())\n",
      "     |      \n",
      "     |      Params:\n",
      "     |          tensor (Tensor): the tensor which has the desired type\n",
      "     |  \n",
      "     |  unfold(...)\n",
      "     |      unfold(dim, size, step) -> Tensor\n",
      "     |      \n",
      "     |      Returns a tensor which contains all slices of size :attr:`size` from\n",
      "     |      :attr:`self` tensor in the dimension :attr:`dim`.\n",
      "     |      \n",
      "     |      Step between two slices is given by :attr:`step`.\n",
      "     |      \n",
      "     |      If `sizedim` is the size of dimension dim for :attr:`self`, the size of\n",
      "     |      dimension :attr:`dim` in the returned tensor will be\n",
      "     |      `(sizedim - size) / step + 1`.\n",
      "     |      \n",
      "     |      An additional dimension of size size is appended in the returned tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension in which unfolding happens\n",
      "     |          size (int): the size of each slice that is unfolded\n",
      "     |          step (int): the step between each slice\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.arange(1, 8)\n",
      "     |          >>> x\n",
      "     |          tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.])\n",
      "     |          >>> x.unfold(0, 2, 1)\n",
      "     |          tensor([[ 1.,  2.],\n",
      "     |                  [ 2.,  3.],\n",
      "     |                  [ 3.,  4.],\n",
      "     |                  [ 4.,  5.],\n",
      "     |                  [ 5.,  6.],\n",
      "     |                  [ 6.,  7.]])\n",
      "     |          >>> x.unfold(0, 2, 2)\n",
      "     |          tensor([[ 1.,  2.],\n",
      "     |                  [ 3.,  4.],\n",
      "     |                  [ 5.,  6.]])\n",
      "     |  \n",
      "     |  uniform_(...)\n",
      "     |      uniform_(from=0, to=1) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with numbers sampled from the continuous uniform\n",
      "     |      distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |          P(x) = \\dfrac{1}{\\text{to} - \\text{from}}\n",
      "     |  \n",
      "     |  unique(self, sorted=False, return_inverse=False)\n",
      "     |      Returns the unique scalar elements of the tensor as a 1-D tensor.\n",
      "     |      \n",
      "     |      See :func:`torch.unique`\n",
      "     |  \n",
      "     |  unsqueeze(...)\n",
      "     |      unsqueeze(dim) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.unsqueeze`\n",
      "     |  \n",
      "     |  unsqueeze_(...)\n",
      "     |      unsqueeze_(dim) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.unsqueeze`\n",
      "     |  \n",
      "     |  var(...)\n",
      "     |      var(dim=None, unbiased=True, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.var`\n",
      "     |  \n",
      "     |  view(...)\n",
      "     |      view(*args) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new tensor with the same data as the :attr:`self` tensor but of a\n",
      "     |      different size.\n",
      "     |      \n",
      "     |      The returned tensor shares the same data and must have the same number\n",
      "     |      of elements, but may have a different size. For a tensor to be viewed, the new\n",
      "     |      view size must be compatible with its original size and stride, i.e., each new\n",
      "     |      view dimension must either be a subspace of an original dimension, or only span\n",
      "     |      across original dimensions :math:`d, d+1, \\dots, d+k` that satisfy the following\n",
      "     |      contiguity-like condition that :math:`\\forall i = 0, \\dots, k-1`,\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |        stride[i] = stride[i+1] \\times size[i+1]\n",
      "     |      \n",
      "     |      Otherwise, :func:`contiguous` needs to be called before the tensor can be\n",
      "     |      viewed.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          args (torch.Size or int...): the desired size\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.randn(4, 4)\n",
      "     |          >>> x.size()\n",
      "     |          torch.Size([4, 4])\n",
      "     |          >>> y = x.view(16)\n",
      "     |          >>> y.size()\n",
      "     |          torch.Size([16])\n",
      "     |          >>> z = x.view(-1, 8)  # the size -1 is inferred from other dimensions\n",
      "     |          >>> z.size()\n",
      "     |          torch.Size([2, 8])\n",
      "     |  \n",
      "     |  view_as(self, tensor)\n",
      "     |      view_as(other) -> Tensor\n",
      "     |      \n",
      "     |      View this tensor as the same size as :attr:`other`.\n",
      "     |      ``self.view_as(other)`` is equivalent to ``self.view(other.size())``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          other (:class:`torch.Tensor`): The result tensor has the same size\n",
      "     |              as :attr:`other.size()`.\n",
      "     |  \n",
      "     |  where(...)\n",
      "     |      where(condition, y) -> Tensor\n",
      "     |      \n",
      "     |      ``self.where(condition, y)`` is equivalent to ``torch.where(condition, self, y)``.\n",
      "     |      See :func:`torch.where`\n",
      "     |  \n",
      "     |  zero_(...)\n",
      "     |      zero_() -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with zeros.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  data\n",
      "     |  \n",
      "     |  device\n",
      "     |  \n",
      "     |  grad\n",
      "     |  \n",
      "     |  grad_fn\n",
      "     |  \n",
      "     |  is_leaf\n",
      "     |  \n",
      "     |  name\n",
      "     |  \n",
      "     |  output_nr\n",
      "     |  \n",
      "     |  requires_grad\n",
      "     |  \n",
      "     |  shape\n",
      "     |  \n",
      "     |  volatile\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  dtype = torch.float32\n",
      "     |  \n",
      "     |  is_cuda = False\n",
      "     |  \n",
      "     |  is_sparse = False\n",
      "     |  \n",
      "     |  layout = torch.strided\n",
      "    \n",
      "    class Generator(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  get_state(...)\n",
      "     |  \n",
      "     |  initial_seed(...)\n",
      "     |  \n",
      "     |  manual_seed(...)\n",
      "     |  \n",
      "     |  seed(...)\n",
      "     |  \n",
      "     |  set_state(...)\n",
      "    \n",
      "    class Graph(pybind11_builtins.pybind11_object)\n",
      "     |  Method resolution order:\n",
      "     |      Graph\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(...)\n",
      "     |      __init__(self: torch._C.Graph) -> None\n",
      "     |  \n",
      "     |  __repr__(...)\n",
      "     |      __repr__(self: torch._C.Graph) -> str\n",
      "     |  \n",
      "     |  addInput(...)\n",
      "     |      addInput(self: torch._C.Graph) -> torch::jit::Value\n",
      "     |  \n",
      "     |  advanceStage(...)\n",
      "     |      advanceStage(self: torch._C.Graph) -> None\n",
      "     |  \n",
      "     |  appendNode(...)\n",
      "     |      appendNode(self: torch._C.Graph, arg0: torch::jit::Node) -> torch::jit::Node\n",
      "     |  \n",
      "     |  create(...)\n",
      "     |      create(*args, **kwargs)\n",
      "     |      Overloaded function.\n",
      "     |      \n",
      "     |      1. create(self: torch._C.Graph, arg0: str) -> torch::jit::Node\n",
      "     |      \n",
      "     |      2. create(self: torch._C.Graph, arg0: str, arg1: int) -> torch::jit::Node\n",
      "     |      \n",
      "     |      3. create(self: torch._C.Graph, arg0: str, arg1: List[torch::jit::Value]) -> torch::jit::Node\n",
      "     |      \n",
      "     |      4. create(self: torch._C.Graph, arg0: str, arg1: List[torch::jit::Value], arg2: int) -> torch::jit::Node\n",
      "     |  \n",
      "     |  createClone(...)\n",
      "     |      createClone(self: torch._C.Graph, arg0: torch::jit::Node, arg1: object) -> torch::jit::Node\n",
      "     |  \n",
      "     |  createConstant(...)\n",
      "     |      createConstant(self: torch._C.Graph, arg0: at::Tensor) -> torch::jit::Node\n",
      "     |  \n",
      "     |  createFusionGroup(...)\n",
      "     |      createFusionGroup(self: torch._C.Graph, arg0: int) -> torch::jit::Node\n",
      "     |  \n",
      "     |  eraseInput(...)\n",
      "     |      eraseInput(self: torch._C.Graph, arg0: int) -> None\n",
      "     |  \n",
      "     |  inputs(...)\n",
      "     |      inputs(self: torch._C.Graph) -> iterator\n",
      "     |  \n",
      "     |  lint(...)\n",
      "     |      lint(self: torch._C.Graph) -> None\n",
      "     |  \n",
      "     |  nodes(...)\n",
      "     |      nodes(self: torch._C.Graph) -> iterator\n",
      "     |  \n",
      "     |  outputs(...)\n",
      "     |      outputs(self: torch._C.Graph) -> iterator\n",
      "     |  \n",
      "     |  prependNode(...)\n",
      "     |      prependNode(self: torch._C.Graph, arg0: torch::jit::Node) -> torch::jit::Node\n",
      "     |  \n",
      "     |  registerOutput(...)\n",
      "     |      registerOutput(self: torch._C.Graph, arg0: torch::jit::Value) -> int\n",
      "     |  \n",
      "     |  stage(...)\n",
      "     |      stage(self: torch._C.Graph) -> int\n",
      "     |  \n",
      "     |  wrapPyFuncWithSymbolic(...)\n",
      "     |      wrapPyFuncWithSymbolic(self: torch._C.Graph, arg0: function, arg1: List[torch::jit::Value], arg2: int, arg3: function) -> iterator\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class GraphExecutor(pybind11_builtins.pybind11_object)\n",
      "     |  Method resolution order:\n",
      "     |      GraphExecutor\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __call__(...)\n",
      "     |      __call__(self: torch._C.GraphExecutor, *args) -> object\n",
      "     |  \n",
      "     |  __init__(...)\n",
      "     |      __init__(*args, **kwargs)\n",
      "     |      Overloaded function.\n",
      "     |      \n",
      "     |      1. __init__(self: torch._C.GraphExecutor, func: function, inputs: List[torch::autograd::Variable], optimize: bool = True) -> None\n",
      "     |      \n",
      "     |      2. __init__(self: torch._C.GraphExecutor, graph: torch::jit::Graph, optimize: bool = True) -> None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  graph\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class IODescriptor(pybind11_builtins.pybind11_object)\n",
      "     |  Method resolution order:\n",
      "     |      IODescriptor\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class IntStorage(torch._C.IntStorageBase, torch.storage._StorageBase)\n",
      "     |  Method resolution order:\n",
      "     |      IntStorage\n",
      "     |      torch._C.IntStorageBase\n",
      "     |      torch.storage._StorageBase\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch._C.IntStorageBase:\n",
      "     |  \n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |  \n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |  \n",
      "     |  __len__(self, /)\n",
      "     |      Return len(self).\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  __setitem__(self, key, value, /)\n",
      "     |      Set self[key] to value.\n",
      "     |  \n",
      "     |  copy_(...)\n",
      "     |  \n",
      "     |  data_ptr(...)\n",
      "     |  \n",
      "     |  element_size(...)\n",
      "     |  \n",
      "     |  fill_(...)\n",
      "     |  \n",
      "     |  is_pinned(...)\n",
      "     |  \n",
      "     |  is_shared(...)\n",
      "     |  \n",
      "     |  new(...)\n",
      "     |  \n",
      "     |  resize_(...)\n",
      "     |  \n",
      "     |  size(...)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from torch._C.IntStorageBase:\n",
      "     |  \n",
      "     |  from_buffer(...)\n",
      "     |  \n",
      "     |  from_file(...)\n",
      "     |      from_file(filename, shared=False, size=0) -> Storage\n",
      "     |      \n",
      "     |      If `shared` is `True`, then memory is shared between all processes.\n",
      "     |      All changes are written to the file. If `shared` is `False`, then the changes on\n",
      "     |      the storage do not affect the file.\n",
      "     |      \n",
      "     |      `size` is the number of elements in the storage. If `shared` is `False`,\n",
      "     |      then the file must contain at least `size * sizeof(Type)` bytes\n",
      "     |      (`Type` is the type of storage). If `shared` is `True` the file will be\n",
      "     |      created if needed.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          filename (str): file name to map\n",
      "     |          shared (bool): whether to share memory\n",
      "     |          size (int): number of elements in the storage\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.storage._StorageBase:\n",
      "     |  \n",
      "     |  __copy__(self)\n",
      "     |  \n",
      "     |  __deepcopy__(self, memo)\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      helper for pickle\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __sizeof__(self)\n",
      "     |      __sizeof__() -> int\n",
      "     |      size of object in memory, in bytes\n",
      "     |  \n",
      "     |  __str__(self)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  byte(self)\n",
      "     |      Casts this storage to byte type\n",
      "     |  \n",
      "     |  char(self)\n",
      "     |      Casts this storage to char type\n",
      "     |  \n",
      "     |  clone(self)\n",
      "     |      Returns a copy of this storage\n",
      "     |  \n",
      "     |  cpu(self)\n",
      "     |      Returns a CPU copy of this storage if it's not already on the CPU\n",
      "     |  \n",
      "     |  cuda = _cuda(self, device=None, non_blocking=False, **kwargs)\n",
      "     |      Returns a copy of this object in CUDA memory.\n",
      "     |      \n",
      "     |      If this object is already in CUDA memory and on the correct device, then\n",
      "     |      no copy is performed and the original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          device (int): The destination GPU id. Defaults to the current device.\n",
      "     |          non_blocking (bool): If ``True`` and the source is in pinned memory,\n",
      "     |              the copy will be asynchronous with respect to the host. Otherwise,\n",
      "     |              the argument has no effect.\n",
      "     |          **kwargs: For compatibility, may contain the key ``async`` in place of\n",
      "     |              the ``non_blocking`` argument.\n",
      "     |  \n",
      "     |  double(self)\n",
      "     |      Casts this storage to double type\n",
      "     |  \n",
      "     |  float(self)\n",
      "     |      Casts this storage to float type\n",
      "     |  \n",
      "     |  half(self)\n",
      "     |      Casts this storage to half type\n",
      "     |  \n",
      "     |  int(self)\n",
      "     |      Casts this storage to int type\n",
      "     |  \n",
      "     |  long(self)\n",
      "     |      Casts this storage to long type\n",
      "     |  \n",
      "     |  pin_memory(self)\n",
      "     |      Copies the storage to pinned memory, if it's not already pinned.\n",
      "     |  \n",
      "     |  share_memory_(self)\n",
      "     |      Moves the storage to shared memory.\n",
      "     |      \n",
      "     |      This is a no-op for storages already in shared memory and for CUDA\n",
      "     |      storages, which do not need to be moved for sharing across processes.\n",
      "     |      Storages in shared memory cannot be resized.\n",
      "     |      \n",
      "     |      Returns: self\n",
      "     |  \n",
      "     |  short(self)\n",
      "     |      Casts this storage to short type\n",
      "     |  \n",
      "     |  tolist(self)\n",
      "     |      Returns a list containing the elements of this storage\n",
      "     |  \n",
      "     |  type = _type(self, dtype=None, non_blocking=False, **kwargs)\n",
      "     |      Returns the type if `dtype` is not provided, else casts this object to\n",
      "     |      the specified type.\n",
      "     |      \n",
      "     |      If this is already of the correct type, no copy is performed and the\n",
      "     |      original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (type or string): The desired type\n",
      "     |          non_blocking (bool): If ``True``, and the source is in pinned memory\n",
      "     |              and destination is on the GPU or vice versa, the copy is performed\n",
      "     |              asynchronously with respect to the host. Otherwise, the argument\n",
      "     |              has no effect.\n",
      "     |          **kwargs: For compatibility, may contain the key ``async`` in place of\n",
      "     |              the ``non_blocking`` argument. The ``async`` arg is deprecated.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.storage._StorageBase:\n",
      "     |  \n",
      "     |  is_cuda = False\n",
      "     |  \n",
      "     |  is_sparse = False\n",
      "    \n",
      "    class IntTensor(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __abs__ = abs(...)\n",
      "     |  \n",
      "     |  __add__(...)\n",
      "     |  \n",
      "     |  __and__(...)\n",
      "     |  \n",
      "     |  __array__(self, dtype=None)\n",
      "     |      # Numpy array interface, to support `numpy.asarray(tensor) -> ndarray`\n",
      "     |  \n",
      "     |  __array_wrap__(self, array)\n",
      "     |      # Wrap Numpy array again in a suitable tensor when done, to support e.g.\n",
      "     |      # `numpy.sin(tensor) -> tensor` or `numpy.greater(tensor, 0) -> ByteTensor`\n",
      "     |  \n",
      "     |  __bool__(...)\n",
      "     |  \n",
      "     |  __deepcopy__(self, memo)\n",
      "     |  \n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |  \n",
      "     |  __dir__(self)\n",
      "     |      __dir__() -> list\n",
      "     |      default dir() implementation\n",
      "     |  \n",
      "     |  __div__(...)\n",
      "     |  \n",
      "     |  __eq__ = eq(...)\n",
      "     |  \n",
      "     |  __float__(...)\n",
      "     |  \n",
      "     |  __format__(self, format_spec)\n",
      "     |      default object formatter\n",
      "     |  \n",
      "     |  __ge__ = ge(...)\n",
      "     |  \n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |  \n",
      "     |  __gt__ = gt(...)\n",
      "     |  \n",
      "     |  __hash__(self)\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __iadd__(...)\n",
      "     |  \n",
      "     |  __iand__(...)\n",
      "     |  \n",
      "     |  __idiv__(...)\n",
      "     |  \n",
      "     |  __ilshift__(...)\n",
      "     |  \n",
      "     |  __imul__(...)\n",
      "     |  \n",
      "     |  __index__(...)\n",
      "     |  \n",
      "     |  __int__(...)\n",
      "     |  \n",
      "     |  __invert__(...)\n",
      "     |  \n",
      "     |  __ior__(...)\n",
      "     |  \n",
      "     |  __ipow__(self, other)\n",
      "     |  \n",
      "     |  __irshift__(...)\n",
      "     |  \n",
      "     |  __isub__(...)\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |  \n",
      "     |  __itruediv__ = __idiv__(...)\n",
      "     |  \n",
      "     |  __ixor__(...)\n",
      "     |  \n",
      "     |  __le__ = le(...)\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |      Return len(self).\n",
      "     |  \n",
      "     |  __long__(...)\n",
      "     |  \n",
      "     |  __lshift__(...)\n",
      "     |  \n",
      "     |  __lt__ = lt(...)\n",
      "     |  \n",
      "     |  __matmul__(...)\n",
      "     |  \n",
      "     |  __mod__(...)\n",
      "     |  \n",
      "     |  __mul__(...)\n",
      "     |  \n",
      "     |  __ne__ = ne(...)\n",
      "     |  \n",
      "     |  __neg__ = neg(...)\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from tensortype\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  __nonzero__(...)\n",
      "     |  \n",
      "     |  __or__(...)\n",
      "     |  \n",
      "     |  __pow__ = pow(...)\n",
      "     |  \n",
      "     |  __radd__(...)\n",
      "     |  \n",
      "     |  __rdiv__(self, other)\n",
      "     |  \n",
      "     |  __reduce_ex__(self, proto)\n",
      "     |      helper for pickle\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __rmul__(...)\n",
      "     |  \n",
      "     |  __rpow__(self, other)\n",
      "     |  \n",
      "     |  __rshift__(...)\n",
      "     |  \n",
      "     |  __rsub__(self, other)\n",
      "     |  \n",
      "     |  __rtruediv__ = __rdiv__(self, other)\n",
      "     |  \n",
      "     |  __setitem__(self, key, value, /)\n",
      "     |      Set self[key] to value.\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |  \n",
      "     |  __sub__(...)\n",
      "     |  \n",
      "     |  __truediv__(...)\n",
      "     |  \n",
      "     |  __xor__(...)\n",
      "     |  \n",
      "     |  abs(...)\n",
      "     |      abs() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.abs`\n",
      "     |  \n",
      "     |  abs_(...)\n",
      "     |      abs_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.abs`\n",
      "     |  \n",
      "     |  acos(...)\n",
      "     |      acos() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.acos`\n",
      "     |  \n",
      "     |  acos_(...)\n",
      "     |      acos_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.acos`\n",
      "     |  \n",
      "     |  add(...)\n",
      "     |      add(value) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.add`\n",
      "     |  \n",
      "     |  add_(...)\n",
      "     |      add_(value) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.add`\n",
      "     |  \n",
      "     |  addbmm(...)\n",
      "     |      addbmm(beta=1, mat, alpha=1, batch1, batch2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addbmm`\n",
      "     |  \n",
      "     |  addbmm_(...)\n",
      "     |      addbmm_(beta=1, mat, alpha=1, batch1, batch2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addbmm`\n",
      "     |  \n",
      "     |  addcdiv(...)\n",
      "     |      addcdiv(value=1, tensor1, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addcdiv`\n",
      "     |  \n",
      "     |  addcdiv_(...)\n",
      "     |      addcdiv_(value=1, tensor1, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addcdiv`\n",
      "     |  \n",
      "     |  addcmul(...)\n",
      "     |      addcmul(value=1, tensor1, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addcmul`\n",
      "     |  \n",
      "     |  addcmul_(...)\n",
      "     |      addcmul_(value=1, tensor1, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addcmul`\n",
      "     |  \n",
      "     |  addmm(...)\n",
      "     |      addmm(beta=1, mat, alpha=1, mat1, mat2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addmm`\n",
      "     |  \n",
      "     |  addmm_(...)\n",
      "     |      addmm_(beta=1, mat, alpha=1, mat1, mat2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addmm`\n",
      "     |  \n",
      "     |  addmv(...)\n",
      "     |      addmv(beta=1, tensor, alpha=1, mat, vec) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addmv`\n",
      "     |  \n",
      "     |  addmv_(...)\n",
      "     |      addmv_(beta=1, tensor, alpha=1, mat, vec) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addmv`\n",
      "     |  \n",
      "     |  addr(...)\n",
      "     |      addr(beta=1, alpha=1, vec1, vec2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addr`\n",
      "     |  \n",
      "     |  addr_(...)\n",
      "     |      addr_(beta=1, alpha=1, vec1, vec2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addr`\n",
      "     |  \n",
      "     |  all(...)\n",
      "     |      all() -> bool\n",
      "     |      \n",
      "     |      Returns ``True`` if all elements in the tensor are non-zero, ``False`` otherwise.\n",
      "     |  \n",
      "     |  allclose(...)\n",
      "     |  \n",
      "     |  any(...)\n",
      "     |      any() -> bool\n",
      "     |      \n",
      "     |      Returns ``True`` if any elements in the tensor are non-zero, ``False`` otherwise.\n",
      "     |  \n",
      "     |  apply_(...)\n",
      "     |      apply_(callable) -> Tensor\n",
      "     |      \n",
      "     |      Applies the function :attr:`callable` to each element in the tensor, replacing\n",
      "     |      each element with the value returned by :attr:`callable`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          This function only works with CPU tensors and should not be used in code\n",
      "     |          sections that require high performance.\n",
      "     |  \n",
      "     |  argmax(self, dim=None, keepdim=False)\n",
      "     |      See :func:`torch.argmax`\n",
      "     |  \n",
      "     |  argmin(self, dim=None, keepdim=False)\n",
      "     |      See :func:`torch.argmin`\n",
      "     |  \n",
      "     |  as_strided(...)\n",
      "     |  \n",
      "     |  as_strided_(...)\n",
      "     |  \n",
      "     |  asin(...)\n",
      "     |      asin() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.asin`\n",
      "     |  \n",
      "     |  asin_(...)\n",
      "     |      asin_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.asin`\n",
      "     |  \n",
      "     |  atan(...)\n",
      "     |      atan() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.atan`\n",
      "     |  \n",
      "     |  atan2(...)\n",
      "     |      atan2(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.atan2`\n",
      "     |  \n",
      "     |  atan2_(...)\n",
      "     |      atan2_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.atan2`\n",
      "     |  \n",
      "     |  atan_(...)\n",
      "     |      atan_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.atan`\n",
      "     |  \n",
      "     |  backward(self, gradient=None, retain_graph=None, create_graph=False)\n",
      "     |      Computes the gradient of current tensor w.r.t. graph leaves.\n",
      "     |      \n",
      "     |      The graph is differentiated using the chain rule. If the tensor is\n",
      "     |      non-scalar (i.e. its data has more than one element) and requires\n",
      "     |      gradient, the function additionally requires specifying ``gradient``.\n",
      "     |      It should be a tensor of matching type and location, that contains\n",
      "     |      the gradient of the differentiated function w.r.t. ``self``.\n",
      "     |      \n",
      "     |      This function accumulates gradients in the leaves - you might need to\n",
      "     |      zero them before calling it.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          gradient (Tensor or None): Gradient w.r.t. the\n",
      "     |              tensor. If it is a tensor, it will be automatically converted\n",
      "     |              to a Tensor that does not require grad unless ``create_graph`` is True.\n",
      "     |              None values can be specified for scalar Tensors or ones that\n",
      "     |              don't require grad. If a None value would be acceptable then\n",
      "     |              this argument is optional.\n",
      "     |          retain_graph (bool, optional): If ``False``, the graph used to compute\n",
      "     |              the grads will be freed. Note that in nearly all cases setting\n",
      "     |              this option to True is not needed and often can be worked around\n",
      "     |              in a much more efficient way. Defaults to the value of\n",
      "     |              ``create_graph``.\n",
      "     |          create_graph (bool, optional): If ``True``, graph of the derivative will\n",
      "     |              be constructed, allowing to compute higher order derivative\n",
      "     |              products. Defaults to ``False``.\n",
      "     |  \n",
      "     |  baddbmm(...)\n",
      "     |      baddbmm(beta=1, alpha=1, batch1, batch2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.baddbmm`\n",
      "     |  \n",
      "     |  baddbmm_(...)\n",
      "     |      baddbmm_(beta=1, alpha=1, batch1, batch2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.baddbmm`\n",
      "     |  \n",
      "     |  bernoulli(...)\n",
      "     |      bernoulli() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bernoulli`\n",
      "     |  \n",
      "     |  bernoulli_(...)\n",
      "     |      bernoulli_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.bernoulli`\n",
      "     |  \n",
      "     |  bmm(...)\n",
      "     |      bmm(batch2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bmm`\n",
      "     |  \n",
      "     |  btrifact(self, info=None, pivot=True)\n",
      "     |      See :func:`torch.btrifact`\n",
      "     |  \n",
      "     |  btrifact_with_info(...)\n",
      "     |      btrifact_with_info(pivot=True) -> (Tensor, Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.btrifact_with_info`\n",
      "     |  \n",
      "     |  btrisolve(...)\n",
      "     |  \n",
      "     |  byte(...)\n",
      "     |      byte() -> Tensor\n",
      "     |      \n",
      "     |      ``self.byte()`` is equivalent to ``self.to(torch.uint8)``. See :func:`to`.\n",
      "     |  \n",
      "     |  cauchy_(...)\n",
      "     |      cauchy_(median=0, sigma=1, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills the tensor with numbers drawn from the Cauchy distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(x) = \\dfrac{1}{\\pi} \\dfrac{\\sigma}{(x - median)^2 + \\sigma^2}\n",
      "     |  \n",
      "     |  ceil(...)\n",
      "     |      ceil() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ceil`\n",
      "     |  \n",
      "     |  ceil_(...)\n",
      "     |      ceil_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ceil`\n",
      "     |  \n",
      "     |  char(...)\n",
      "     |      char() -> Tensor\n",
      "     |      \n",
      "     |      ``self.char()`` is equivalent to ``self.to(torch.int8)``. See :func:`to`.\n",
      "     |  \n",
      "     |  chunk(...)\n",
      "     |      chunk(chunks, dim=0) -> List of Tensors\n",
      "     |      \n",
      "     |      See :func:`torch.chunk`\n",
      "     |  \n",
      "     |  clamp(...)\n",
      "     |      clamp(min, max) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.clamp`\n",
      "     |  \n",
      "     |  clamp_(...)\n",
      "     |      clamp_(min, max) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.clamp`\n",
      "     |  \n",
      "     |  clone(...)\n",
      "     |      clone() -> Tensor\n",
      "     |      \n",
      "     |      Returns a copy of the :attr:`self` tensor. The copy has the same size and data\n",
      "     |      type as :attr:`self`.\n",
      "     |  \n",
      "     |  coalesce(...)\n",
      "     |  \n",
      "     |  contiguous(...)\n",
      "     |      contiguous() -> Tensor\n",
      "     |      \n",
      "     |      Returns a contiguous tensor containing the same data as :attr:`self` tensor. If\n",
      "     |      :attr:`self` tensor is contiguous, this function returns the :attr:`self`\n",
      "     |      tensor.\n",
      "     |  \n",
      "     |  conv_tbc(...)\n",
      "     |  \n",
      "     |  copy_(...)\n",
      "     |      copy_(src, non_blocking=False) -> Tensor\n",
      "     |      \n",
      "     |      Copies the elements from :attr:`src` into :attr:`self` tensor and returns\n",
      "     |      :attr:`self`.\n",
      "     |      \n",
      "     |      The :attr:`src` tensor must be :ref:`broadcastable <broadcasting-semantics>`\n",
      "     |      with the :attr:`self` tensor. It may be of a different data type or reside on a\n",
      "     |      different device.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          src (Tensor): the source tensor to copy from\n",
      "     |          non_blocking (bool): if ``True`` and this copy is between CPU and GPU,\n",
      "     |              the copy may occur asynchronously with respect to the host. For other\n",
      "     |              cases, this argument has no effect.\n",
      "     |  \n",
      "     |  cos(...)\n",
      "     |      cos() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cos`\n",
      "     |  \n",
      "     |  cos_(...)\n",
      "     |      cos_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.cos`\n",
      "     |  \n",
      "     |  cosh(...)\n",
      "     |      cosh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cosh`\n",
      "     |  \n",
      "     |  cosh_(...)\n",
      "     |      cosh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.cosh`\n",
      "     |  \n",
      "     |  cpu(...)\n",
      "     |  \n",
      "     |  cross(...)\n",
      "     |      cross(other, dim=-1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cross`\n",
      "     |  \n",
      "     |  cuda(...)\n",
      "     |      cuda(device=None, non_blocking=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a copy of this object in CUDA memory.\n",
      "     |      \n",
      "     |      If this object is already in CUDA memory and on the correct device,\n",
      "     |      then no copy is performed and the original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          device (:class:`torch.device`): The destination GPU device.\n",
      "     |              Defaults to the current CUDA device.\n",
      "     |          non_blocking (bool): If ``True`` and the source is in pinned memory,\n",
      "     |              the copy will be asynchronous with respect to the host.\n",
      "     |              Otherwise, the argument has no effect. Default: ``False``.\n",
      "     |  \n",
      "     |  cumprod(...)\n",
      "     |      cumprod(dim) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cumprod`\n",
      "     |  \n",
      "     |  cumsum(...)\n",
      "     |      cumsum(dim) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cumsum`\n",
      "     |  \n",
      "     |  data_ptr(...)\n",
      "     |      data_ptr() -> int\n",
      "     |      \n",
      "     |      Returns the address of the first element of :attr:`self` tensor.\n",
      "     |  \n",
      "     |  det(...)\n",
      "     |      det() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.det`\n",
      "     |  \n",
      "     |  detach(...)\n",
      "     |      Returns a new Tensor, detached from the current graph.\n",
      "     |      \n",
      "     |      The result will never require gradient.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |        Returned Tensor uses the same data tensor as the original one.\n",
      "     |        In-place modifications on either of them will be seen, and may trigger\n",
      "     |        errors in correctness checks.\n",
      "     |  \n",
      "     |  detach_(...)\n",
      "     |      Detaches the Tensor from the graph that created it, making it a leaf.\n",
      "     |      Views cannot be detached in-place.\n",
      "     |  \n",
      "     |  diag(...)\n",
      "     |      diag(diagonal=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diag`\n",
      "     |  \n",
      "     |  digamma(...)\n",
      "     |  \n",
      "     |  digamma_(...)\n",
      "     |  \n",
      "     |  dim(...)\n",
      "     |      dim() -> int\n",
      "     |      \n",
      "     |      Returns the number of dimensions of :attr:`self` tensor.\n",
      "     |  \n",
      "     |  dist(...)\n",
      "     |      dist(other, p=2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.dist`\n",
      "     |  \n",
      "     |  div(...)\n",
      "     |      div(value) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.div`\n",
      "     |  \n",
      "     |  div_(...)\n",
      "     |      div_(value) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.div`\n",
      "     |  \n",
      "     |  dot(...)\n",
      "     |      dot(tensor2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.dot`\n",
      "     |  \n",
      "     |  double(...)\n",
      "     |      double() -> Tensor\n",
      "     |      \n",
      "     |      ``self.double()`` is equivalent to ``self.to(torch.float64)``. See :func:`to`.\n",
      "     |  \n",
      "     |  eig(...)\n",
      "     |      eig(eigenvectors=False) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.eig`\n",
      "     |  \n",
      "     |  element_size(...)\n",
      "     |      element_size() -> int\n",
      "     |      \n",
      "     |      Returns the size in bytes of an individual element.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> torch.tensor([]).element_size()\n",
      "     |          4\n",
      "     |          >>> torch.tensor([], dtype=torch.uint8).element_size()\n",
      "     |          1\n",
      "     |  \n",
      "     |  eq(...)\n",
      "     |      eq(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.eq`\n",
      "     |  \n",
      "     |  eq_(...)\n",
      "     |      eq_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.eq`\n",
      "     |  \n",
      "     |  equal(...)\n",
      "     |      equal(other) -> bool\n",
      "     |      \n",
      "     |      See :func:`torch.equal`\n",
      "     |  \n",
      "     |  erf(...)\n",
      "     |      erf() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.erf`\n",
      "     |  \n",
      "     |  erf_(...)\n",
      "     |  \n",
      "     |  erfinv(...)\n",
      "     |      erfinv() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.erfinv`\n",
      "     |  \n",
      "     |  erfinv_(...)\n",
      "     |  \n",
      "     |  exp(...)\n",
      "     |      exp() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.exp`\n",
      "     |  \n",
      "     |  exp_(...)\n",
      "     |      exp_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.exp`\n",
      "     |  \n",
      "     |  expand(...)\n",
      "     |      expand(*sizes) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new view of the :attr:`self` tensor with singleton dimensions expanded\n",
      "     |      to a larger size.\n",
      "     |      \n",
      "     |      Passing -1 as the size for a dimension means not changing the size of\n",
      "     |      that dimension.\n",
      "     |      \n",
      "     |      Tensor can be also expanded to a larger number of dimensions, and the\n",
      "     |      new ones will be appended at the front. For the new dimensions, the\n",
      "     |      size cannot be set to -1.\n",
      "     |      \n",
      "     |      Expanding a tensor does not allocate new memory, but only creates a\n",
      "     |      new view on the existing tensor where a dimension of size one is\n",
      "     |      expanded to a larger size by setting the ``stride`` to 0. Any dimension\n",
      "     |      of size 1 can be expanded to an arbitrary value without allocating new\n",
      "     |      memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *sizes (torch.Size or int...): the desired expanded size\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1], [2], [3]])\n",
      "     |          >>> x.size()\n",
      "     |          torch.Size([3, 1])\n",
      "     |          >>> x.expand(3, 4)\n",
      "     |          tensor([[ 1,  1,  1,  1],\n",
      "     |                  [ 2,  2,  2,  2],\n",
      "     |                  [ 3,  3,  3,  3]])\n",
      "     |          >>> x.expand(-1, 4)   # -1 means not changing the size of that dimension\n",
      "     |          tensor([[ 1,  1,  1,  1],\n",
      "     |                  [ 2,  2,  2,  2],\n",
      "     |                  [ 3,  3,  3,  3]])\n",
      "     |  \n",
      "     |  expand_as(self, tensor)\n",
      "     |  \n",
      "     |  expm1(...)\n",
      "     |      expm1() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.expm1`\n",
      "     |  \n",
      "     |  expm1_(...)\n",
      "     |      expm1_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.expm1`\n",
      "     |  \n",
      "     |  exponential_(...)\n",
      "     |      exponential_(lambd=1, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with elements drawn from the exponential distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(x) = \\lambda e^{-\\lambda x}\n",
      "     |  \n",
      "     |  fft(...)\n",
      "     |      fft(signal_ndim, normalized=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fft`\n",
      "     |  \n",
      "     |  fill_(...)\n",
      "     |      fill_(value) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with the specified value.\n",
      "     |  \n",
      "     |  float(...)\n",
      "     |      float() -> Tensor\n",
      "     |      \n",
      "     |      ``self.float()`` is equivalent to ``self.to(torch.float32)``. See :func:`to`.\n",
      "     |  \n",
      "     |  floor(...)\n",
      "     |      floor() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.floor`\n",
      "     |  \n",
      "     |  floor_(...)\n",
      "     |      floor_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.floor`\n",
      "     |  \n",
      "     |  fmod(...)\n",
      "     |      fmod(divisor) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fmod`\n",
      "     |  \n",
      "     |  fmod_(...)\n",
      "     |      fmod_(divisor) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.fmod`\n",
      "     |  \n",
      "     |  frac(...)\n",
      "     |      frac() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.frac`\n",
      "     |  \n",
      "     |  frac_(...)\n",
      "     |      frac_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.frac`\n",
      "     |  \n",
      "     |  gather(...)\n",
      "     |      gather(dim, index) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.gather`\n",
      "     |  \n",
      "     |  ge(...)\n",
      "     |      ge(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ge`\n",
      "     |  \n",
      "     |  ge_(...)\n",
      "     |      ge_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ge`\n",
      "     |  \n",
      "     |  gels(...)\n",
      "     |      gels(A) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.gels`\n",
      "     |  \n",
      "     |  geometric_(...)\n",
      "     |      geometric_(p, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with elements drawn from the geometric distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(X=k) = (1 - p)^{k - 1} p\n",
      "     |  \n",
      "     |  geqrf(...)\n",
      "     |      geqrf() -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.geqrf`\n",
      "     |  \n",
      "     |  ger(...)\n",
      "     |      ger(vec2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ger`\n",
      "     |  \n",
      "     |  gesv(...)\n",
      "     |      gesv(A) -> Tensor, Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.gesv`\n",
      "     |  \n",
      "     |  get_device(...)\n",
      "     |  \n",
      "     |  gt(...)\n",
      "     |      gt(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.gt`\n",
      "     |  \n",
      "     |  gt_(...)\n",
      "     |      gt_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.gt`\n",
      "     |  \n",
      "     |  half(...)\n",
      "     |      half() -> Tensor\n",
      "     |      \n",
      "     |      ``self.half()`` is equivalent to ``self.to(torch.float16)``. See :func:`to`.\n",
      "     |  \n",
      "     |  histc(...)\n",
      "     |      histc(bins=100, min=0, max=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.histc`\n",
      "     |  \n",
      "     |  ifft(...)\n",
      "     |      ifft(signal_ndim, normalized=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ifft`\n",
      "     |  \n",
      "     |  index(...)\n",
      "     |      index(m) -> Tensor\n",
      "     |      \n",
      "     |      Selects elements from :attr:`self` tensor using a binary mask or along a given\n",
      "     |      dimension. The expression ``tensor.index(m)`` is equivalent to ``tensor[m]``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          m (int or ByteTensor or slice): the dimension or mask used to select elements\n",
      "     |  \n",
      "     |  index_add(self, dim, index, tensor)\n",
      "     |  \n",
      "     |  index_add_(...)\n",
      "     |      index_add_(dim, index, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Accumulate the elements of :attr:`tensor` into the :attr:`self` tensor by adding\n",
      "     |      to the indices in the order given in :attr:`index`. For example, if ``dim == 0``\n",
      "     |      and ``index[i] == j``, then the ``i``\\ th row of :attr:`tensor` is added to the\n",
      "     |      ``j``\\ th row of :attr:`self`.\n",
      "     |      \n",
      "     |      The :attr:`dim`\\ th dimension of :attr:`tensor` must have the same size as the\n",
      "     |      length of :attr:`index` (which must be a vector), and all other dimensions must\n",
      "     |      match :attr:`self`, or an error will be raised.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension along which to index\n",
      "     |          index (LongTensor): indices of :attr:`tensor` to select from\n",
      "     |          tensor (Tensor): the tensor containing values to add\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.ones(5, 3)\n",
      "     |          >>> t = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
      "     |          >>> index = torch.tensor([0, 4, 2])\n",
      "     |          >>> x.index_add_(0, index, t)\n",
      "     |          tensor([[  2.,   3.,   4.],\n",
      "     |                  [  1.,   1.,   1.],\n",
      "     |                  [  8.,   9.,  10.],\n",
      "     |                  [  1.,   1.,   1.],\n",
      "     |                  [  5.,   6.,   7.]])\n",
      "     |  \n",
      "     |  index_copy(self, dim, index, tensor)\n",
      "     |  \n",
      "     |  index_copy_(...)\n",
      "     |      index_copy_(dim, index, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Copies the elements of :attr:`tensor` into the :attr:`self` tensor by selecting\n",
      "     |      the indices in the order given in :attr:`index`. For example, if ``dim == 0``\n",
      "     |      and ``index[i] == j``, then the ``i``\\ th row of :attr:`tensor` is copied to the\n",
      "     |      ``j``\\ th row of :attr:`self`.\n",
      "     |      \n",
      "     |      The :attr:`dim`\\ th dimension of :attr:`tensor` must have the same size as the\n",
      "     |      length of :attr:`index` (which must be a vector), and all other dimensions must\n",
      "     |      match :attr:`self`, or an error will be raised.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension along which to index\n",
      "     |          index (LongTensor): indices of :attr:`tensor` to select from\n",
      "     |          tensor (Tensor): the tensor containing values to copy\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.zeros(5, 3)\n",
      "     |          >>> t = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
      "     |          >>> index = torch.tensor([0, 4, 2])\n",
      "     |          >>> x.index_copy_(0, index, t)\n",
      "     |          tensor([[ 1.,  2.,  3.],\n",
      "     |                  [ 0.,  0.,  0.],\n",
      "     |                  [ 7.,  8.,  9.],\n",
      "     |                  [ 0.,  0.,  0.],\n",
      "     |                  [ 4.,  5.,  6.]])\n",
      "     |  \n",
      "     |  index_fill(self, dim, index, value)\n",
      "     |  \n",
      "     |  index_fill_(...)\n",
      "     |      index_fill_(dim, index, val) -> Tensor\n",
      "     |      \n",
      "     |      Fills the elements of the :attr:`self` tensor with value :attr:`val` by\n",
      "     |      selecting the indices in the order given in :attr:`index`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension along which to index\n",
      "     |          index (LongTensor): indices of :attr:`self` tensor to fill in\n",
      "     |          val (float): the value to fill with\n",
      "     |      \n",
      "     |      Example::\n",
      "     |          >>> x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
      "     |          >>> index = torch.tensor([0, 2])\n",
      "     |          >>> x.index_fill_(1, index, -1)\n",
      "     |          tensor([[-1.,  2., -1.],\n",
      "     |                  [-1.,  5., -1.],\n",
      "     |                  [-1.,  8., -1.]])\n",
      "     |  \n",
      "     |  index_put_(...)\n",
      "     |      index_put_(indices, value) -> Tensor\n",
      "     |      \n",
      "     |      Puts values from the tensor :attr:`value` into the tensor :attr:`self` using\n",
      "     |      the indices specified in :attr:`indices` (which is a tuple of Tensors). The\n",
      "     |      expression ``tensor.index_put_(indices, value)`` is equivalent to\n",
      "     |      ``tensor[indices] = value``. Returns :attr:`self`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          indices (tuple of LongTensor): tensors used to index into `self`.\n",
      "     |          value (Tensor): tensor of same dtype as `self`.\n",
      "     |  \n",
      "     |  index_select(...)\n",
      "     |      index_select(dim, index) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.index_select`\n",
      "     |  \n",
      "     |  int(...)\n",
      "     |      int() -> Tensor\n",
      "     |      \n",
      "     |      ``self.int()`` is equivalent to ``self.to(torch.int32)``. See :func:`to`.\n",
      "     |  \n",
      "     |  inverse(...)\n",
      "     |      inverse() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.inverse`\n",
      "     |  \n",
      "     |  irfft(...)\n",
      "     |      irfft(signal_ndim, normalized=False, onesided=True, signal_sizes=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.irfft`\n",
      "     |  \n",
      "     |  is_coalesced(...)\n",
      "     |  \n",
      "     |  is_contiguous(...)\n",
      "     |      is_contiguous() -> bool\n",
      "     |      \n",
      "     |      Returns True if :attr:`self` tensor is contiguous in memory in C order.\n",
      "     |  \n",
      "     |  is_distributed(...)\n",
      "     |  \n",
      "     |  is_floating_point(...)\n",
      "     |  \n",
      "     |  is_nonzero(...)\n",
      "     |  \n",
      "     |  is_pinned(self)\n",
      "     |      Returns true if this tensor resides in pinned memory\n",
      "     |  \n",
      "     |  is_same_size(...)\n",
      "     |  \n",
      "     |  is_set_to(...)\n",
      "     |      is_set_to(tensor) -> bool\n",
      "     |      \n",
      "     |      Returns True if this object refers to the same ``THTensor`` object from the\n",
      "     |      Torch C API as the given tensor.\n",
      "     |  \n",
      "     |  is_shared(self)\n",
      "     |      Checks if tensor is in shared memory.\n",
      "     |      \n",
      "     |      This is always ``True`` for CUDA tensors.\n",
      "     |  \n",
      "     |  is_signed(...)\n",
      "     |  \n",
      "     |  isclose(...)\n",
      "     |  \n",
      "     |  item(...)\n",
      "     |      item() -> number\n",
      "     |      \n",
      "     |      Returns the value of this tensor as a standard Python number. This only works\n",
      "     |      for tensors with one element.\n",
      "     |      \n",
      "     |      This operation is not differentiable.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([1.0])\n",
      "     |          >>> x.item()\n",
      "     |          1.0\n",
      "     |  \n",
      "     |  kthvalue(...)\n",
      "     |      kthvalue(k, dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.kthvalue`\n",
      "     |  \n",
      "     |  le(...)\n",
      "     |      le(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.le`\n",
      "     |  \n",
      "     |  le_(...)\n",
      "     |      le_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.le`\n",
      "     |  \n",
      "     |  lerp(...)\n",
      "     |      lerp(start, end, weight) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lerp`\n",
      "     |  \n",
      "     |  lerp_(...)\n",
      "     |      lerp_(start, end, weight) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lerp`\n",
      "     |  \n",
      "     |  lgamma(...)\n",
      "     |  \n",
      "     |  lgamma_(...)\n",
      "     |  \n",
      "     |  log(...)\n",
      "     |      log() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log`\n",
      "     |  \n",
      "     |  log10(...)\n",
      "     |      log10() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log10`\n",
      "     |  \n",
      "     |  log10_(...)\n",
      "     |      log10_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log10`\n",
      "     |  \n",
      "     |  log1p(...)\n",
      "     |      log1p() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log1p`\n",
      "     |  \n",
      "     |  log1p_(...)\n",
      "     |      log1p_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log1p`\n",
      "     |  \n",
      "     |  log2(...)\n",
      "     |      log2() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log2`\n",
      "     |  \n",
      "     |  log2_(...)\n",
      "     |      log2_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log2`\n",
      "     |  \n",
      "     |  log_(...)\n",
      "     |      log_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log`\n",
      "     |  \n",
      "     |  log_normal_(...)\n",
      "     |      log_normal_(mean=1, std=2, *, generator=None)\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with numbers samples from the log-normal distribution\n",
      "     |      parameterized by the given mean (µ) and standard deviation (σ).\n",
      "     |      Note that :attr:`mean` and :attr:`stdv` are the mean and standard deviation of\n",
      "     |      the underlying normal distribution, and not of the returned distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(x) = \\dfrac{1}{x \\sigma \\sqrt{2\\pi}}\\ e^{-\\dfrac{(\\ln x - \\mu)^2}{2\\sigma^2}}\n",
      "     |  \n",
      "     |  logdet(...)\n",
      "     |      logdet() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logdet`\n",
      "     |  \n",
      "     |  long(...)\n",
      "     |      long() -> Tensor\n",
      "     |      \n",
      "     |      ``self.long()`` is equivalent to ``self.to(torch.int64)``. See :func:`to`.\n",
      "     |  \n",
      "     |  lt(...)\n",
      "     |      lt(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lt`\n",
      "     |  \n",
      "     |  lt_(...)\n",
      "     |      lt_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lt`\n",
      "     |  \n",
      "     |  map2_(...)\n",
      "     |  \n",
      "     |  map_(...)\n",
      "     |      map_(tensor, callable)\n",
      "     |      \n",
      "     |      Applies :attr:`callable` for each element in :attr:`self` tensor and the given\n",
      "     |      :attr:`tensor` and stores the results in :attr:`self` tensor. :attr:`self` tensor and\n",
      "     |      the given :attr:`tensor` must be :ref:`broadcastable <broadcasting-semantics>`.\n",
      "     |      \n",
      "     |      The :attr:`callable` should have the signature::\n",
      "     |      \n",
      "     |          def callable(a, b) -> number\n",
      "     |  \n",
      "     |  masked_copy(self, mask, tensor)\n",
      "     |  \n",
      "     |  masked_copy_(self, mask, tensor)\n",
      "     |  \n",
      "     |  masked_fill(self, mask, value)\n",
      "     |  \n",
      "     |  masked_fill_(...)\n",
      "     |      masked_fill_(mask, value)\n",
      "     |      \n",
      "     |      Fills elements of :attr:`self` tensor with :attr:`value` where :attr:`mask` is\n",
      "     |      one. The shape of :attr:`mask` must be\n",
      "     |      :ref:`broadcastable <broadcasting-semantics>` with the shape of the underlying\n",
      "     |      tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          mask (ByteTensor): the binary mask\n",
      "     |          value (float): the value to fill in with\n",
      "     |  \n",
      "     |  masked_scatter(self, mask, tensor)\n",
      "     |  \n",
      "     |  masked_scatter_(...)\n",
      "     |      masked_scatter_(mask, source)\n",
      "     |      \n",
      "     |      Copies elements from :attr:`source` into :attr:`self` tensor at positions where\n",
      "     |      the :attr:`mask` is one.\n",
      "     |      The shape of :attr:`mask` must be :ref:`broadcastable <broadcasting-semantics>`\n",
      "     |      with the shape of the underlying tensor. The :attr:`source` should have at least\n",
      "     |      as many elements as the number of ones in :attr:`mask`\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          mask (ByteTensor): the binary mask\n",
      "     |          source (Tensor): the tensor to copy from\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The :attr:`mask` operates on the :attr:`self` tensor, not on the given\n",
      "     |          :attr:`source` tensor.\n",
      "     |  \n",
      "     |  masked_select(...)\n",
      "     |      masked_select(mask) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.masked_select`\n",
      "     |  \n",
      "     |  matmul(...)\n",
      "     |      matmul(tensor2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.matmul`\n",
      "     |  \n",
      "     |  max(...)\n",
      "     |      max(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.max`\n",
      "     |  \n",
      "     |  mean(...)\n",
      "     |      mean(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.mean`\n",
      "     |  \n",
      "     |  median(...)\n",
      "     |      median(dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.median`\n",
      "     |  \n",
      "     |  min(...)\n",
      "     |      min(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.min`\n",
      "     |  \n",
      "     |  mm(...)\n",
      "     |      mm(mat2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mm`\n",
      "     |  \n",
      "     |  mode(...)\n",
      "     |      mode(dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.mode`\n",
      "     |  \n",
      "     |  mul(...)\n",
      "     |      mul(value) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mul`\n",
      "     |  \n",
      "     |  mul_(...)\n",
      "     |      mul_(value)\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.mul`\n",
      "     |  \n",
      "     |  multinomial(...)\n",
      "     |      multinomial(num_samples, replacement=False, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.multinomial`\n",
      "     |  \n",
      "     |  mv(...)\n",
      "     |      mv(vec) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mv`\n",
      "     |  \n",
      "     |  narrow(...)\n",
      "     |      narrow(dimension, start, length) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new tensor that is a narrowed version of :attr:`self` tensor. The\n",
      "     |      dimension :attr:`dim` is narrowed from :attr:`start` to :attr:`start + length`. The\n",
      "     |      returned tensor and :attr:`self` tensor share the same underlying storage.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dimension (int): the dimension along which to narrow\n",
      "     |          start (int): the starting dimension\n",
      "     |          length (int): the distance to the ending dimension\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
      "     |          >>> x.narrow(0, 0, 2)\n",
      "     |          tensor([[ 1,  2,  3],\n",
      "     |                  [ 4,  5,  6]])\n",
      "     |          >>> x.narrow(1, 1, 2)\n",
      "     |          tensor([[ 2,  3],\n",
      "     |                  [ 5,  6],\n",
      "     |                  [ 8,  9]])\n",
      "     |  \n",
      "     |  ndimension(...)\n",
      "     |      ndimension() -> int\n",
      "     |      \n",
      "     |      Alias for :meth:`~Tensor.dim()`\n",
      "     |  \n",
      "     |  ne(...)\n",
      "     |      ne(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ne`\n",
      "     |  \n",
      "     |  ne_(...)\n",
      "     |      ne_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ne`\n",
      "     |  \n",
      "     |  neg(...)\n",
      "     |      neg() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.neg`\n",
      "     |  \n",
      "     |  neg_(...)\n",
      "     |      neg_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.neg`\n",
      "     |  \n",
      "     |  nelement(...)\n",
      "     |      nelement() -> int\n",
      "     |      \n",
      "     |      Alias for :meth:`~Tensor.numel`\n",
      "     |  \n",
      "     |  new(...)\n",
      "     |  \n",
      "     |  new_empty(...)\n",
      "     |      new_empty(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with uninitialized data.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones(())\n",
      "     |          >>> tensor.new_empty((2, 3))\n",
      "     |          tensor([[ 5.8182e-18,  4.5765e-41, -1.0545e+30],\n",
      "     |                  [ 3.0949e-41,  4.4842e-44,  0.0000e+00]])\n",
      "     |  \n",
      "     |  new_full(...)\n",
      "     |      new_full(size, fill_value, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with :attr:`fill_value`.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          fill_value (scalar): the number to fill the output tensor with.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones((2,), dtype=torch.float64)\n",
      "     |          >>> tensor.new_full((3, 4), 3.141592)\n",
      "     |          tensor([[ 3.1416,  3.1416,  3.1416,  3.1416],\n",
      "     |                  [ 3.1416,  3.1416,  3.1416,  3.1416],\n",
      "     |                  [ 3.1416,  3.1416,  3.1416,  3.1416]], dtype=torch.float64)\n",
      "     |  \n",
      "     |  new_ones(...)\n",
      "     |      new_ones(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with ``1``.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (int...): a list, tuple, or :class:`torch.Size` of integers defining the\n",
      "     |              shape of the output tensor.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.tensor((), dtype=torch.int32)\n",
      "     |          >>> tensor.new_ones((2, 3))\n",
      "     |          tensor([[ 1,  1,  1],\n",
      "     |                  [ 1,  1,  1]], dtype=torch.int32)\n",
      "     |  \n",
      "     |  new_tensor(...)\n",
      "     |      new_tensor(data, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new Tensor with :attr:`data` as the tensor data.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          :func:`new_tensor` always copies :attr:`data`. If you have a Tensor\n",
      "     |          ``data`` and want to avoid a copy, use :func:`torch.Tensor.requires_grad_`\n",
      "     |          or :func:`torch.Tensor.detach`.\n",
      "     |          If you have a numpy array and want to avoid a copy, use\n",
      "     |          :func:`torch.from_numpy`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          data (array_like): The returned Tensor copies :attr:`data`.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones((2,), dtype=torch.int8)\n",
      "     |          >>> data = [[0, 1], [2, 3]]\n",
      "     |          >>> tensor.new_tensor(data)\n",
      "     |          tensor([[ 0,  1],\n",
      "     |                  [ 2,  3]], dtype=torch.int8)\n",
      "     |  \n",
      "     |  new_zeros(...)\n",
      "     |      new_zeros(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with ``0``.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (int...): a list, tuple, or :class:`torch.Size` of integers defining the\n",
      "     |              shape of the output tensor.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.tensor((), dtype=torch.float64)\n",
      "     |          >>> tensor.new_ones((2, 3))\n",
      "     |          tensor([[ 1.,  1.,  1.],\n",
      "     |                  [ 1.,  1.,  1.]], dtype=torch.float64)\n",
      "     |  \n",
      "     |  nonzero(...)\n",
      "     |      nonzero() -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.nonzero`\n",
      "     |  \n",
      "     |  norm(...)\n",
      "     |      norm(p=2, dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.norm`\n",
      "     |  \n",
      "     |  normal_(...)\n",
      "     |      normal_(mean=0, std=1, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with elements samples from the normal distribution\n",
      "     |      parameterized by :attr:`mean` and :attr:`std`.\n",
      "     |  \n",
      "     |  numel(...)\n",
      "     |      numel() -> int\n",
      "     |      \n",
      "     |      See :func:`torch.numel`\n",
      "     |  \n",
      "     |  numpy(...)\n",
      "     |      numpy() -> numpy.ndarray\n",
      "     |      \n",
      "     |      Returns :attr:`self` tensor as a NumPy :class:`ndarray`. This tensor and the\n",
      "     |      returned :class:`ndarray` share the same underlying storage. Changes to\n",
      "     |      :attr:`self` tensor will be reflected in the :class:`ndarray` and vice versa.\n",
      "     |  \n",
      "     |  orgqr(...)\n",
      "     |      orgqr(input2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.orgqr`\n",
      "     |  \n",
      "     |  ormqr(...)\n",
      "     |      ormqr(input2, input3, left=True, transpose=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ormqr`\n",
      "     |  \n",
      "     |  permute(...)\n",
      "     |  \n",
      "     |  pin_memory(...)\n",
      "     |  \n",
      "     |  polygamma(...)\n",
      "     |  \n",
      "     |  polygamma_(...)\n",
      "     |  \n",
      "     |  potrf(...)\n",
      "     |      potrf(upper=True) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.potrf`\n",
      "     |  \n",
      "     |  potri(...)\n",
      "     |      potri(upper=True) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.potri`\n",
      "     |  \n",
      "     |  potrs(...)\n",
      "     |      potrs(input2, upper=True) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.potrs`\n",
      "     |  \n",
      "     |  pow(...)\n",
      "     |      pow(exponent) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.pow`\n",
      "     |  \n",
      "     |  pow_(...)\n",
      "     |      pow_(exponent) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.pow`\n",
      "     |  \n",
      "     |  prod(...)\n",
      "     |      prod(dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.prod`\n",
      "     |  \n",
      "     |  pstrf(...)\n",
      "     |      pstrf(upper=True, tol=-1) -> (Tensor, IntTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.pstrf`\n",
      "     |  \n",
      "     |  put_(...)\n",
      "     |      put_(indices, tensor, accumulate=False) -> Tensor\n",
      "     |      \n",
      "     |      Copies the elements from :attr:`tensor` into the positions specified by\n",
      "     |      indices. For the purpose of indexing, the :attr:`self` tensor is treated as if\n",
      "     |      it were a 1-D tensor.\n",
      "     |      \n",
      "     |      If :attr:`accumulate` is ``True``, the elements in :attr:`tensor` are added to\n",
      "     |      :attr:`self`. If accumulate is ``False``, the behavior is undefined if indices\n",
      "     |      contain duplicate elements.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          indices (LongTensor): the indices into self\n",
      "     |          tensor (Tensor): the tensor containing values to copy from\n",
      "     |          accumulate (bool): whether to accumulate into self\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> src = torch.tensor([[4, 3, 5],\n",
      "     |                                  [6, 7, 8]])\n",
      "     |          >>> src.put_(torch.tensor([1, 3]), torch.tensor([9, 10]))\n",
      "     |          tensor([[  4,   9,   5],\n",
      "     |                  [ 10,   7,   8]])\n",
      "     |  \n",
      "     |  qr(...)\n",
      "     |      qr() -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.qr`\n",
      "     |  \n",
      "     |  random_(...)\n",
      "     |      random_(from=0, to=None, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with numbers sampled from the discrete uniform\n",
      "     |      distribution over ``[from, to - 1]``. If not specified, the values are usually\n",
      "     |      only bounded by :attr:`self` tensor's data type. However, for floating point\n",
      "     |      types, if unspecified, range will be ``[0, 2^mantissa]`` to ensure that every\n",
      "     |      value is representable. For example, `torch.tensor(1, dtype=torch.double).random_()`\n",
      "     |      will be uniform in ``[0, 2^53]``.\n",
      "     |  \n",
      "     |  reciprocal(...)\n",
      "     |      reciprocal() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.reciprocal`\n",
      "     |  \n",
      "     |  reciprocal_(...)\n",
      "     |      reciprocal_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.reciprocal`\n",
      "     |  \n",
      "     |  record_stream(...)\n",
      "     |  \n",
      "     |  register_hook(self, hook)\n",
      "     |      Registers a backward hook.\n",
      "     |      \n",
      "     |      The hook will be called every time a gradient with respect to the\n",
      "     |      Tensor is computed. The hook should have the following signature::\n",
      "     |      \n",
      "     |          hook(grad) -> Tensor or None\n",
      "     |      \n",
      "     |      The hook should not modify its argument, but it can optionally return\n",
      "     |      a new gradient which will be used in place of :attr:`grad`.\n",
      "     |      \n",
      "     |      This function returns a handle with a method ``handle.remove()``\n",
      "     |      that removes the hook from the module.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          >>> v = torch.tensor([0., 0., 0.], requires_grad=True)\n",
      "     |          >>> h = v.register_hook(lambda grad: grad * 2)  # double the gradient\n",
      "     |          >>> v.backward(torch.tensor([1., 2., 3.]))\n",
      "     |          >>> v.grad\n",
      "     |      \n",
      "     |           2\n",
      "     |           4\n",
      "     |           6\n",
      "     |          [torch.FloatTensor of size (3,)]\n",
      "     |      \n",
      "     |          >>> h.remove()  # removes the hook\n",
      "     |  \n",
      "     |  reinforce(self, reward)\n",
      "     |  \n",
      "     |  relu(...)\n",
      "     |  \n",
      "     |  relu_(...)\n",
      "     |  \n",
      "     |  remainder(...)\n",
      "     |      remainder(divisor) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.remainder`\n",
      "     |  \n",
      "     |  remainder_(...)\n",
      "     |      remainder_(divisor) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.remainder`\n",
      "     |  \n",
      "     |  renorm(...)\n",
      "     |      renorm(p, dim, maxnorm) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.renorm`\n",
      "     |  \n",
      "     |  renorm_(...)\n",
      "     |      renorm_(p, dim, maxnorm) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.renorm`\n",
      "     |  \n",
      "     |  repeat(...)\n",
      "     |      repeat(*sizes) -> Tensor\n",
      "     |      \n",
      "     |      Repeats this tensor along the specified dimensions.\n",
      "     |      \n",
      "     |      Unlike :meth:`~Tensor.expand`, this function copies the tensor's data.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          sizes (torch.Size or int...): The number of times to repeat this tensor along each\n",
      "     |              dimension\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([1, 2, 3])\n",
      "     |          >>> x.repeat(4, 2)\n",
      "     |          tensor([[ 1,  2,  3,  1,  2,  3],\n",
      "     |                  [ 1,  2,  3,  1,  2,  3],\n",
      "     |                  [ 1,  2,  3,  1,  2,  3],\n",
      "     |                  [ 1,  2,  3,  1,  2,  3]])\n",
      "     |          >>> x.repeat(4, 2, 1).size()\n",
      "     |          torch.Size([4, 2, 3])\n",
      "     |  \n",
      "     |  requires_grad_(...)\n",
      "     |      requires_grad_(requires_grad=True) -> Tensor\n",
      "     |      \n",
      "     |      Change if autograd should record operations on this tensor: sets this tensor's\n",
      "     |      :attr:`requires_grad` attribute in-place. Returns this tensor.\n",
      "     |      \n",
      "     |      :func:`require_grad_`'s main use case is to tell autograd to begin recording\n",
      "     |      operations on a Tensor ``tensor``. If ``tensor`` has ``requires_grad=False``\n",
      "     |      (because it was obtained through a DataLoader, or required preprocessing or\n",
      "     |      initialization), ``tensor.requires_grad_()`` makes it so that autograd will\n",
      "     |      begin to record operations on ``tensor``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          requires_grad (bool): If autograd should record operations on this tensor.\n",
      "     |              Default: ``True``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> # Let's say we want to preprocess some saved weights and use\n",
      "     |          >>> # the result as new weights.\n",
      "     |          >>> saved_weights = [0.1, 0.2, 0.3, 0.25]\n",
      "     |          >>> loaded_weights = torch.tensor(saved_weights)\n",
      "     |          >>> weights = preprocess(loaded_weights)  # some function\n",
      "     |          >>> weights\n",
      "     |          tensor([-0.5503,  0.4926, -2.1158, -0.8303])\n",
      "     |      \n",
      "     |          >>> # Now, start to record operations done to weights\n",
      "     |          >>> weights.requires_grad_()\n",
      "     |          >>> out = weights.pow(2).sum()\n",
      "     |          >>> out.backward()\n",
      "     |          >>> weights.grad\n",
      "     |          tensor([-1.1007,  0.9853, -4.2316, -1.6606])\n",
      "     |  \n",
      "     |  reshape(...)\n",
      "     |      reshape(*shape) -> Tensor\n",
      "     |      \n",
      "     |      Returns a tensor with the same data and number of elements as :attr:`self`,\n",
      "     |      but with the specified shape.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          shape (tuple of ints or int...): the desired shape\n",
      "     |      \n",
      "     |      See :func:`torch.reshape`\n",
      "     |  \n",
      "     |  resize(self, *sizes)\n",
      "     |  \n",
      "     |  resize_(...)\n",
      "     |      resize_(*sizes) -> Tensor\n",
      "     |      \n",
      "     |      Resizes :attr:`self` tensor to the specified size. If the number of elements is\n",
      "     |      larger than the current storage size, then the underlying storage is resized\n",
      "     |      to fit the new number of elements. If the number of elements is smaller, the\n",
      "     |      underlying storage is not changed. Existing elements are preserved but any new\n",
      "     |      memory is uninitialized.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          sizes (torch.Size or int...): the desired size\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1, 2], [3, 4], [5, 6]])\n",
      "     |          >>> x.resize_(2, 2)\n",
      "     |          tensor([[ 1,  2],\n",
      "     |                  [ 3,  4]])\n",
      "     |  \n",
      "     |  resize_as(self, tensor)\n",
      "     |  \n",
      "     |  resize_as_(...)\n",
      "     |      resize_as_(tensor) -> Tensor\n",
      "     |      \n",
      "     |      Resizes the :attr:`self` tensor to be the same size as the specified\n",
      "     |      :attr:`tensor`. This is equivalent to ``self.resize_(tensor.size())``.\n",
      "     |  \n",
      "     |  retain_grad(self)\n",
      "     |      Enables .grad attribute for non-leaf Tensors.\n",
      "     |  \n",
      "     |  rfft(...)\n",
      "     |      rfft(signal_ndim, normalized=False, onesided=True) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.rfft`\n",
      "     |  \n",
      "     |  round(...)\n",
      "     |      round() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.round`\n",
      "     |  \n",
      "     |  round_(...)\n",
      "     |      round_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.round`\n",
      "     |  \n",
      "     |  rsqrt(...)\n",
      "     |      rsqrt() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.rsqrt`\n",
      "     |  \n",
      "     |  rsqrt_(...)\n",
      "     |      rsqrt_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.rsqrt`\n",
      "     |  \n",
      "     |  scatter(self, dim, index, source)\n",
      "     |  \n",
      "     |  scatter_(...)\n",
      "     |      scatter_(dim, index, src) -> Tensor\n",
      "     |      \n",
      "     |      Writes all values from the tensor :attr:`src` into :attr:`self` at the indices\n",
      "     |      specified in the :attr:`index` tensor. For each value in :attr:`src`, its output\n",
      "     |      index is specified by its index in :attr:`src` for dimension != :attr:`dim` and\n",
      "     |      by the corresponding value in :attr:`index` for dimension = :attr:`dim`.\n",
      "     |      \n",
      "     |      For a 3-D tensor, :attr:`self` is updated as::\n",
      "     |      \n",
      "     |          self[index[i][j][k]][j][k] = src[i][j][k]  # if dim == 0\n",
      "     |          self[i][index[i][j][k]][k] = src[i][j][k]  # if dim == 1\n",
      "     |          self[i][j][index[i][j][k]] = src[i][j][k]  # if dim == 2\n",
      "     |      \n",
      "     |      This is the reverse operation of the manner described in :meth:`~Tensor.gather`.\n",
      "     |      \n",
      "     |      :attr:`self`, :attr:`index` and :attr:`src` should have same number of\n",
      "     |      dimensions. It is also required that `index->size[d] <= src->size[d]` for all\n",
      "     |      dimension `d`, and that `index->size[d] <= real->size[d]` for all dimensions\n",
      "     |      `d != dim`.\n",
      "     |      \n",
      "     |      Moreover, as for :meth:`~Tensor.gather`, the values of :attr:`index` must be\n",
      "     |      between `0` and `(self.size(dim) -1)` inclusive, and all values in a row along\n",
      "     |      the specified dimension :attr:`dim` must be unique.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          input (Tensor): the source tensor\n",
      "     |          dim (int): the axis along which to index\n",
      "     |          index (LongTensor): the indices of elements to scatter\n",
      "     |          src (Tensor or float): the source element(s) to scatter\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.rand(2, 5)\n",
      "     |          >>> x\n",
      "     |          tensor([[ 0.3992,  0.2908,  0.9044,  0.4850,  0.6004],\n",
      "     |                  [ 0.5735,  0.9006,  0.6797,  0.4152,  0.1732]])\n",
      "     |          >>> torch.zeros(3, 5).scatter_(0, torch.tensor([[0, 1, 2, 0, 0], [2, 0, 0, 1, 2]]), x)\n",
      "     |          tensor([[ 0.3992,  0.9006,  0.6797,  0.4850,  0.6004],\n",
      "     |                  [ 0.0000,  0.2908,  0.0000,  0.4152,  0.0000],\n",
      "     |                  [ 0.5735,  0.0000,  0.9044,  0.0000,  0.1732]])\n",
      "     |      \n",
      "     |          >>> z = torch.zeros(2, 4).scatter_(1, torch.tensor([[2], [3]]), 1.23)\n",
      "     |          >>> z\n",
      "     |          tensor([[ 0.0000,  0.0000,  1.2300,  0.0000],\n",
      "     |                  [ 0.0000,  0.0000,  0.0000,  1.2300]])\n",
      "     |  \n",
      "     |  scatter_add(self, dim, index, source)\n",
      "     |  \n",
      "     |  scatter_add_(...)\n",
      "     |  \n",
      "     |  select(...)\n",
      "     |      select(dim, index) -> Tensor\n",
      "     |      \n",
      "     |      Slices the :attr:`self` tensor along the selected dimension at the given index.\n",
      "     |      This function returns a tensor with the given dimension removed.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the dimension to slice\n",
      "     |          index (int): the index to select with\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          :meth:`select` is equivalent to slicing. For example,\n",
      "     |          ``tensor.select(0, index)`` is equivalent to ``tensor[index]`` and\n",
      "     |          ``tensor.select(2, index)`` is equivalent to ``tensor[:,:,index]``.\n",
      "     |  \n",
      "     |  set_(...)\n",
      "     |      set_(source=None, storage_offset=0, size=None, stride=None) -> Tensor\n",
      "     |      \n",
      "     |      Sets the underlying storage, size, and strides. If :attr:`source` is a tensor,\n",
      "     |      :attr:`self` tensor will share the same storage and have the same size and\n",
      "     |      strides as :attr:`source`. Changes to elements in one tensor will be reflected\n",
      "     |      in the other.\n",
      "     |      \n",
      "     |      If :attr:`source` is a :class:`~torch.Storage`, the method sets the underlying\n",
      "     |      storage, offset, size, and stride.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          source (Tensor or Storage): the tensor or storage to use\n",
      "     |          storage_offset (int, optional): the offset in the storage\n",
      "     |          size (torch.Size, optional): the desired size. Defaults to the size of the source.\n",
      "     |          stride (tuple, optional): the desired stride. Defaults to C-contiguous strides.\n",
      "     |  \n",
      "     |  share_memory_(self)\n",
      "     |      Moves the underlying storage to shared memory.\n",
      "     |      \n",
      "     |      This is a no-op if the underlying storage is already in shared memory\n",
      "     |      and for CUDA tensors. Tensors in shared memory cannot be resized.\n",
      "     |  \n",
      "     |  short(...)\n",
      "     |      short() -> Tensor\n",
      "     |      \n",
      "     |      ``self.short()`` is equivalent to ``self.to(torch.int16)``. See :func:`to`.\n",
      "     |  \n",
      "     |  sigmoid(...)\n",
      "     |      sigmoid() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sigmoid`\n",
      "     |  \n",
      "     |  sigmoid_(...)\n",
      "     |      sigmoid_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sigmoid`\n",
      "     |  \n",
      "     |  sign(...)\n",
      "     |      sign() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sign`\n",
      "     |  \n",
      "     |  sign_(...)\n",
      "     |      sign_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sign`\n",
      "     |  \n",
      "     |  sin(...)\n",
      "     |      sin() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sin`\n",
      "     |  \n",
      "     |  sin_(...)\n",
      "     |      sin_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sin`\n",
      "     |  \n",
      "     |  sinh(...)\n",
      "     |      sinh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sinh`\n",
      "     |  \n",
      "     |  sinh_(...)\n",
      "     |      sinh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sinh`\n",
      "     |  \n",
      "     |  size(...)\n",
      "     |      size() -> torch.Size\n",
      "     |      \n",
      "     |      Returns the size of the :attr:`self` tensor. The returned value is a subclass of\n",
      "     |      :class:`tuple`.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> torch.empty(3, 4, 5).size()\n",
      "     |          torch.Size([3, 4, 5])\n",
      "     |  \n",
      "     |  slice(...)\n",
      "     |  \n",
      "     |  slogdet(...)\n",
      "     |      slogdet() -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.slogdet`\n",
      "     |  \n",
      "     |  smm(...)\n",
      "     |  \n",
      "     |  sort(...)\n",
      "     |      sort(dim=None, descending=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.sort`\n",
      "     |  \n",
      "     |  split(self, split_size, dim=0)\n",
      "     |      See :func:`torch.split`\n",
      "     |  \n",
      "     |  split_with_sizes(...)\n",
      "     |  \n",
      "     |  sqrt(...)\n",
      "     |      sqrt() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sqrt`\n",
      "     |  \n",
      "     |  sqrt_(...)\n",
      "     |      sqrt_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sqrt`\n",
      "     |  \n",
      "     |  squeeze(...)\n",
      "     |      squeeze(dim=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.squeeze`\n",
      "     |  \n",
      "     |  squeeze_(...)\n",
      "     |      squeeze_(dim=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.squeeze`\n",
      "     |  \n",
      "     |  sspaddmm(...)\n",
      "     |  \n",
      "     |  std(...)\n",
      "     |      std(dim=None, unbiased=True, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.std`\n",
      "     |  \n",
      "     |  stft(...)\n",
      "     |      stft(frame_length, hop, fft_size=None, return_onesided=True, window=None, pad_end=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.stft`\n",
      "     |  \n",
      "     |  storage(...)\n",
      "     |      storage() -> torch.Storage\n",
      "     |      \n",
      "     |      Returns the underlying storage\n",
      "     |  \n",
      "     |  storage_offset(...)\n",
      "     |      storage_offset() -> int\n",
      "     |      \n",
      "     |      Returns :attr:`self` tensor's offset in the underlying storage in terms of\n",
      "     |      number of storage elements (not bytes).\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([1, 2, 3, 4, 5])\n",
      "     |          >>> x.storage_offset()\n",
      "     |          0\n",
      "     |          >>> x[3:].storage_offset()\n",
      "     |          3\n",
      "     |  \n",
      "     |  storage_type(...)\n",
      "     |  \n",
      "     |  stride(...)\n",
      "     |      stride(dim) -> tuple or int\n",
      "     |      \n",
      "     |      Returns the stride of :attr:`self` tensor.\n",
      "     |      \n",
      "     |      Stride is the jump necessary to go from one element to the next one in the\n",
      "     |      specified dimension :attr:`dim`. A tuple of all strides is returned when no\n",
      "     |      argument is passed in. Otherwise, an integer value is returned as the stride in\n",
      "     |      the particular dimension :attr:`dim`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int, optional): the desired dimension in which stride is required\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1, 2, 3, 4, 5], [6, 7, 8, 9, 10]])\n",
      "     |          >>> x.stride()\n",
      "     |          (5, 1)\n",
      "     |          >>>x.stride(0)\n",
      "     |          5\n",
      "     |          >>> x.stride(-1)\n",
      "     |          1\n",
      "     |  \n",
      "     |  sub(...)\n",
      "     |      sub(value, other) -> Tensor\n",
      "     |      \n",
      "     |      Subtracts a scalar or tensor from :attr:`self` tensor. If both :attr:`value` and\n",
      "     |      :attr:`other` are specified, each element of :attr:`other` is scaled by\n",
      "     |      :attr:`value` before being used.\n",
      "     |      \n",
      "     |      When :attr:`other` is a tensor, the shape of :attr:`other` must be\n",
      "     |      :ref:`broadcastable <broadcasting-semantics>` with the shape of the underlying\n",
      "     |      tensor.\n",
      "     |  \n",
      "     |  sub_(...)\n",
      "     |      sub_(x) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sub`\n",
      "     |  \n",
      "     |  sum(...)\n",
      "     |      sum(dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sum`\n",
      "     |  \n",
      "     |  svd(...)\n",
      "     |      svd(some=True) -> (Tensor, Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.svd`\n",
      "     |  \n",
      "     |  symeig(...)\n",
      "     |      symeig(eigenvectors=False, upper=True) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.symeig`\n",
      "     |  \n",
      "     |  t(...)\n",
      "     |      t() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.t`\n",
      "     |  \n",
      "     |  t_(...)\n",
      "     |      t_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.t`\n",
      "     |  \n",
      "     |  take(...)\n",
      "     |      take(indices) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.take`\n",
      "     |  \n",
      "     |  tan(...)\n",
      "     |  \n",
      "     |  tan_(...)\n",
      "     |      tan_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.tan`\n",
      "     |  \n",
      "     |  tanh(...)\n",
      "     |      tanh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tanh`\n",
      "     |  \n",
      "     |  tanh_(...)\n",
      "     |      tanh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.tanh`\n",
      "     |  \n",
      "     |  to(...)\n",
      "     |      to(*args, **kwargs) -> Tensor\n",
      "     |      \n",
      "     |      Performs Tensor dtype and/or device conversion. A :class:`torch.dtype` and :class:`torch.device` are\n",
      "     |      inferred from the arguments of ``self.to(*args, **kwargs)``.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          If the ``self`` Tensor already\n",
      "     |          has the correct :class:`torch.dtype` and :class:`torch.device`, then ``self`` is returned.\n",
      "     |          Otherwise, the returned tensor is a copy of ``self`` with the desired\n",
      "     |          :class:`torch.dtype` and :class:`torch.device`.\n",
      "     |      \n",
      "     |      Here are the ways to call ``to``:\n",
      "     |      \n",
      "     |      .. function:: to(dtype) -> Tensor\n",
      "     |      \n",
      "     |          Returns a Tensor with the specified :attr:`dtype`\n",
      "     |      \n",
      "     |      .. function:: to(device, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |          Returns a Tensor with the specified :attr:`device` and (optional)\n",
      "     |          :attr:`dtype`. If :attr:`dtype` is ``None`` it is inferred to be ``self.dtype``.\n",
      "     |      \n",
      "     |      .. function:: to(other) -> Tensor\n",
      "     |      \n",
      "     |          Returns a Tensor with same :class:`torch.dtype` and :class:`torch.device` as the Tensor\n",
      "     |          :attr:`other`.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.randn(2, 2)  # Initially dtype=float32, device=cpu\n",
      "     |          >>> tensor.to(torch.float64)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], dtype=torch.float64)\n",
      "     |      \n",
      "     |          >>> cuda0 = torch.device('cuda:0')\n",
      "     |          >>> tensor.to(cuda0)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], device='cuda:0')\n",
      "     |      \n",
      "     |          >>> tensor.to(cuda0, dtype=torch.float64)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], dtype=torch.float64, device='cuda:0')\n",
      "     |      \n",
      "     |          >>> other = torch.randn((), dtype=torch.float64, device=cuda0)\n",
      "     |          >>> tensor.to(other)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], dtype=torch.float64, device='cuda:0')\n",
      "     |  \n",
      "     |  to_dense(...)\n",
      "     |  \n",
      "     |  tolist(...)\n",
      "     |  \n",
      "     |  topk(...)\n",
      "     |      topk(k, dim=None, largest=True, sorted=True) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.topk`\n",
      "     |  \n",
      "     |  trace(...)\n",
      "     |      trace() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.trace`\n",
      "     |  \n",
      "     |  transpose(...)\n",
      "     |      transpose(dim0, dim1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.transpose`\n",
      "     |  \n",
      "     |  transpose_(...)\n",
      "     |      transpose_(dim0, dim1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.transpose`\n",
      "     |  \n",
      "     |  tril(...)\n",
      "     |      tril(k=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tril`\n",
      "     |  \n",
      "     |  tril_(...)\n",
      "     |      tril_(k=0) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.tril`\n",
      "     |  \n",
      "     |  triu(...)\n",
      "     |      triu(k=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.triu`\n",
      "     |  \n",
      "     |  triu_(...)\n",
      "     |      triu_(k=0) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.triu`\n",
      "     |  \n",
      "     |  trtrs(...)\n",
      "     |      trtrs(A, upper=True, transpose=False, unitriangular=False) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.trtrs`\n",
      "     |  \n",
      "     |  trunc(...)\n",
      "     |      trunc() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.trunc`\n",
      "     |  \n",
      "     |  trunc_(...)\n",
      "     |      trunc_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.trunc`\n",
      "     |  \n",
      "     |  type(...)\n",
      "     |      type(dtype=None, non_blocking=False, **kwargs) -> str or Tensor\n",
      "     |      Returns the type if `dtype` is not provided, else casts this object to\n",
      "     |      the specified type.\n",
      "     |      \n",
      "     |      If this is already of the correct type, no copy is performed and the\n",
      "     |      original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (type or string): The desired type\n",
      "     |          non_blocking (bool): If ``True``, and the source is in pinned memory\n",
      "     |              and destination is on the GPU or vice versa, the copy is performed\n",
      "     |              asynchronously with respect to the host. Otherwise, the argument\n",
      "     |              has no effect.\n",
      "     |          **kwargs: For compatibility, may contain the key ``async`` in place of\n",
      "     |              the ``non_blocking`` argument. The ``async`` arg is deprecated.\n",
      "     |  \n",
      "     |  type_as(...)\n",
      "     |      type_as(tensor) -> Tensor\n",
      "     |      \n",
      "     |      Returns this tensor cast to the type of the given tensor.\n",
      "     |      \n",
      "     |      This is a no-op if the tensor is already of the correct type. This is\n",
      "     |      equivalent to::\n",
      "     |      \n",
      "     |          self.type(tensor.type())\n",
      "     |      \n",
      "     |      Params:\n",
      "     |          tensor (Tensor): the tensor which has the desired type\n",
      "     |  \n",
      "     |  unfold(...)\n",
      "     |      unfold(dim, size, step) -> Tensor\n",
      "     |      \n",
      "     |      Returns a tensor which contains all slices of size :attr:`size` from\n",
      "     |      :attr:`self` tensor in the dimension :attr:`dim`.\n",
      "     |      \n",
      "     |      Step between two slices is given by :attr:`step`.\n",
      "     |      \n",
      "     |      If `sizedim` is the size of dimension dim for :attr:`self`, the size of\n",
      "     |      dimension :attr:`dim` in the returned tensor will be\n",
      "     |      `(sizedim - size) / step + 1`.\n",
      "     |      \n",
      "     |      An additional dimension of size size is appended in the returned tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension in which unfolding happens\n",
      "     |          size (int): the size of each slice that is unfolded\n",
      "     |          step (int): the step between each slice\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.arange(1, 8)\n",
      "     |          >>> x\n",
      "     |          tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.])\n",
      "     |          >>> x.unfold(0, 2, 1)\n",
      "     |          tensor([[ 1.,  2.],\n",
      "     |                  [ 2.,  3.],\n",
      "     |                  [ 3.,  4.],\n",
      "     |                  [ 4.,  5.],\n",
      "     |                  [ 5.,  6.],\n",
      "     |                  [ 6.,  7.]])\n",
      "     |          >>> x.unfold(0, 2, 2)\n",
      "     |          tensor([[ 1.,  2.],\n",
      "     |                  [ 3.,  4.],\n",
      "     |                  [ 5.,  6.]])\n",
      "     |  \n",
      "     |  uniform_(...)\n",
      "     |      uniform_(from=0, to=1) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with numbers sampled from the continuous uniform\n",
      "     |      distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |          P(x) = \\dfrac{1}{\\text{to} - \\text{from}}\n",
      "     |  \n",
      "     |  unique(self, sorted=False, return_inverse=False)\n",
      "     |      Returns the unique scalar elements of the tensor as a 1-D tensor.\n",
      "     |      \n",
      "     |      See :func:`torch.unique`\n",
      "     |  \n",
      "     |  unsqueeze(...)\n",
      "     |      unsqueeze(dim) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.unsqueeze`\n",
      "     |  \n",
      "     |  unsqueeze_(...)\n",
      "     |      unsqueeze_(dim) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.unsqueeze`\n",
      "     |  \n",
      "     |  var(...)\n",
      "     |      var(dim=None, unbiased=True, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.var`\n",
      "     |  \n",
      "     |  view(...)\n",
      "     |      view(*args) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new tensor with the same data as the :attr:`self` tensor but of a\n",
      "     |      different size.\n",
      "     |      \n",
      "     |      The returned tensor shares the same data and must have the same number\n",
      "     |      of elements, but may have a different size. For a tensor to be viewed, the new\n",
      "     |      view size must be compatible with its original size and stride, i.e., each new\n",
      "     |      view dimension must either be a subspace of an original dimension, or only span\n",
      "     |      across original dimensions :math:`d, d+1, \\dots, d+k` that satisfy the following\n",
      "     |      contiguity-like condition that :math:`\\forall i = 0, \\dots, k-1`,\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |        stride[i] = stride[i+1] \\times size[i+1]\n",
      "     |      \n",
      "     |      Otherwise, :func:`contiguous` needs to be called before the tensor can be\n",
      "     |      viewed.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          args (torch.Size or int...): the desired size\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.randn(4, 4)\n",
      "     |          >>> x.size()\n",
      "     |          torch.Size([4, 4])\n",
      "     |          >>> y = x.view(16)\n",
      "     |          >>> y.size()\n",
      "     |          torch.Size([16])\n",
      "     |          >>> z = x.view(-1, 8)  # the size -1 is inferred from other dimensions\n",
      "     |          >>> z.size()\n",
      "     |          torch.Size([2, 8])\n",
      "     |  \n",
      "     |  view_as(self, tensor)\n",
      "     |      view_as(other) -> Tensor\n",
      "     |      \n",
      "     |      View this tensor as the same size as :attr:`other`.\n",
      "     |      ``self.view_as(other)`` is equivalent to ``self.view(other.size())``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          other (:class:`torch.Tensor`): The result tensor has the same size\n",
      "     |              as :attr:`other.size()`.\n",
      "     |  \n",
      "     |  where(...)\n",
      "     |      where(condition, y) -> Tensor\n",
      "     |      \n",
      "     |      ``self.where(condition, y)`` is equivalent to ``torch.where(condition, self, y)``.\n",
      "     |      See :func:`torch.where`\n",
      "     |  \n",
      "     |  zero_(...)\n",
      "     |      zero_() -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with zeros.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  data\n",
      "     |  \n",
      "     |  device\n",
      "     |  \n",
      "     |  grad\n",
      "     |  \n",
      "     |  grad_fn\n",
      "     |  \n",
      "     |  is_leaf\n",
      "     |  \n",
      "     |  name\n",
      "     |  \n",
      "     |  output_nr\n",
      "     |  \n",
      "     |  requires_grad\n",
      "     |  \n",
      "     |  shape\n",
      "     |  \n",
      "     |  volatile\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  dtype = torch.int32\n",
      "     |  \n",
      "     |  is_cuda = False\n",
      "     |  \n",
      "     |  is_sparse = False\n",
      "     |  \n",
      "     |  layout = torch.strided\n",
      "    \n",
      "    class InterpreterFunctionFactory(pybind11_builtins.pybind11_object)\n",
      "     |  Method resolution order:\n",
      "     |      InterpreterFunctionFactory\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __call__(...)\n",
      "     |      __call__(self: torch._C.InterpreterFunctionFactory) -> std::shared_ptr<torch::autograd::Function>\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class LongStorage(torch._C.LongStorageBase, torch.storage._StorageBase)\n",
      "     |  Method resolution order:\n",
      "     |      LongStorage\n",
      "     |      torch._C.LongStorageBase\n",
      "     |      torch.storage._StorageBase\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch._C.LongStorageBase:\n",
      "     |  \n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |  \n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |  \n",
      "     |  __len__(self, /)\n",
      "     |      Return len(self).\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  __setitem__(self, key, value, /)\n",
      "     |      Set self[key] to value.\n",
      "     |  \n",
      "     |  copy_(...)\n",
      "     |  \n",
      "     |  data_ptr(...)\n",
      "     |  \n",
      "     |  element_size(...)\n",
      "     |  \n",
      "     |  fill_(...)\n",
      "     |  \n",
      "     |  is_pinned(...)\n",
      "     |  \n",
      "     |  is_shared(...)\n",
      "     |  \n",
      "     |  new(...)\n",
      "     |  \n",
      "     |  resize_(...)\n",
      "     |  \n",
      "     |  size(...)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from torch._C.LongStorageBase:\n",
      "     |  \n",
      "     |  from_buffer(...)\n",
      "     |  \n",
      "     |  from_file(...)\n",
      "     |      from_file(filename, shared=False, size=0) -> Storage\n",
      "     |      \n",
      "     |      If `shared` is `True`, then memory is shared between all processes.\n",
      "     |      All changes are written to the file. If `shared` is `False`, then the changes on\n",
      "     |      the storage do not affect the file.\n",
      "     |      \n",
      "     |      `size` is the number of elements in the storage. If `shared` is `False`,\n",
      "     |      then the file must contain at least `size * sizeof(Type)` bytes\n",
      "     |      (`Type` is the type of storage). If `shared` is `True` the file will be\n",
      "     |      created if needed.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          filename (str): file name to map\n",
      "     |          shared (bool): whether to share memory\n",
      "     |          size (int): number of elements in the storage\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.storage._StorageBase:\n",
      "     |  \n",
      "     |  __copy__(self)\n",
      "     |  \n",
      "     |  __deepcopy__(self, memo)\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      helper for pickle\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __sizeof__(self)\n",
      "     |      __sizeof__() -> int\n",
      "     |      size of object in memory, in bytes\n",
      "     |  \n",
      "     |  __str__(self)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  byte(self)\n",
      "     |      Casts this storage to byte type\n",
      "     |  \n",
      "     |  char(self)\n",
      "     |      Casts this storage to char type\n",
      "     |  \n",
      "     |  clone(self)\n",
      "     |      Returns a copy of this storage\n",
      "     |  \n",
      "     |  cpu(self)\n",
      "     |      Returns a CPU copy of this storage if it's not already on the CPU\n",
      "     |  \n",
      "     |  cuda = _cuda(self, device=None, non_blocking=False, **kwargs)\n",
      "     |      Returns a copy of this object in CUDA memory.\n",
      "     |      \n",
      "     |      If this object is already in CUDA memory and on the correct device, then\n",
      "     |      no copy is performed and the original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          device (int): The destination GPU id. Defaults to the current device.\n",
      "     |          non_blocking (bool): If ``True`` and the source is in pinned memory,\n",
      "     |              the copy will be asynchronous with respect to the host. Otherwise,\n",
      "     |              the argument has no effect.\n",
      "     |          **kwargs: For compatibility, may contain the key ``async`` in place of\n",
      "     |              the ``non_blocking`` argument.\n",
      "     |  \n",
      "     |  double(self)\n",
      "     |      Casts this storage to double type\n",
      "     |  \n",
      "     |  float(self)\n",
      "     |      Casts this storage to float type\n",
      "     |  \n",
      "     |  half(self)\n",
      "     |      Casts this storage to half type\n",
      "     |  \n",
      "     |  int(self)\n",
      "     |      Casts this storage to int type\n",
      "     |  \n",
      "     |  long(self)\n",
      "     |      Casts this storage to long type\n",
      "     |  \n",
      "     |  pin_memory(self)\n",
      "     |      Copies the storage to pinned memory, if it's not already pinned.\n",
      "     |  \n",
      "     |  share_memory_(self)\n",
      "     |      Moves the storage to shared memory.\n",
      "     |      \n",
      "     |      This is a no-op for storages already in shared memory and for CUDA\n",
      "     |      storages, which do not need to be moved for sharing across processes.\n",
      "     |      Storages in shared memory cannot be resized.\n",
      "     |      \n",
      "     |      Returns: self\n",
      "     |  \n",
      "     |  short(self)\n",
      "     |      Casts this storage to short type\n",
      "     |  \n",
      "     |  tolist(self)\n",
      "     |      Returns a list containing the elements of this storage\n",
      "     |  \n",
      "     |  type = _type(self, dtype=None, non_blocking=False, **kwargs)\n",
      "     |      Returns the type if `dtype` is not provided, else casts this object to\n",
      "     |      the specified type.\n",
      "     |      \n",
      "     |      If this is already of the correct type, no copy is performed and the\n",
      "     |      original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (type or string): The desired type\n",
      "     |          non_blocking (bool): If ``True``, and the source is in pinned memory\n",
      "     |              and destination is on the GPU or vice versa, the copy is performed\n",
      "     |              asynchronously with respect to the host. Otherwise, the argument\n",
      "     |              has no effect.\n",
      "     |          **kwargs: For compatibility, may contain the key ``async`` in place of\n",
      "     |              the ``non_blocking`` argument. The ``async`` arg is deprecated.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.storage._StorageBase:\n",
      "     |  \n",
      "     |  is_cuda = False\n",
      "     |  \n",
      "     |  is_sparse = False\n",
      "    \n",
      "    class LongTensor(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __abs__ = abs(...)\n",
      "     |  \n",
      "     |  __add__(...)\n",
      "     |  \n",
      "     |  __and__(...)\n",
      "     |  \n",
      "     |  __array__(self, dtype=None)\n",
      "     |      # Numpy array interface, to support `numpy.asarray(tensor) -> ndarray`\n",
      "     |  \n",
      "     |  __array_wrap__(self, array)\n",
      "     |      # Wrap Numpy array again in a suitable tensor when done, to support e.g.\n",
      "     |      # `numpy.sin(tensor) -> tensor` or `numpy.greater(tensor, 0) -> ByteTensor`\n",
      "     |  \n",
      "     |  __bool__(...)\n",
      "     |  \n",
      "     |  __deepcopy__(self, memo)\n",
      "     |  \n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |  \n",
      "     |  __dir__(self)\n",
      "     |      __dir__() -> list\n",
      "     |      default dir() implementation\n",
      "     |  \n",
      "     |  __div__(...)\n",
      "     |  \n",
      "     |  __eq__ = eq(...)\n",
      "     |  \n",
      "     |  __float__(...)\n",
      "     |  \n",
      "     |  __format__(self, format_spec)\n",
      "     |      default object formatter\n",
      "     |  \n",
      "     |  __ge__ = ge(...)\n",
      "     |  \n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |  \n",
      "     |  __gt__ = gt(...)\n",
      "     |  \n",
      "     |  __hash__(self)\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __iadd__(...)\n",
      "     |  \n",
      "     |  __iand__(...)\n",
      "     |  \n",
      "     |  __idiv__(...)\n",
      "     |  \n",
      "     |  __ilshift__(...)\n",
      "     |  \n",
      "     |  __imul__(...)\n",
      "     |  \n",
      "     |  __index__(...)\n",
      "     |  \n",
      "     |  __int__(...)\n",
      "     |  \n",
      "     |  __invert__(...)\n",
      "     |  \n",
      "     |  __ior__(...)\n",
      "     |  \n",
      "     |  __ipow__(self, other)\n",
      "     |  \n",
      "     |  __irshift__(...)\n",
      "     |  \n",
      "     |  __isub__(...)\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |  \n",
      "     |  __itruediv__ = __idiv__(...)\n",
      "     |  \n",
      "     |  __ixor__(...)\n",
      "     |  \n",
      "     |  __le__ = le(...)\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |      Return len(self).\n",
      "     |  \n",
      "     |  __long__(...)\n",
      "     |  \n",
      "     |  __lshift__(...)\n",
      "     |  \n",
      "     |  __lt__ = lt(...)\n",
      "     |  \n",
      "     |  __matmul__(...)\n",
      "     |  \n",
      "     |  __mod__(...)\n",
      "     |  \n",
      "     |  __mul__(...)\n",
      "     |  \n",
      "     |  __ne__ = ne(...)\n",
      "     |  \n",
      "     |  __neg__ = neg(...)\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from tensortype\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  __nonzero__(...)\n",
      "     |  \n",
      "     |  __or__(...)\n",
      "     |  \n",
      "     |  __pow__ = pow(...)\n",
      "     |  \n",
      "     |  __radd__(...)\n",
      "     |  \n",
      "     |  __rdiv__(self, other)\n",
      "     |  \n",
      "     |  __reduce_ex__(self, proto)\n",
      "     |      helper for pickle\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __rmul__(...)\n",
      "     |  \n",
      "     |  __rpow__(self, other)\n",
      "     |  \n",
      "     |  __rshift__(...)\n",
      "     |  \n",
      "     |  __rsub__(self, other)\n",
      "     |  \n",
      "     |  __rtruediv__ = __rdiv__(self, other)\n",
      "     |  \n",
      "     |  __setitem__(self, key, value, /)\n",
      "     |      Set self[key] to value.\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |  \n",
      "     |  __sub__(...)\n",
      "     |  \n",
      "     |  __truediv__(...)\n",
      "     |  \n",
      "     |  __xor__(...)\n",
      "     |  \n",
      "     |  abs(...)\n",
      "     |      abs() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.abs`\n",
      "     |  \n",
      "     |  abs_(...)\n",
      "     |      abs_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.abs`\n",
      "     |  \n",
      "     |  acos(...)\n",
      "     |      acos() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.acos`\n",
      "     |  \n",
      "     |  acos_(...)\n",
      "     |      acos_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.acos`\n",
      "     |  \n",
      "     |  add(...)\n",
      "     |      add(value) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.add`\n",
      "     |  \n",
      "     |  add_(...)\n",
      "     |      add_(value) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.add`\n",
      "     |  \n",
      "     |  addbmm(...)\n",
      "     |      addbmm(beta=1, mat, alpha=1, batch1, batch2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addbmm`\n",
      "     |  \n",
      "     |  addbmm_(...)\n",
      "     |      addbmm_(beta=1, mat, alpha=1, batch1, batch2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addbmm`\n",
      "     |  \n",
      "     |  addcdiv(...)\n",
      "     |      addcdiv(value=1, tensor1, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addcdiv`\n",
      "     |  \n",
      "     |  addcdiv_(...)\n",
      "     |      addcdiv_(value=1, tensor1, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addcdiv`\n",
      "     |  \n",
      "     |  addcmul(...)\n",
      "     |      addcmul(value=1, tensor1, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addcmul`\n",
      "     |  \n",
      "     |  addcmul_(...)\n",
      "     |      addcmul_(value=1, tensor1, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addcmul`\n",
      "     |  \n",
      "     |  addmm(...)\n",
      "     |      addmm(beta=1, mat, alpha=1, mat1, mat2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addmm`\n",
      "     |  \n",
      "     |  addmm_(...)\n",
      "     |      addmm_(beta=1, mat, alpha=1, mat1, mat2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addmm`\n",
      "     |  \n",
      "     |  addmv(...)\n",
      "     |      addmv(beta=1, tensor, alpha=1, mat, vec) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addmv`\n",
      "     |  \n",
      "     |  addmv_(...)\n",
      "     |      addmv_(beta=1, tensor, alpha=1, mat, vec) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addmv`\n",
      "     |  \n",
      "     |  addr(...)\n",
      "     |      addr(beta=1, alpha=1, vec1, vec2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addr`\n",
      "     |  \n",
      "     |  addr_(...)\n",
      "     |      addr_(beta=1, alpha=1, vec1, vec2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addr`\n",
      "     |  \n",
      "     |  all(...)\n",
      "     |      all() -> bool\n",
      "     |      \n",
      "     |      Returns ``True`` if all elements in the tensor are non-zero, ``False`` otherwise.\n",
      "     |  \n",
      "     |  allclose(...)\n",
      "     |  \n",
      "     |  any(...)\n",
      "     |      any() -> bool\n",
      "     |      \n",
      "     |      Returns ``True`` if any elements in the tensor are non-zero, ``False`` otherwise.\n",
      "     |  \n",
      "     |  apply_(...)\n",
      "     |      apply_(callable) -> Tensor\n",
      "     |      \n",
      "     |      Applies the function :attr:`callable` to each element in the tensor, replacing\n",
      "     |      each element with the value returned by :attr:`callable`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          This function only works with CPU tensors and should not be used in code\n",
      "     |          sections that require high performance.\n",
      "     |  \n",
      "     |  argmax(self, dim=None, keepdim=False)\n",
      "     |      See :func:`torch.argmax`\n",
      "     |  \n",
      "     |  argmin(self, dim=None, keepdim=False)\n",
      "     |      See :func:`torch.argmin`\n",
      "     |  \n",
      "     |  as_strided(...)\n",
      "     |  \n",
      "     |  as_strided_(...)\n",
      "     |  \n",
      "     |  asin(...)\n",
      "     |      asin() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.asin`\n",
      "     |  \n",
      "     |  asin_(...)\n",
      "     |      asin_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.asin`\n",
      "     |  \n",
      "     |  atan(...)\n",
      "     |      atan() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.atan`\n",
      "     |  \n",
      "     |  atan2(...)\n",
      "     |      atan2(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.atan2`\n",
      "     |  \n",
      "     |  atan2_(...)\n",
      "     |      atan2_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.atan2`\n",
      "     |  \n",
      "     |  atan_(...)\n",
      "     |      atan_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.atan`\n",
      "     |  \n",
      "     |  backward(self, gradient=None, retain_graph=None, create_graph=False)\n",
      "     |      Computes the gradient of current tensor w.r.t. graph leaves.\n",
      "     |      \n",
      "     |      The graph is differentiated using the chain rule. If the tensor is\n",
      "     |      non-scalar (i.e. its data has more than one element) and requires\n",
      "     |      gradient, the function additionally requires specifying ``gradient``.\n",
      "     |      It should be a tensor of matching type and location, that contains\n",
      "     |      the gradient of the differentiated function w.r.t. ``self``.\n",
      "     |      \n",
      "     |      This function accumulates gradients in the leaves - you might need to\n",
      "     |      zero them before calling it.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          gradient (Tensor or None): Gradient w.r.t. the\n",
      "     |              tensor. If it is a tensor, it will be automatically converted\n",
      "     |              to a Tensor that does not require grad unless ``create_graph`` is True.\n",
      "     |              None values can be specified for scalar Tensors or ones that\n",
      "     |              don't require grad. If a None value would be acceptable then\n",
      "     |              this argument is optional.\n",
      "     |          retain_graph (bool, optional): If ``False``, the graph used to compute\n",
      "     |              the grads will be freed. Note that in nearly all cases setting\n",
      "     |              this option to True is not needed and often can be worked around\n",
      "     |              in a much more efficient way. Defaults to the value of\n",
      "     |              ``create_graph``.\n",
      "     |          create_graph (bool, optional): If ``True``, graph of the derivative will\n",
      "     |              be constructed, allowing to compute higher order derivative\n",
      "     |              products. Defaults to ``False``.\n",
      "     |  \n",
      "     |  baddbmm(...)\n",
      "     |      baddbmm(beta=1, alpha=1, batch1, batch2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.baddbmm`\n",
      "     |  \n",
      "     |  baddbmm_(...)\n",
      "     |      baddbmm_(beta=1, alpha=1, batch1, batch2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.baddbmm`\n",
      "     |  \n",
      "     |  bernoulli(...)\n",
      "     |      bernoulli() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bernoulli`\n",
      "     |  \n",
      "     |  bernoulli_(...)\n",
      "     |      bernoulli_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.bernoulli`\n",
      "     |  \n",
      "     |  bmm(...)\n",
      "     |      bmm(batch2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bmm`\n",
      "     |  \n",
      "     |  btrifact(self, info=None, pivot=True)\n",
      "     |      See :func:`torch.btrifact`\n",
      "     |  \n",
      "     |  btrifact_with_info(...)\n",
      "     |      btrifact_with_info(pivot=True) -> (Tensor, Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.btrifact_with_info`\n",
      "     |  \n",
      "     |  btrisolve(...)\n",
      "     |  \n",
      "     |  byte(...)\n",
      "     |      byte() -> Tensor\n",
      "     |      \n",
      "     |      ``self.byte()`` is equivalent to ``self.to(torch.uint8)``. See :func:`to`.\n",
      "     |  \n",
      "     |  cauchy_(...)\n",
      "     |      cauchy_(median=0, sigma=1, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills the tensor with numbers drawn from the Cauchy distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(x) = \\dfrac{1}{\\pi} \\dfrac{\\sigma}{(x - median)^2 + \\sigma^2}\n",
      "     |  \n",
      "     |  ceil(...)\n",
      "     |      ceil() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ceil`\n",
      "     |  \n",
      "     |  ceil_(...)\n",
      "     |      ceil_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ceil`\n",
      "     |  \n",
      "     |  char(...)\n",
      "     |      char() -> Tensor\n",
      "     |      \n",
      "     |      ``self.char()`` is equivalent to ``self.to(torch.int8)``. See :func:`to`.\n",
      "     |  \n",
      "     |  chunk(...)\n",
      "     |      chunk(chunks, dim=0) -> List of Tensors\n",
      "     |      \n",
      "     |      See :func:`torch.chunk`\n",
      "     |  \n",
      "     |  clamp(...)\n",
      "     |      clamp(min, max) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.clamp`\n",
      "     |  \n",
      "     |  clamp_(...)\n",
      "     |      clamp_(min, max) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.clamp`\n",
      "     |  \n",
      "     |  clone(...)\n",
      "     |      clone() -> Tensor\n",
      "     |      \n",
      "     |      Returns a copy of the :attr:`self` tensor. The copy has the same size and data\n",
      "     |      type as :attr:`self`.\n",
      "     |  \n",
      "     |  coalesce(...)\n",
      "     |  \n",
      "     |  contiguous(...)\n",
      "     |      contiguous() -> Tensor\n",
      "     |      \n",
      "     |      Returns a contiguous tensor containing the same data as :attr:`self` tensor. If\n",
      "     |      :attr:`self` tensor is contiguous, this function returns the :attr:`self`\n",
      "     |      tensor.\n",
      "     |  \n",
      "     |  conv_tbc(...)\n",
      "     |  \n",
      "     |  copy_(...)\n",
      "     |      copy_(src, non_blocking=False) -> Tensor\n",
      "     |      \n",
      "     |      Copies the elements from :attr:`src` into :attr:`self` tensor and returns\n",
      "     |      :attr:`self`.\n",
      "     |      \n",
      "     |      The :attr:`src` tensor must be :ref:`broadcastable <broadcasting-semantics>`\n",
      "     |      with the :attr:`self` tensor. It may be of a different data type or reside on a\n",
      "     |      different device.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          src (Tensor): the source tensor to copy from\n",
      "     |          non_blocking (bool): if ``True`` and this copy is between CPU and GPU,\n",
      "     |              the copy may occur asynchronously with respect to the host. For other\n",
      "     |              cases, this argument has no effect.\n",
      "     |  \n",
      "     |  cos(...)\n",
      "     |      cos() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cos`\n",
      "     |  \n",
      "     |  cos_(...)\n",
      "     |      cos_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.cos`\n",
      "     |  \n",
      "     |  cosh(...)\n",
      "     |      cosh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cosh`\n",
      "     |  \n",
      "     |  cosh_(...)\n",
      "     |      cosh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.cosh`\n",
      "     |  \n",
      "     |  cpu(...)\n",
      "     |  \n",
      "     |  cross(...)\n",
      "     |      cross(other, dim=-1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cross`\n",
      "     |  \n",
      "     |  cuda(...)\n",
      "     |      cuda(device=None, non_blocking=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a copy of this object in CUDA memory.\n",
      "     |      \n",
      "     |      If this object is already in CUDA memory and on the correct device,\n",
      "     |      then no copy is performed and the original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          device (:class:`torch.device`): The destination GPU device.\n",
      "     |              Defaults to the current CUDA device.\n",
      "     |          non_blocking (bool): If ``True`` and the source is in pinned memory,\n",
      "     |              the copy will be asynchronous with respect to the host.\n",
      "     |              Otherwise, the argument has no effect. Default: ``False``.\n",
      "     |  \n",
      "     |  cumprod(...)\n",
      "     |      cumprod(dim) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cumprod`\n",
      "     |  \n",
      "     |  cumsum(...)\n",
      "     |      cumsum(dim) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cumsum`\n",
      "     |  \n",
      "     |  data_ptr(...)\n",
      "     |      data_ptr() -> int\n",
      "     |      \n",
      "     |      Returns the address of the first element of :attr:`self` tensor.\n",
      "     |  \n",
      "     |  det(...)\n",
      "     |      det() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.det`\n",
      "     |  \n",
      "     |  detach(...)\n",
      "     |      Returns a new Tensor, detached from the current graph.\n",
      "     |      \n",
      "     |      The result will never require gradient.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |        Returned Tensor uses the same data tensor as the original one.\n",
      "     |        In-place modifications on either of them will be seen, and may trigger\n",
      "     |        errors in correctness checks.\n",
      "     |  \n",
      "     |  detach_(...)\n",
      "     |      Detaches the Tensor from the graph that created it, making it a leaf.\n",
      "     |      Views cannot be detached in-place.\n",
      "     |  \n",
      "     |  diag(...)\n",
      "     |      diag(diagonal=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diag`\n",
      "     |  \n",
      "     |  digamma(...)\n",
      "     |  \n",
      "     |  digamma_(...)\n",
      "     |  \n",
      "     |  dim(...)\n",
      "     |      dim() -> int\n",
      "     |      \n",
      "     |      Returns the number of dimensions of :attr:`self` tensor.\n",
      "     |  \n",
      "     |  dist(...)\n",
      "     |      dist(other, p=2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.dist`\n",
      "     |  \n",
      "     |  div(...)\n",
      "     |      div(value) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.div`\n",
      "     |  \n",
      "     |  div_(...)\n",
      "     |      div_(value) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.div`\n",
      "     |  \n",
      "     |  dot(...)\n",
      "     |      dot(tensor2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.dot`\n",
      "     |  \n",
      "     |  double(...)\n",
      "     |      double() -> Tensor\n",
      "     |      \n",
      "     |      ``self.double()`` is equivalent to ``self.to(torch.float64)``. See :func:`to`.\n",
      "     |  \n",
      "     |  eig(...)\n",
      "     |      eig(eigenvectors=False) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.eig`\n",
      "     |  \n",
      "     |  element_size(...)\n",
      "     |      element_size() -> int\n",
      "     |      \n",
      "     |      Returns the size in bytes of an individual element.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> torch.tensor([]).element_size()\n",
      "     |          4\n",
      "     |          >>> torch.tensor([], dtype=torch.uint8).element_size()\n",
      "     |          1\n",
      "     |  \n",
      "     |  eq(...)\n",
      "     |      eq(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.eq`\n",
      "     |  \n",
      "     |  eq_(...)\n",
      "     |      eq_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.eq`\n",
      "     |  \n",
      "     |  equal(...)\n",
      "     |      equal(other) -> bool\n",
      "     |      \n",
      "     |      See :func:`torch.equal`\n",
      "     |  \n",
      "     |  erf(...)\n",
      "     |      erf() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.erf`\n",
      "     |  \n",
      "     |  erf_(...)\n",
      "     |  \n",
      "     |  erfinv(...)\n",
      "     |      erfinv() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.erfinv`\n",
      "     |  \n",
      "     |  erfinv_(...)\n",
      "     |  \n",
      "     |  exp(...)\n",
      "     |      exp() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.exp`\n",
      "     |  \n",
      "     |  exp_(...)\n",
      "     |      exp_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.exp`\n",
      "     |  \n",
      "     |  expand(...)\n",
      "     |      expand(*sizes) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new view of the :attr:`self` tensor with singleton dimensions expanded\n",
      "     |      to a larger size.\n",
      "     |      \n",
      "     |      Passing -1 as the size for a dimension means not changing the size of\n",
      "     |      that dimension.\n",
      "     |      \n",
      "     |      Tensor can be also expanded to a larger number of dimensions, and the\n",
      "     |      new ones will be appended at the front. For the new dimensions, the\n",
      "     |      size cannot be set to -1.\n",
      "     |      \n",
      "     |      Expanding a tensor does not allocate new memory, but only creates a\n",
      "     |      new view on the existing tensor where a dimension of size one is\n",
      "     |      expanded to a larger size by setting the ``stride`` to 0. Any dimension\n",
      "     |      of size 1 can be expanded to an arbitrary value without allocating new\n",
      "     |      memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *sizes (torch.Size or int...): the desired expanded size\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1], [2], [3]])\n",
      "     |          >>> x.size()\n",
      "     |          torch.Size([3, 1])\n",
      "     |          >>> x.expand(3, 4)\n",
      "     |          tensor([[ 1,  1,  1,  1],\n",
      "     |                  [ 2,  2,  2,  2],\n",
      "     |                  [ 3,  3,  3,  3]])\n",
      "     |          >>> x.expand(-1, 4)   # -1 means not changing the size of that dimension\n",
      "     |          tensor([[ 1,  1,  1,  1],\n",
      "     |                  [ 2,  2,  2,  2],\n",
      "     |                  [ 3,  3,  3,  3]])\n",
      "     |  \n",
      "     |  expand_as(self, tensor)\n",
      "     |  \n",
      "     |  expm1(...)\n",
      "     |      expm1() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.expm1`\n",
      "     |  \n",
      "     |  expm1_(...)\n",
      "     |      expm1_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.expm1`\n",
      "     |  \n",
      "     |  exponential_(...)\n",
      "     |      exponential_(lambd=1, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with elements drawn from the exponential distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(x) = \\lambda e^{-\\lambda x}\n",
      "     |  \n",
      "     |  fft(...)\n",
      "     |      fft(signal_ndim, normalized=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fft`\n",
      "     |  \n",
      "     |  fill_(...)\n",
      "     |      fill_(value) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with the specified value.\n",
      "     |  \n",
      "     |  float(...)\n",
      "     |      float() -> Tensor\n",
      "     |      \n",
      "     |      ``self.float()`` is equivalent to ``self.to(torch.float32)``. See :func:`to`.\n",
      "     |  \n",
      "     |  floor(...)\n",
      "     |      floor() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.floor`\n",
      "     |  \n",
      "     |  floor_(...)\n",
      "     |      floor_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.floor`\n",
      "     |  \n",
      "     |  fmod(...)\n",
      "     |      fmod(divisor) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fmod`\n",
      "     |  \n",
      "     |  fmod_(...)\n",
      "     |      fmod_(divisor) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.fmod`\n",
      "     |  \n",
      "     |  frac(...)\n",
      "     |      frac() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.frac`\n",
      "     |  \n",
      "     |  frac_(...)\n",
      "     |      frac_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.frac`\n",
      "     |  \n",
      "     |  gather(...)\n",
      "     |      gather(dim, index) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.gather`\n",
      "     |  \n",
      "     |  ge(...)\n",
      "     |      ge(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ge`\n",
      "     |  \n",
      "     |  ge_(...)\n",
      "     |      ge_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ge`\n",
      "     |  \n",
      "     |  gels(...)\n",
      "     |      gels(A) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.gels`\n",
      "     |  \n",
      "     |  geometric_(...)\n",
      "     |      geometric_(p, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with elements drawn from the geometric distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(X=k) = (1 - p)^{k - 1} p\n",
      "     |  \n",
      "     |  geqrf(...)\n",
      "     |      geqrf() -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.geqrf`\n",
      "     |  \n",
      "     |  ger(...)\n",
      "     |      ger(vec2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ger`\n",
      "     |  \n",
      "     |  gesv(...)\n",
      "     |      gesv(A) -> Tensor, Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.gesv`\n",
      "     |  \n",
      "     |  get_device(...)\n",
      "     |  \n",
      "     |  gt(...)\n",
      "     |      gt(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.gt`\n",
      "     |  \n",
      "     |  gt_(...)\n",
      "     |      gt_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.gt`\n",
      "     |  \n",
      "     |  half(...)\n",
      "     |      half() -> Tensor\n",
      "     |      \n",
      "     |      ``self.half()`` is equivalent to ``self.to(torch.float16)``. See :func:`to`.\n",
      "     |  \n",
      "     |  histc(...)\n",
      "     |      histc(bins=100, min=0, max=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.histc`\n",
      "     |  \n",
      "     |  ifft(...)\n",
      "     |      ifft(signal_ndim, normalized=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ifft`\n",
      "     |  \n",
      "     |  index(...)\n",
      "     |      index(m) -> Tensor\n",
      "     |      \n",
      "     |      Selects elements from :attr:`self` tensor using a binary mask or along a given\n",
      "     |      dimension. The expression ``tensor.index(m)`` is equivalent to ``tensor[m]``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          m (int or ByteTensor or slice): the dimension or mask used to select elements\n",
      "     |  \n",
      "     |  index_add(self, dim, index, tensor)\n",
      "     |  \n",
      "     |  index_add_(...)\n",
      "     |      index_add_(dim, index, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Accumulate the elements of :attr:`tensor` into the :attr:`self` tensor by adding\n",
      "     |      to the indices in the order given in :attr:`index`. For example, if ``dim == 0``\n",
      "     |      and ``index[i] == j``, then the ``i``\\ th row of :attr:`tensor` is added to the\n",
      "     |      ``j``\\ th row of :attr:`self`.\n",
      "     |      \n",
      "     |      The :attr:`dim`\\ th dimension of :attr:`tensor` must have the same size as the\n",
      "     |      length of :attr:`index` (which must be a vector), and all other dimensions must\n",
      "     |      match :attr:`self`, or an error will be raised.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension along which to index\n",
      "     |          index (LongTensor): indices of :attr:`tensor` to select from\n",
      "     |          tensor (Tensor): the tensor containing values to add\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.ones(5, 3)\n",
      "     |          >>> t = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
      "     |          >>> index = torch.tensor([0, 4, 2])\n",
      "     |          >>> x.index_add_(0, index, t)\n",
      "     |          tensor([[  2.,   3.,   4.],\n",
      "     |                  [  1.,   1.,   1.],\n",
      "     |                  [  8.,   9.,  10.],\n",
      "     |                  [  1.,   1.,   1.],\n",
      "     |                  [  5.,   6.,   7.]])\n",
      "     |  \n",
      "     |  index_copy(self, dim, index, tensor)\n",
      "     |  \n",
      "     |  index_copy_(...)\n",
      "     |      index_copy_(dim, index, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Copies the elements of :attr:`tensor` into the :attr:`self` tensor by selecting\n",
      "     |      the indices in the order given in :attr:`index`. For example, if ``dim == 0``\n",
      "     |      and ``index[i] == j``, then the ``i``\\ th row of :attr:`tensor` is copied to the\n",
      "     |      ``j``\\ th row of :attr:`self`.\n",
      "     |      \n",
      "     |      The :attr:`dim`\\ th dimension of :attr:`tensor` must have the same size as the\n",
      "     |      length of :attr:`index` (which must be a vector), and all other dimensions must\n",
      "     |      match :attr:`self`, or an error will be raised.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension along which to index\n",
      "     |          index (LongTensor): indices of :attr:`tensor` to select from\n",
      "     |          tensor (Tensor): the tensor containing values to copy\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.zeros(5, 3)\n",
      "     |          >>> t = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
      "     |          >>> index = torch.tensor([0, 4, 2])\n",
      "     |          >>> x.index_copy_(0, index, t)\n",
      "     |          tensor([[ 1.,  2.,  3.],\n",
      "     |                  [ 0.,  0.,  0.],\n",
      "     |                  [ 7.,  8.,  9.],\n",
      "     |                  [ 0.,  0.,  0.],\n",
      "     |                  [ 4.,  5.,  6.]])\n",
      "     |  \n",
      "     |  index_fill(self, dim, index, value)\n",
      "     |  \n",
      "     |  index_fill_(...)\n",
      "     |      index_fill_(dim, index, val) -> Tensor\n",
      "     |      \n",
      "     |      Fills the elements of the :attr:`self` tensor with value :attr:`val` by\n",
      "     |      selecting the indices in the order given in :attr:`index`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension along which to index\n",
      "     |          index (LongTensor): indices of :attr:`self` tensor to fill in\n",
      "     |          val (float): the value to fill with\n",
      "     |      \n",
      "     |      Example::\n",
      "     |          >>> x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
      "     |          >>> index = torch.tensor([0, 2])\n",
      "     |          >>> x.index_fill_(1, index, -1)\n",
      "     |          tensor([[-1.,  2., -1.],\n",
      "     |                  [-1.,  5., -1.],\n",
      "     |                  [-1.,  8., -1.]])\n",
      "     |  \n",
      "     |  index_put_(...)\n",
      "     |      index_put_(indices, value) -> Tensor\n",
      "     |      \n",
      "     |      Puts values from the tensor :attr:`value` into the tensor :attr:`self` using\n",
      "     |      the indices specified in :attr:`indices` (which is a tuple of Tensors). The\n",
      "     |      expression ``tensor.index_put_(indices, value)`` is equivalent to\n",
      "     |      ``tensor[indices] = value``. Returns :attr:`self`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          indices (tuple of LongTensor): tensors used to index into `self`.\n",
      "     |          value (Tensor): tensor of same dtype as `self`.\n",
      "     |  \n",
      "     |  index_select(...)\n",
      "     |      index_select(dim, index) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.index_select`\n",
      "     |  \n",
      "     |  int(...)\n",
      "     |      int() -> Tensor\n",
      "     |      \n",
      "     |      ``self.int()`` is equivalent to ``self.to(torch.int32)``. See :func:`to`.\n",
      "     |  \n",
      "     |  inverse(...)\n",
      "     |      inverse() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.inverse`\n",
      "     |  \n",
      "     |  irfft(...)\n",
      "     |      irfft(signal_ndim, normalized=False, onesided=True, signal_sizes=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.irfft`\n",
      "     |  \n",
      "     |  is_coalesced(...)\n",
      "     |  \n",
      "     |  is_contiguous(...)\n",
      "     |      is_contiguous() -> bool\n",
      "     |      \n",
      "     |      Returns True if :attr:`self` tensor is contiguous in memory in C order.\n",
      "     |  \n",
      "     |  is_distributed(...)\n",
      "     |  \n",
      "     |  is_floating_point(...)\n",
      "     |  \n",
      "     |  is_nonzero(...)\n",
      "     |  \n",
      "     |  is_pinned(self)\n",
      "     |      Returns true if this tensor resides in pinned memory\n",
      "     |  \n",
      "     |  is_same_size(...)\n",
      "     |  \n",
      "     |  is_set_to(...)\n",
      "     |      is_set_to(tensor) -> bool\n",
      "     |      \n",
      "     |      Returns True if this object refers to the same ``THTensor`` object from the\n",
      "     |      Torch C API as the given tensor.\n",
      "     |  \n",
      "     |  is_shared(self)\n",
      "     |      Checks if tensor is in shared memory.\n",
      "     |      \n",
      "     |      This is always ``True`` for CUDA tensors.\n",
      "     |  \n",
      "     |  is_signed(...)\n",
      "     |  \n",
      "     |  isclose(...)\n",
      "     |  \n",
      "     |  item(...)\n",
      "     |      item() -> number\n",
      "     |      \n",
      "     |      Returns the value of this tensor as a standard Python number. This only works\n",
      "     |      for tensors with one element.\n",
      "     |      \n",
      "     |      This operation is not differentiable.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([1.0])\n",
      "     |          >>> x.item()\n",
      "     |          1.0\n",
      "     |  \n",
      "     |  kthvalue(...)\n",
      "     |      kthvalue(k, dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.kthvalue`\n",
      "     |  \n",
      "     |  le(...)\n",
      "     |      le(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.le`\n",
      "     |  \n",
      "     |  le_(...)\n",
      "     |      le_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.le`\n",
      "     |  \n",
      "     |  lerp(...)\n",
      "     |      lerp(start, end, weight) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lerp`\n",
      "     |  \n",
      "     |  lerp_(...)\n",
      "     |      lerp_(start, end, weight) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lerp`\n",
      "     |  \n",
      "     |  lgamma(...)\n",
      "     |  \n",
      "     |  lgamma_(...)\n",
      "     |  \n",
      "     |  log(...)\n",
      "     |      log() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log`\n",
      "     |  \n",
      "     |  log10(...)\n",
      "     |      log10() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log10`\n",
      "     |  \n",
      "     |  log10_(...)\n",
      "     |      log10_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log10`\n",
      "     |  \n",
      "     |  log1p(...)\n",
      "     |      log1p() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log1p`\n",
      "     |  \n",
      "     |  log1p_(...)\n",
      "     |      log1p_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log1p`\n",
      "     |  \n",
      "     |  log2(...)\n",
      "     |      log2() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log2`\n",
      "     |  \n",
      "     |  log2_(...)\n",
      "     |      log2_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log2`\n",
      "     |  \n",
      "     |  log_(...)\n",
      "     |      log_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log`\n",
      "     |  \n",
      "     |  log_normal_(...)\n",
      "     |      log_normal_(mean=1, std=2, *, generator=None)\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with numbers samples from the log-normal distribution\n",
      "     |      parameterized by the given mean (µ) and standard deviation (σ).\n",
      "     |      Note that :attr:`mean` and :attr:`stdv` are the mean and standard deviation of\n",
      "     |      the underlying normal distribution, and not of the returned distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(x) = \\dfrac{1}{x \\sigma \\sqrt{2\\pi}}\\ e^{-\\dfrac{(\\ln x - \\mu)^2}{2\\sigma^2}}\n",
      "     |  \n",
      "     |  logdet(...)\n",
      "     |      logdet() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logdet`\n",
      "     |  \n",
      "     |  long(...)\n",
      "     |      long() -> Tensor\n",
      "     |      \n",
      "     |      ``self.long()`` is equivalent to ``self.to(torch.int64)``. See :func:`to`.\n",
      "     |  \n",
      "     |  lt(...)\n",
      "     |      lt(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lt`\n",
      "     |  \n",
      "     |  lt_(...)\n",
      "     |      lt_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lt`\n",
      "     |  \n",
      "     |  map2_(...)\n",
      "     |  \n",
      "     |  map_(...)\n",
      "     |      map_(tensor, callable)\n",
      "     |      \n",
      "     |      Applies :attr:`callable` for each element in :attr:`self` tensor and the given\n",
      "     |      :attr:`tensor` and stores the results in :attr:`self` tensor. :attr:`self` tensor and\n",
      "     |      the given :attr:`tensor` must be :ref:`broadcastable <broadcasting-semantics>`.\n",
      "     |      \n",
      "     |      The :attr:`callable` should have the signature::\n",
      "     |      \n",
      "     |          def callable(a, b) -> number\n",
      "     |  \n",
      "     |  masked_copy(self, mask, tensor)\n",
      "     |  \n",
      "     |  masked_copy_(self, mask, tensor)\n",
      "     |  \n",
      "     |  masked_fill(self, mask, value)\n",
      "     |  \n",
      "     |  masked_fill_(...)\n",
      "     |      masked_fill_(mask, value)\n",
      "     |      \n",
      "     |      Fills elements of :attr:`self` tensor with :attr:`value` where :attr:`mask` is\n",
      "     |      one. The shape of :attr:`mask` must be\n",
      "     |      :ref:`broadcastable <broadcasting-semantics>` with the shape of the underlying\n",
      "     |      tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          mask (ByteTensor): the binary mask\n",
      "     |          value (float): the value to fill in with\n",
      "     |  \n",
      "     |  masked_scatter(self, mask, tensor)\n",
      "     |  \n",
      "     |  masked_scatter_(...)\n",
      "     |      masked_scatter_(mask, source)\n",
      "     |      \n",
      "     |      Copies elements from :attr:`source` into :attr:`self` tensor at positions where\n",
      "     |      the :attr:`mask` is one.\n",
      "     |      The shape of :attr:`mask` must be :ref:`broadcastable <broadcasting-semantics>`\n",
      "     |      with the shape of the underlying tensor. The :attr:`source` should have at least\n",
      "     |      as many elements as the number of ones in :attr:`mask`\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          mask (ByteTensor): the binary mask\n",
      "     |          source (Tensor): the tensor to copy from\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The :attr:`mask` operates on the :attr:`self` tensor, not on the given\n",
      "     |          :attr:`source` tensor.\n",
      "     |  \n",
      "     |  masked_select(...)\n",
      "     |      masked_select(mask) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.masked_select`\n",
      "     |  \n",
      "     |  matmul(...)\n",
      "     |      matmul(tensor2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.matmul`\n",
      "     |  \n",
      "     |  max(...)\n",
      "     |      max(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.max`\n",
      "     |  \n",
      "     |  mean(...)\n",
      "     |      mean(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.mean`\n",
      "     |  \n",
      "     |  median(...)\n",
      "     |      median(dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.median`\n",
      "     |  \n",
      "     |  min(...)\n",
      "     |      min(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.min`\n",
      "     |  \n",
      "     |  mm(...)\n",
      "     |      mm(mat2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mm`\n",
      "     |  \n",
      "     |  mode(...)\n",
      "     |      mode(dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.mode`\n",
      "     |  \n",
      "     |  mul(...)\n",
      "     |      mul(value) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mul`\n",
      "     |  \n",
      "     |  mul_(...)\n",
      "     |      mul_(value)\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.mul`\n",
      "     |  \n",
      "     |  multinomial(...)\n",
      "     |      multinomial(num_samples, replacement=False, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.multinomial`\n",
      "     |  \n",
      "     |  mv(...)\n",
      "     |      mv(vec) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mv`\n",
      "     |  \n",
      "     |  narrow(...)\n",
      "     |      narrow(dimension, start, length) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new tensor that is a narrowed version of :attr:`self` tensor. The\n",
      "     |      dimension :attr:`dim` is narrowed from :attr:`start` to :attr:`start + length`. The\n",
      "     |      returned tensor and :attr:`self` tensor share the same underlying storage.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dimension (int): the dimension along which to narrow\n",
      "     |          start (int): the starting dimension\n",
      "     |          length (int): the distance to the ending dimension\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
      "     |          >>> x.narrow(0, 0, 2)\n",
      "     |          tensor([[ 1,  2,  3],\n",
      "     |                  [ 4,  5,  6]])\n",
      "     |          >>> x.narrow(1, 1, 2)\n",
      "     |          tensor([[ 2,  3],\n",
      "     |                  [ 5,  6],\n",
      "     |                  [ 8,  9]])\n",
      "     |  \n",
      "     |  ndimension(...)\n",
      "     |      ndimension() -> int\n",
      "     |      \n",
      "     |      Alias for :meth:`~Tensor.dim()`\n",
      "     |  \n",
      "     |  ne(...)\n",
      "     |      ne(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ne`\n",
      "     |  \n",
      "     |  ne_(...)\n",
      "     |      ne_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ne`\n",
      "     |  \n",
      "     |  neg(...)\n",
      "     |      neg() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.neg`\n",
      "     |  \n",
      "     |  neg_(...)\n",
      "     |      neg_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.neg`\n",
      "     |  \n",
      "     |  nelement(...)\n",
      "     |      nelement() -> int\n",
      "     |      \n",
      "     |      Alias for :meth:`~Tensor.numel`\n",
      "     |  \n",
      "     |  new(...)\n",
      "     |  \n",
      "     |  new_empty(...)\n",
      "     |      new_empty(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with uninitialized data.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones(())\n",
      "     |          >>> tensor.new_empty((2, 3))\n",
      "     |          tensor([[ 5.8182e-18,  4.5765e-41, -1.0545e+30],\n",
      "     |                  [ 3.0949e-41,  4.4842e-44,  0.0000e+00]])\n",
      "     |  \n",
      "     |  new_full(...)\n",
      "     |      new_full(size, fill_value, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with :attr:`fill_value`.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          fill_value (scalar): the number to fill the output tensor with.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones((2,), dtype=torch.float64)\n",
      "     |          >>> tensor.new_full((3, 4), 3.141592)\n",
      "     |          tensor([[ 3.1416,  3.1416,  3.1416,  3.1416],\n",
      "     |                  [ 3.1416,  3.1416,  3.1416,  3.1416],\n",
      "     |                  [ 3.1416,  3.1416,  3.1416,  3.1416]], dtype=torch.float64)\n",
      "     |  \n",
      "     |  new_ones(...)\n",
      "     |      new_ones(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with ``1``.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (int...): a list, tuple, or :class:`torch.Size` of integers defining the\n",
      "     |              shape of the output tensor.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.tensor((), dtype=torch.int32)\n",
      "     |          >>> tensor.new_ones((2, 3))\n",
      "     |          tensor([[ 1,  1,  1],\n",
      "     |                  [ 1,  1,  1]], dtype=torch.int32)\n",
      "     |  \n",
      "     |  new_tensor(...)\n",
      "     |      new_tensor(data, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new Tensor with :attr:`data` as the tensor data.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          :func:`new_tensor` always copies :attr:`data`. If you have a Tensor\n",
      "     |          ``data`` and want to avoid a copy, use :func:`torch.Tensor.requires_grad_`\n",
      "     |          or :func:`torch.Tensor.detach`.\n",
      "     |          If you have a numpy array and want to avoid a copy, use\n",
      "     |          :func:`torch.from_numpy`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          data (array_like): The returned Tensor copies :attr:`data`.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones((2,), dtype=torch.int8)\n",
      "     |          >>> data = [[0, 1], [2, 3]]\n",
      "     |          >>> tensor.new_tensor(data)\n",
      "     |          tensor([[ 0,  1],\n",
      "     |                  [ 2,  3]], dtype=torch.int8)\n",
      "     |  \n",
      "     |  new_zeros(...)\n",
      "     |      new_zeros(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with ``0``.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (int...): a list, tuple, or :class:`torch.Size` of integers defining the\n",
      "     |              shape of the output tensor.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.tensor((), dtype=torch.float64)\n",
      "     |          >>> tensor.new_ones((2, 3))\n",
      "     |          tensor([[ 1.,  1.,  1.],\n",
      "     |                  [ 1.,  1.,  1.]], dtype=torch.float64)\n",
      "     |  \n",
      "     |  nonzero(...)\n",
      "     |      nonzero() -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.nonzero`\n",
      "     |  \n",
      "     |  norm(...)\n",
      "     |      norm(p=2, dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.norm`\n",
      "     |  \n",
      "     |  normal_(...)\n",
      "     |      normal_(mean=0, std=1, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with elements samples from the normal distribution\n",
      "     |      parameterized by :attr:`mean` and :attr:`std`.\n",
      "     |  \n",
      "     |  numel(...)\n",
      "     |      numel() -> int\n",
      "     |      \n",
      "     |      See :func:`torch.numel`\n",
      "     |  \n",
      "     |  numpy(...)\n",
      "     |      numpy() -> numpy.ndarray\n",
      "     |      \n",
      "     |      Returns :attr:`self` tensor as a NumPy :class:`ndarray`. This tensor and the\n",
      "     |      returned :class:`ndarray` share the same underlying storage. Changes to\n",
      "     |      :attr:`self` tensor will be reflected in the :class:`ndarray` and vice versa.\n",
      "     |  \n",
      "     |  orgqr(...)\n",
      "     |      orgqr(input2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.orgqr`\n",
      "     |  \n",
      "     |  ormqr(...)\n",
      "     |      ormqr(input2, input3, left=True, transpose=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ormqr`\n",
      "     |  \n",
      "     |  permute(...)\n",
      "     |  \n",
      "     |  pin_memory(...)\n",
      "     |  \n",
      "     |  polygamma(...)\n",
      "     |  \n",
      "     |  polygamma_(...)\n",
      "     |  \n",
      "     |  potrf(...)\n",
      "     |      potrf(upper=True) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.potrf`\n",
      "     |  \n",
      "     |  potri(...)\n",
      "     |      potri(upper=True) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.potri`\n",
      "     |  \n",
      "     |  potrs(...)\n",
      "     |      potrs(input2, upper=True) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.potrs`\n",
      "     |  \n",
      "     |  pow(...)\n",
      "     |      pow(exponent) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.pow`\n",
      "     |  \n",
      "     |  pow_(...)\n",
      "     |      pow_(exponent) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.pow`\n",
      "     |  \n",
      "     |  prod(...)\n",
      "     |      prod(dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.prod`\n",
      "     |  \n",
      "     |  pstrf(...)\n",
      "     |      pstrf(upper=True, tol=-1) -> (Tensor, IntTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.pstrf`\n",
      "     |  \n",
      "     |  put_(...)\n",
      "     |      put_(indices, tensor, accumulate=False) -> Tensor\n",
      "     |      \n",
      "     |      Copies the elements from :attr:`tensor` into the positions specified by\n",
      "     |      indices. For the purpose of indexing, the :attr:`self` tensor is treated as if\n",
      "     |      it were a 1-D tensor.\n",
      "     |      \n",
      "     |      If :attr:`accumulate` is ``True``, the elements in :attr:`tensor` are added to\n",
      "     |      :attr:`self`. If accumulate is ``False``, the behavior is undefined if indices\n",
      "     |      contain duplicate elements.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          indices (LongTensor): the indices into self\n",
      "     |          tensor (Tensor): the tensor containing values to copy from\n",
      "     |          accumulate (bool): whether to accumulate into self\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> src = torch.tensor([[4, 3, 5],\n",
      "     |                                  [6, 7, 8]])\n",
      "     |          >>> src.put_(torch.tensor([1, 3]), torch.tensor([9, 10]))\n",
      "     |          tensor([[  4,   9,   5],\n",
      "     |                  [ 10,   7,   8]])\n",
      "     |  \n",
      "     |  qr(...)\n",
      "     |      qr() -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.qr`\n",
      "     |  \n",
      "     |  random_(...)\n",
      "     |      random_(from=0, to=None, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with numbers sampled from the discrete uniform\n",
      "     |      distribution over ``[from, to - 1]``. If not specified, the values are usually\n",
      "     |      only bounded by :attr:`self` tensor's data type. However, for floating point\n",
      "     |      types, if unspecified, range will be ``[0, 2^mantissa]`` to ensure that every\n",
      "     |      value is representable. For example, `torch.tensor(1, dtype=torch.double).random_()`\n",
      "     |      will be uniform in ``[0, 2^53]``.\n",
      "     |  \n",
      "     |  reciprocal(...)\n",
      "     |      reciprocal() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.reciprocal`\n",
      "     |  \n",
      "     |  reciprocal_(...)\n",
      "     |      reciprocal_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.reciprocal`\n",
      "     |  \n",
      "     |  record_stream(...)\n",
      "     |  \n",
      "     |  register_hook(self, hook)\n",
      "     |      Registers a backward hook.\n",
      "     |      \n",
      "     |      The hook will be called every time a gradient with respect to the\n",
      "     |      Tensor is computed. The hook should have the following signature::\n",
      "     |      \n",
      "     |          hook(grad) -> Tensor or None\n",
      "     |      \n",
      "     |      The hook should not modify its argument, but it can optionally return\n",
      "     |      a new gradient which will be used in place of :attr:`grad`.\n",
      "     |      \n",
      "     |      This function returns a handle with a method ``handle.remove()``\n",
      "     |      that removes the hook from the module.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          >>> v = torch.tensor([0., 0., 0.], requires_grad=True)\n",
      "     |          >>> h = v.register_hook(lambda grad: grad * 2)  # double the gradient\n",
      "     |          >>> v.backward(torch.tensor([1., 2., 3.]))\n",
      "     |          >>> v.grad\n",
      "     |      \n",
      "     |           2\n",
      "     |           4\n",
      "     |           6\n",
      "     |          [torch.FloatTensor of size (3,)]\n",
      "     |      \n",
      "     |          >>> h.remove()  # removes the hook\n",
      "     |  \n",
      "     |  reinforce(self, reward)\n",
      "     |  \n",
      "     |  relu(...)\n",
      "     |  \n",
      "     |  relu_(...)\n",
      "     |  \n",
      "     |  remainder(...)\n",
      "     |      remainder(divisor) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.remainder`\n",
      "     |  \n",
      "     |  remainder_(...)\n",
      "     |      remainder_(divisor) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.remainder`\n",
      "     |  \n",
      "     |  renorm(...)\n",
      "     |      renorm(p, dim, maxnorm) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.renorm`\n",
      "     |  \n",
      "     |  renorm_(...)\n",
      "     |      renorm_(p, dim, maxnorm) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.renorm`\n",
      "     |  \n",
      "     |  repeat(...)\n",
      "     |      repeat(*sizes) -> Tensor\n",
      "     |      \n",
      "     |      Repeats this tensor along the specified dimensions.\n",
      "     |      \n",
      "     |      Unlike :meth:`~Tensor.expand`, this function copies the tensor's data.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          sizes (torch.Size or int...): The number of times to repeat this tensor along each\n",
      "     |              dimension\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([1, 2, 3])\n",
      "     |          >>> x.repeat(4, 2)\n",
      "     |          tensor([[ 1,  2,  3,  1,  2,  3],\n",
      "     |                  [ 1,  2,  3,  1,  2,  3],\n",
      "     |                  [ 1,  2,  3,  1,  2,  3],\n",
      "     |                  [ 1,  2,  3,  1,  2,  3]])\n",
      "     |          >>> x.repeat(4, 2, 1).size()\n",
      "     |          torch.Size([4, 2, 3])\n",
      "     |  \n",
      "     |  requires_grad_(...)\n",
      "     |      requires_grad_(requires_grad=True) -> Tensor\n",
      "     |      \n",
      "     |      Change if autograd should record operations on this tensor: sets this tensor's\n",
      "     |      :attr:`requires_grad` attribute in-place. Returns this tensor.\n",
      "     |      \n",
      "     |      :func:`require_grad_`'s main use case is to tell autograd to begin recording\n",
      "     |      operations on a Tensor ``tensor``. If ``tensor`` has ``requires_grad=False``\n",
      "     |      (because it was obtained through a DataLoader, or required preprocessing or\n",
      "     |      initialization), ``tensor.requires_grad_()`` makes it so that autograd will\n",
      "     |      begin to record operations on ``tensor``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          requires_grad (bool): If autograd should record operations on this tensor.\n",
      "     |              Default: ``True``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> # Let's say we want to preprocess some saved weights and use\n",
      "     |          >>> # the result as new weights.\n",
      "     |          >>> saved_weights = [0.1, 0.2, 0.3, 0.25]\n",
      "     |          >>> loaded_weights = torch.tensor(saved_weights)\n",
      "     |          >>> weights = preprocess(loaded_weights)  # some function\n",
      "     |          >>> weights\n",
      "     |          tensor([-0.5503,  0.4926, -2.1158, -0.8303])\n",
      "     |      \n",
      "     |          >>> # Now, start to record operations done to weights\n",
      "     |          >>> weights.requires_grad_()\n",
      "     |          >>> out = weights.pow(2).sum()\n",
      "     |          >>> out.backward()\n",
      "     |          >>> weights.grad\n",
      "     |          tensor([-1.1007,  0.9853, -4.2316, -1.6606])\n",
      "     |  \n",
      "     |  reshape(...)\n",
      "     |      reshape(*shape) -> Tensor\n",
      "     |      \n",
      "     |      Returns a tensor with the same data and number of elements as :attr:`self`,\n",
      "     |      but with the specified shape.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          shape (tuple of ints or int...): the desired shape\n",
      "     |      \n",
      "     |      See :func:`torch.reshape`\n",
      "     |  \n",
      "     |  resize(self, *sizes)\n",
      "     |  \n",
      "     |  resize_(...)\n",
      "     |      resize_(*sizes) -> Tensor\n",
      "     |      \n",
      "     |      Resizes :attr:`self` tensor to the specified size. If the number of elements is\n",
      "     |      larger than the current storage size, then the underlying storage is resized\n",
      "     |      to fit the new number of elements. If the number of elements is smaller, the\n",
      "     |      underlying storage is not changed. Existing elements are preserved but any new\n",
      "     |      memory is uninitialized.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          sizes (torch.Size or int...): the desired size\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1, 2], [3, 4], [5, 6]])\n",
      "     |          >>> x.resize_(2, 2)\n",
      "     |          tensor([[ 1,  2],\n",
      "     |                  [ 3,  4]])\n",
      "     |  \n",
      "     |  resize_as(self, tensor)\n",
      "     |  \n",
      "     |  resize_as_(...)\n",
      "     |      resize_as_(tensor) -> Tensor\n",
      "     |      \n",
      "     |      Resizes the :attr:`self` tensor to be the same size as the specified\n",
      "     |      :attr:`tensor`. This is equivalent to ``self.resize_(tensor.size())``.\n",
      "     |  \n",
      "     |  retain_grad(self)\n",
      "     |      Enables .grad attribute for non-leaf Tensors.\n",
      "     |  \n",
      "     |  rfft(...)\n",
      "     |      rfft(signal_ndim, normalized=False, onesided=True) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.rfft`\n",
      "     |  \n",
      "     |  round(...)\n",
      "     |      round() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.round`\n",
      "     |  \n",
      "     |  round_(...)\n",
      "     |      round_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.round`\n",
      "     |  \n",
      "     |  rsqrt(...)\n",
      "     |      rsqrt() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.rsqrt`\n",
      "     |  \n",
      "     |  rsqrt_(...)\n",
      "     |      rsqrt_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.rsqrt`\n",
      "     |  \n",
      "     |  scatter(self, dim, index, source)\n",
      "     |  \n",
      "     |  scatter_(...)\n",
      "     |      scatter_(dim, index, src) -> Tensor\n",
      "     |      \n",
      "     |      Writes all values from the tensor :attr:`src` into :attr:`self` at the indices\n",
      "     |      specified in the :attr:`index` tensor. For each value in :attr:`src`, its output\n",
      "     |      index is specified by its index in :attr:`src` for dimension != :attr:`dim` and\n",
      "     |      by the corresponding value in :attr:`index` for dimension = :attr:`dim`.\n",
      "     |      \n",
      "     |      For a 3-D tensor, :attr:`self` is updated as::\n",
      "     |      \n",
      "     |          self[index[i][j][k]][j][k] = src[i][j][k]  # if dim == 0\n",
      "     |          self[i][index[i][j][k]][k] = src[i][j][k]  # if dim == 1\n",
      "     |          self[i][j][index[i][j][k]] = src[i][j][k]  # if dim == 2\n",
      "     |      \n",
      "     |      This is the reverse operation of the manner described in :meth:`~Tensor.gather`.\n",
      "     |      \n",
      "     |      :attr:`self`, :attr:`index` and :attr:`src` should have same number of\n",
      "     |      dimensions. It is also required that `index->size[d] <= src->size[d]` for all\n",
      "     |      dimension `d`, and that `index->size[d] <= real->size[d]` for all dimensions\n",
      "     |      `d != dim`.\n",
      "     |      \n",
      "     |      Moreover, as for :meth:`~Tensor.gather`, the values of :attr:`index` must be\n",
      "     |      between `0` and `(self.size(dim) -1)` inclusive, and all values in a row along\n",
      "     |      the specified dimension :attr:`dim` must be unique.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          input (Tensor): the source tensor\n",
      "     |          dim (int): the axis along which to index\n",
      "     |          index (LongTensor): the indices of elements to scatter\n",
      "     |          src (Tensor or float): the source element(s) to scatter\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.rand(2, 5)\n",
      "     |          >>> x\n",
      "     |          tensor([[ 0.3992,  0.2908,  0.9044,  0.4850,  0.6004],\n",
      "     |                  [ 0.5735,  0.9006,  0.6797,  0.4152,  0.1732]])\n",
      "     |          >>> torch.zeros(3, 5).scatter_(0, torch.tensor([[0, 1, 2, 0, 0], [2, 0, 0, 1, 2]]), x)\n",
      "     |          tensor([[ 0.3992,  0.9006,  0.6797,  0.4850,  0.6004],\n",
      "     |                  [ 0.0000,  0.2908,  0.0000,  0.4152,  0.0000],\n",
      "     |                  [ 0.5735,  0.0000,  0.9044,  0.0000,  0.1732]])\n",
      "     |      \n",
      "     |          >>> z = torch.zeros(2, 4).scatter_(1, torch.tensor([[2], [3]]), 1.23)\n",
      "     |          >>> z\n",
      "     |          tensor([[ 0.0000,  0.0000,  1.2300,  0.0000],\n",
      "     |                  [ 0.0000,  0.0000,  0.0000,  1.2300]])\n",
      "     |  \n",
      "     |  scatter_add(self, dim, index, source)\n",
      "     |  \n",
      "     |  scatter_add_(...)\n",
      "     |  \n",
      "     |  select(...)\n",
      "     |      select(dim, index) -> Tensor\n",
      "     |      \n",
      "     |      Slices the :attr:`self` tensor along the selected dimension at the given index.\n",
      "     |      This function returns a tensor with the given dimension removed.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the dimension to slice\n",
      "     |          index (int): the index to select with\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          :meth:`select` is equivalent to slicing. For example,\n",
      "     |          ``tensor.select(0, index)`` is equivalent to ``tensor[index]`` and\n",
      "     |          ``tensor.select(2, index)`` is equivalent to ``tensor[:,:,index]``.\n",
      "     |  \n",
      "     |  set_(...)\n",
      "     |      set_(source=None, storage_offset=0, size=None, stride=None) -> Tensor\n",
      "     |      \n",
      "     |      Sets the underlying storage, size, and strides. If :attr:`source` is a tensor,\n",
      "     |      :attr:`self` tensor will share the same storage and have the same size and\n",
      "     |      strides as :attr:`source`. Changes to elements in one tensor will be reflected\n",
      "     |      in the other.\n",
      "     |      \n",
      "     |      If :attr:`source` is a :class:`~torch.Storage`, the method sets the underlying\n",
      "     |      storage, offset, size, and stride.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          source (Tensor or Storage): the tensor or storage to use\n",
      "     |          storage_offset (int, optional): the offset in the storage\n",
      "     |          size (torch.Size, optional): the desired size. Defaults to the size of the source.\n",
      "     |          stride (tuple, optional): the desired stride. Defaults to C-contiguous strides.\n",
      "     |  \n",
      "     |  share_memory_(self)\n",
      "     |      Moves the underlying storage to shared memory.\n",
      "     |      \n",
      "     |      This is a no-op if the underlying storage is already in shared memory\n",
      "     |      and for CUDA tensors. Tensors in shared memory cannot be resized.\n",
      "     |  \n",
      "     |  short(...)\n",
      "     |      short() -> Tensor\n",
      "     |      \n",
      "     |      ``self.short()`` is equivalent to ``self.to(torch.int16)``. See :func:`to`.\n",
      "     |  \n",
      "     |  sigmoid(...)\n",
      "     |      sigmoid() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sigmoid`\n",
      "     |  \n",
      "     |  sigmoid_(...)\n",
      "     |      sigmoid_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sigmoid`\n",
      "     |  \n",
      "     |  sign(...)\n",
      "     |      sign() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sign`\n",
      "     |  \n",
      "     |  sign_(...)\n",
      "     |      sign_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sign`\n",
      "     |  \n",
      "     |  sin(...)\n",
      "     |      sin() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sin`\n",
      "     |  \n",
      "     |  sin_(...)\n",
      "     |      sin_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sin`\n",
      "     |  \n",
      "     |  sinh(...)\n",
      "     |      sinh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sinh`\n",
      "     |  \n",
      "     |  sinh_(...)\n",
      "     |      sinh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sinh`\n",
      "     |  \n",
      "     |  size(...)\n",
      "     |      size() -> torch.Size\n",
      "     |      \n",
      "     |      Returns the size of the :attr:`self` tensor. The returned value is a subclass of\n",
      "     |      :class:`tuple`.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> torch.empty(3, 4, 5).size()\n",
      "     |          torch.Size([3, 4, 5])\n",
      "     |  \n",
      "     |  slice(...)\n",
      "     |  \n",
      "     |  slogdet(...)\n",
      "     |      slogdet() -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.slogdet`\n",
      "     |  \n",
      "     |  smm(...)\n",
      "     |  \n",
      "     |  sort(...)\n",
      "     |      sort(dim=None, descending=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.sort`\n",
      "     |  \n",
      "     |  split(self, split_size, dim=0)\n",
      "     |      See :func:`torch.split`\n",
      "     |  \n",
      "     |  split_with_sizes(...)\n",
      "     |  \n",
      "     |  sqrt(...)\n",
      "     |      sqrt() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sqrt`\n",
      "     |  \n",
      "     |  sqrt_(...)\n",
      "     |      sqrt_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sqrt`\n",
      "     |  \n",
      "     |  squeeze(...)\n",
      "     |      squeeze(dim=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.squeeze`\n",
      "     |  \n",
      "     |  squeeze_(...)\n",
      "     |      squeeze_(dim=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.squeeze`\n",
      "     |  \n",
      "     |  sspaddmm(...)\n",
      "     |  \n",
      "     |  std(...)\n",
      "     |      std(dim=None, unbiased=True, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.std`\n",
      "     |  \n",
      "     |  stft(...)\n",
      "     |      stft(frame_length, hop, fft_size=None, return_onesided=True, window=None, pad_end=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.stft`\n",
      "     |  \n",
      "     |  storage(...)\n",
      "     |      storage() -> torch.Storage\n",
      "     |      \n",
      "     |      Returns the underlying storage\n",
      "     |  \n",
      "     |  storage_offset(...)\n",
      "     |      storage_offset() -> int\n",
      "     |      \n",
      "     |      Returns :attr:`self` tensor's offset in the underlying storage in terms of\n",
      "     |      number of storage elements (not bytes).\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([1, 2, 3, 4, 5])\n",
      "     |          >>> x.storage_offset()\n",
      "     |          0\n",
      "     |          >>> x[3:].storage_offset()\n",
      "     |          3\n",
      "     |  \n",
      "     |  storage_type(...)\n",
      "     |  \n",
      "     |  stride(...)\n",
      "     |      stride(dim) -> tuple or int\n",
      "     |      \n",
      "     |      Returns the stride of :attr:`self` tensor.\n",
      "     |      \n",
      "     |      Stride is the jump necessary to go from one element to the next one in the\n",
      "     |      specified dimension :attr:`dim`. A tuple of all strides is returned when no\n",
      "     |      argument is passed in. Otherwise, an integer value is returned as the stride in\n",
      "     |      the particular dimension :attr:`dim`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int, optional): the desired dimension in which stride is required\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1, 2, 3, 4, 5], [6, 7, 8, 9, 10]])\n",
      "     |          >>> x.stride()\n",
      "     |          (5, 1)\n",
      "     |          >>>x.stride(0)\n",
      "     |          5\n",
      "     |          >>> x.stride(-1)\n",
      "     |          1\n",
      "     |  \n",
      "     |  sub(...)\n",
      "     |      sub(value, other) -> Tensor\n",
      "     |      \n",
      "     |      Subtracts a scalar or tensor from :attr:`self` tensor. If both :attr:`value` and\n",
      "     |      :attr:`other` are specified, each element of :attr:`other` is scaled by\n",
      "     |      :attr:`value` before being used.\n",
      "     |      \n",
      "     |      When :attr:`other` is a tensor, the shape of :attr:`other` must be\n",
      "     |      :ref:`broadcastable <broadcasting-semantics>` with the shape of the underlying\n",
      "     |      tensor.\n",
      "     |  \n",
      "     |  sub_(...)\n",
      "     |      sub_(x) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sub`\n",
      "     |  \n",
      "     |  sum(...)\n",
      "     |      sum(dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sum`\n",
      "     |  \n",
      "     |  svd(...)\n",
      "     |      svd(some=True) -> (Tensor, Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.svd`\n",
      "     |  \n",
      "     |  symeig(...)\n",
      "     |      symeig(eigenvectors=False, upper=True) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.symeig`\n",
      "     |  \n",
      "     |  t(...)\n",
      "     |      t() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.t`\n",
      "     |  \n",
      "     |  t_(...)\n",
      "     |      t_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.t`\n",
      "     |  \n",
      "     |  take(...)\n",
      "     |      take(indices) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.take`\n",
      "     |  \n",
      "     |  tan(...)\n",
      "     |  \n",
      "     |  tan_(...)\n",
      "     |      tan_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.tan`\n",
      "     |  \n",
      "     |  tanh(...)\n",
      "     |      tanh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tanh`\n",
      "     |  \n",
      "     |  tanh_(...)\n",
      "     |      tanh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.tanh`\n",
      "     |  \n",
      "     |  to(...)\n",
      "     |      to(*args, **kwargs) -> Tensor\n",
      "     |      \n",
      "     |      Performs Tensor dtype and/or device conversion. A :class:`torch.dtype` and :class:`torch.device` are\n",
      "     |      inferred from the arguments of ``self.to(*args, **kwargs)``.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          If the ``self`` Tensor already\n",
      "     |          has the correct :class:`torch.dtype` and :class:`torch.device`, then ``self`` is returned.\n",
      "     |          Otherwise, the returned tensor is a copy of ``self`` with the desired\n",
      "     |          :class:`torch.dtype` and :class:`torch.device`.\n",
      "     |      \n",
      "     |      Here are the ways to call ``to``:\n",
      "     |      \n",
      "     |      .. function:: to(dtype) -> Tensor\n",
      "     |      \n",
      "     |          Returns a Tensor with the specified :attr:`dtype`\n",
      "     |      \n",
      "     |      .. function:: to(device, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |          Returns a Tensor with the specified :attr:`device` and (optional)\n",
      "     |          :attr:`dtype`. If :attr:`dtype` is ``None`` it is inferred to be ``self.dtype``.\n",
      "     |      \n",
      "     |      .. function:: to(other) -> Tensor\n",
      "     |      \n",
      "     |          Returns a Tensor with same :class:`torch.dtype` and :class:`torch.device` as the Tensor\n",
      "     |          :attr:`other`.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.randn(2, 2)  # Initially dtype=float32, device=cpu\n",
      "     |          >>> tensor.to(torch.float64)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], dtype=torch.float64)\n",
      "     |      \n",
      "     |          >>> cuda0 = torch.device('cuda:0')\n",
      "     |          >>> tensor.to(cuda0)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], device='cuda:0')\n",
      "     |      \n",
      "     |          >>> tensor.to(cuda0, dtype=torch.float64)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], dtype=torch.float64, device='cuda:0')\n",
      "     |      \n",
      "     |          >>> other = torch.randn((), dtype=torch.float64, device=cuda0)\n",
      "     |          >>> tensor.to(other)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], dtype=torch.float64, device='cuda:0')\n",
      "     |  \n",
      "     |  to_dense(...)\n",
      "     |  \n",
      "     |  tolist(...)\n",
      "     |  \n",
      "     |  topk(...)\n",
      "     |      topk(k, dim=None, largest=True, sorted=True) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.topk`\n",
      "     |  \n",
      "     |  trace(...)\n",
      "     |      trace() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.trace`\n",
      "     |  \n",
      "     |  transpose(...)\n",
      "     |      transpose(dim0, dim1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.transpose`\n",
      "     |  \n",
      "     |  transpose_(...)\n",
      "     |      transpose_(dim0, dim1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.transpose`\n",
      "     |  \n",
      "     |  tril(...)\n",
      "     |      tril(k=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tril`\n",
      "     |  \n",
      "     |  tril_(...)\n",
      "     |      tril_(k=0) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.tril`\n",
      "     |  \n",
      "     |  triu(...)\n",
      "     |      triu(k=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.triu`\n",
      "     |  \n",
      "     |  triu_(...)\n",
      "     |      triu_(k=0) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.triu`\n",
      "     |  \n",
      "     |  trtrs(...)\n",
      "     |      trtrs(A, upper=True, transpose=False, unitriangular=False) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.trtrs`\n",
      "     |  \n",
      "     |  trunc(...)\n",
      "     |      trunc() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.trunc`\n",
      "     |  \n",
      "     |  trunc_(...)\n",
      "     |      trunc_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.trunc`\n",
      "     |  \n",
      "     |  type(...)\n",
      "     |      type(dtype=None, non_blocking=False, **kwargs) -> str or Tensor\n",
      "     |      Returns the type if `dtype` is not provided, else casts this object to\n",
      "     |      the specified type.\n",
      "     |      \n",
      "     |      If this is already of the correct type, no copy is performed and the\n",
      "     |      original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (type or string): The desired type\n",
      "     |          non_blocking (bool): If ``True``, and the source is in pinned memory\n",
      "     |              and destination is on the GPU or vice versa, the copy is performed\n",
      "     |              asynchronously with respect to the host. Otherwise, the argument\n",
      "     |              has no effect.\n",
      "     |          **kwargs: For compatibility, may contain the key ``async`` in place of\n",
      "     |              the ``non_blocking`` argument. The ``async`` arg is deprecated.\n",
      "     |  \n",
      "     |  type_as(...)\n",
      "     |      type_as(tensor) -> Tensor\n",
      "     |      \n",
      "     |      Returns this tensor cast to the type of the given tensor.\n",
      "     |      \n",
      "     |      This is a no-op if the tensor is already of the correct type. This is\n",
      "     |      equivalent to::\n",
      "     |      \n",
      "     |          self.type(tensor.type())\n",
      "     |      \n",
      "     |      Params:\n",
      "     |          tensor (Tensor): the tensor which has the desired type\n",
      "     |  \n",
      "     |  unfold(...)\n",
      "     |      unfold(dim, size, step) -> Tensor\n",
      "     |      \n",
      "     |      Returns a tensor which contains all slices of size :attr:`size` from\n",
      "     |      :attr:`self` tensor in the dimension :attr:`dim`.\n",
      "     |      \n",
      "     |      Step between two slices is given by :attr:`step`.\n",
      "     |      \n",
      "     |      If `sizedim` is the size of dimension dim for :attr:`self`, the size of\n",
      "     |      dimension :attr:`dim` in the returned tensor will be\n",
      "     |      `(sizedim - size) / step + 1`.\n",
      "     |      \n",
      "     |      An additional dimension of size size is appended in the returned tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension in which unfolding happens\n",
      "     |          size (int): the size of each slice that is unfolded\n",
      "     |          step (int): the step between each slice\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.arange(1, 8)\n",
      "     |          >>> x\n",
      "     |          tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.])\n",
      "     |          >>> x.unfold(0, 2, 1)\n",
      "     |          tensor([[ 1.,  2.],\n",
      "     |                  [ 2.,  3.],\n",
      "     |                  [ 3.,  4.],\n",
      "     |                  [ 4.,  5.],\n",
      "     |                  [ 5.,  6.],\n",
      "     |                  [ 6.,  7.]])\n",
      "     |          >>> x.unfold(0, 2, 2)\n",
      "     |          tensor([[ 1.,  2.],\n",
      "     |                  [ 3.,  4.],\n",
      "     |                  [ 5.,  6.]])\n",
      "     |  \n",
      "     |  uniform_(...)\n",
      "     |      uniform_(from=0, to=1) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with numbers sampled from the continuous uniform\n",
      "     |      distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |          P(x) = \\dfrac{1}{\\text{to} - \\text{from}}\n",
      "     |  \n",
      "     |  unique(self, sorted=False, return_inverse=False)\n",
      "     |      Returns the unique scalar elements of the tensor as a 1-D tensor.\n",
      "     |      \n",
      "     |      See :func:`torch.unique`\n",
      "     |  \n",
      "     |  unsqueeze(...)\n",
      "     |      unsqueeze(dim) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.unsqueeze`\n",
      "     |  \n",
      "     |  unsqueeze_(...)\n",
      "     |      unsqueeze_(dim) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.unsqueeze`\n",
      "     |  \n",
      "     |  var(...)\n",
      "     |      var(dim=None, unbiased=True, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.var`\n",
      "     |  \n",
      "     |  view(...)\n",
      "     |      view(*args) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new tensor with the same data as the :attr:`self` tensor but of a\n",
      "     |      different size.\n",
      "     |      \n",
      "     |      The returned tensor shares the same data and must have the same number\n",
      "     |      of elements, but may have a different size. For a tensor to be viewed, the new\n",
      "     |      view size must be compatible with its original size and stride, i.e., each new\n",
      "     |      view dimension must either be a subspace of an original dimension, or only span\n",
      "     |      across original dimensions :math:`d, d+1, \\dots, d+k` that satisfy the following\n",
      "     |      contiguity-like condition that :math:`\\forall i = 0, \\dots, k-1`,\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |        stride[i] = stride[i+1] \\times size[i+1]\n",
      "     |      \n",
      "     |      Otherwise, :func:`contiguous` needs to be called before the tensor can be\n",
      "     |      viewed.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          args (torch.Size or int...): the desired size\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.randn(4, 4)\n",
      "     |          >>> x.size()\n",
      "     |          torch.Size([4, 4])\n",
      "     |          >>> y = x.view(16)\n",
      "     |          >>> y.size()\n",
      "     |          torch.Size([16])\n",
      "     |          >>> z = x.view(-1, 8)  # the size -1 is inferred from other dimensions\n",
      "     |          >>> z.size()\n",
      "     |          torch.Size([2, 8])\n",
      "     |  \n",
      "     |  view_as(self, tensor)\n",
      "     |      view_as(other) -> Tensor\n",
      "     |      \n",
      "     |      View this tensor as the same size as :attr:`other`.\n",
      "     |      ``self.view_as(other)`` is equivalent to ``self.view(other.size())``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          other (:class:`torch.Tensor`): The result tensor has the same size\n",
      "     |              as :attr:`other.size()`.\n",
      "     |  \n",
      "     |  where(...)\n",
      "     |      where(condition, y) -> Tensor\n",
      "     |      \n",
      "     |      ``self.where(condition, y)`` is equivalent to ``torch.where(condition, self, y)``.\n",
      "     |      See :func:`torch.where`\n",
      "     |  \n",
      "     |  zero_(...)\n",
      "     |      zero_() -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with zeros.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  data\n",
      "     |  \n",
      "     |  device\n",
      "     |  \n",
      "     |  grad\n",
      "     |  \n",
      "     |  grad_fn\n",
      "     |  \n",
      "     |  is_leaf\n",
      "     |  \n",
      "     |  name\n",
      "     |  \n",
      "     |  output_nr\n",
      "     |  \n",
      "     |  requires_grad\n",
      "     |  \n",
      "     |  shape\n",
      "     |  \n",
      "     |  volatile\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  dtype = torch.int64\n",
      "     |  \n",
      "     |  is_cuda = False\n",
      "     |  \n",
      "     |  is_sparse = False\n",
      "     |  \n",
      "     |  layout = torch.strided\n",
      "    \n",
      "    class Node(pybind11_builtins.pybind11_object)\n",
      "     |  Method resolution order:\n",
      "     |      Node\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(...)\n",
      "     |      __repr__(self: torch._C.Node) -> str\n",
      "     |  \n",
      "     |  addInput(...)\n",
      "     |      addInput(self: torch._C.Node, arg0: torch._C.Value) -> torch._C.Value\n",
      "     |  \n",
      "     |  addOutput(...)\n",
      "     |      addOutput(self: torch._C.Node) -> torch._C.Value\n",
      "     |  \n",
      "     |  attributeNames(...)\n",
      "     |      attributeNames(self: torch._C.Node) -> List[str]\n",
      "     |  \n",
      "     |  cconv(...)\n",
      "     |      cconv(self: torch._C.Node) -> str\n",
      "     |  \n",
      "     |  copyAttributes(...)\n",
      "     |      copyAttributes(self: torch._C.Node, arg0: torch::jit::Attributes<torch::jit::Node>) -> None\n",
      "     |  \n",
      "     |  destroy(...)\n",
      "     |      destroy(self: torch._C.Node) -> None\n",
      "     |  \n",
      "     |  eraseOutput(...)\n",
      "     |      eraseOutput(self: torch._C.Node, arg0: int) -> None\n",
      "     |  \n",
      "     |  f(...)\n",
      "     |      f(self: torch._C.Node, arg0: str) -> float\n",
      "     |  \n",
      "     |  f_(...)\n",
      "     |      f_(self: torch._C.Node, arg0: str, arg1: float) -> torch._C.Node\n",
      "     |  \n",
      "     |  fs(...)\n",
      "     |      fs(self: torch._C.Node, arg0: str) -> List[float]\n",
      "     |  \n",
      "     |  fs_(...)\n",
      "     |      fs_(self: torch._C.Node, arg0: str, arg1: List[float]) -> torch._C.Node\n",
      "     |  \n",
      "     |  g(...)\n",
      "     |      g(self: torch._C.Node, arg0: str) -> torch._C.Graph\n",
      "     |  \n",
      "     |  g_(...)\n",
      "     |      g_(self: torch._C.Node, arg0: str, arg1: torch._C.Graph) -> torch._C.Node\n",
      "     |  \n",
      "     |  gs(...)\n",
      "     |      gs(self: torch._C.Node, arg0: str) -> List[torch._C.Graph]\n",
      "     |  \n",
      "     |  gs_(...)\n",
      "     |      gs_(self: torch._C.Node, arg0: str, arg1: List[torch._C.Graph]) -> torch._C.Node\n",
      "     |  \n",
      "     |  hasAttribute(...)\n",
      "     |      hasAttribute(self: torch._C.Node, arg0: str) -> bool\n",
      "     |  \n",
      "     |  hasAttributes(...)\n",
      "     |      hasAttributes(self: torch._C.Node) -> bool\n",
      "     |  \n",
      "     |  hasMultipleOutputs(...)\n",
      "     |      hasMultipleOutputs(self: torch._C.Node) -> bool\n",
      "     |  \n",
      "     |  hasUses(...)\n",
      "     |      hasUses(self: torch._C.Node) -> bool\n",
      "     |  \n",
      "     |  i(...)\n",
      "     |      i(self: torch._C.Node, arg0: str) -> int\n",
      "     |  \n",
      "     |  i_(...)\n",
      "     |      i_(self: torch._C.Node, arg0: str, arg1: int) -> torch._C.Node\n",
      "     |  \n",
      "     |  inputs(...)\n",
      "     |      inputs(self: torch._C.Node) -> iterator\n",
      "     |  \n",
      "     |  insertAfter(...)\n",
      "     |      insertAfter(self: torch._C.Node, arg0: torch._C.Node) -> torch._C.Node\n",
      "     |  \n",
      "     |  insertBefore(...)\n",
      "     |      insertBefore(self: torch._C.Node, arg0: torch._C.Node) -> torch._C.Node\n",
      "     |  \n",
      "     |  is(...)\n",
      "     |      is(self: torch._C.Node, arg0: str) -> List[int]\n",
      "     |  \n",
      "     |  is_(...)\n",
      "     |      is_(self: torch._C.Node, arg0: str, arg1: List[int]) -> torch._C.Node\n",
      "     |  \n",
      "     |  kind(...)\n",
      "     |      kind(self: torch._C.Node) -> Symbol\n",
      "     |  \n",
      "     |  kindOf(...)\n",
      "     |      kindOf(self: torch._C.Node, arg0: str) -> AttributeKind\n",
      "     |  \n",
      "     |  moveAfter(...)\n",
      "     |      moveAfter(self: torch._C.Node, arg0: torch._C.Node) -> None\n",
      "     |  \n",
      "     |  moveBefore(...)\n",
      "     |      moveBefore(self: torch._C.Node, arg0: torch._C.Node) -> None\n",
      "     |  \n",
      "     |  output(...)\n",
      "     |      output(self: torch._C.Node) -> torch._C.Value\n",
      "     |  \n",
      "     |  outputs(...)\n",
      "     |      outputs(self: torch._C.Node) -> iterator\n",
      "     |  \n",
      "     |  outputsSize(...)\n",
      "     |      outputsSize(self: torch._C.Node) -> int\n",
      "     |  \n",
      "     |  pyname(...)\n",
      "     |      pyname(self: torch._C.Node) -> str\n",
      "     |  \n",
      "     |  pyobj(...)\n",
      "     |      pyobj(self: torch._C.Node) -> object\n",
      "     |  \n",
      "     |  removeAllInputs(...)\n",
      "     |      removeAllInputs(self: torch._C.Node) -> None\n",
      "     |  \n",
      "     |  removeAttribute(...)\n",
      "     |      removeAttribute(self: torch._C.Node, arg0: str) -> torch._C.Node\n",
      "     |  \n",
      "     |  removeInput(...)\n",
      "     |      removeInput(self: torch._C.Node, arg0: int) -> None\n",
      "     |  \n",
      "     |  replaceAllUsesWith(...)\n",
      "     |      replaceAllUsesWith(self: torch._C.Node, arg0: torch._C.Node) -> None\n",
      "     |  \n",
      "     |  replaceInput(...)\n",
      "     |      replaceInput(self: torch._C.Node, arg0: int, arg1: torch._C.Value) -> torch._C.Value\n",
      "     |  \n",
      "     |  replaceInputWith(...)\n",
      "     |      replaceInputWith(self: torch._C.Node, arg0: torch._C.Value, arg1: torch._C.Value) -> None\n",
      "     |  \n",
      "     |  s(...)\n",
      "     |      s(self: torch._C.Node, arg0: str) -> str\n",
      "     |  \n",
      "     |  s_(...)\n",
      "     |      s_(self: torch._C.Node, arg0: str, arg1: str) -> torch._C.Node\n",
      "     |  \n",
      "     |  scalar_args(...)\n",
      "     |      scalar_args(self: torch._C.Node) -> list\n",
      "     |  \n",
      "     |  scopeName(...)\n",
      "     |      scopeName(self: torch._C.Node) -> str\n",
      "     |  \n",
      "     |  setStage(...)\n",
      "     |      setStage(self: torch._C.Node, arg0: int) -> torch._C.Node\n",
      "     |  \n",
      "     |  ss(...)\n",
      "     |      ss(self: torch._C.Node, arg0: str) -> List[str]\n",
      "     |  \n",
      "     |  ss_(...)\n",
      "     |      ss_(self: torch._C.Node, arg0: str, arg1: List[str]) -> torch._C.Node\n",
      "     |  \n",
      "     |  stage(...)\n",
      "     |      stage(self: torch._C.Node) -> int\n",
      "     |  \n",
      "     |  t(...)\n",
      "     |      t(self: torch._C.Node, arg0: str) -> torch::autograd::Variable\n",
      "     |  \n",
      "     |  t_(...)\n",
      "     |      t_(self: torch._C.Node, arg0: str, arg1: torch::autograd::Variable) -> torch._C.Node\n",
      "     |  \n",
      "     |  ts(...)\n",
      "     |      ts(self: torch._C.Node, arg0: str) -> List[torch::autograd::Variable]\n",
      "     |  \n",
      "     |  ts_(...)\n",
      "     |      ts_(self: torch._C.Node, arg0: str, arg1: List[torch::autograd::Variable]) -> torch._C.Node\n",
      "     |  \n",
      "     |  z(...)\n",
      "     |      z(self: torch._C.Node, arg0: str) -> at::Tensor\n",
      "     |  \n",
      "     |  z_(...)\n",
      "     |      z_(self: torch._C.Node, arg0: str, arg1: at::Tensor) -> torch._C.Node\n",
      "     |  \n",
      "     |  zs(...)\n",
      "     |      zs(self: torch._C.Node, arg0: str) -> List[at::Tensor]\n",
      "     |  \n",
      "     |  zs_(...)\n",
      "     |      zs_(self: torch._C.Node, arg0: str, arg1: List[at::Tensor]) -> torch._C.Node\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class ScriptMethod(pybind11_builtins.pybind11_object)\n",
      "     |  Method resolution order:\n",
      "     |      ScriptMethod\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __call__(...)\n",
      "     |      __call__(self: torch._C.ScriptMethod, *args) -> object\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  graph(...)\n",
      "     |      graph(self: torch._C.ScriptMethod) -> torch._C.Graph\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class ScriptModule(pybind11_builtins.pybind11_object)\n",
      "     |  Method resolution order:\n",
      "     |      ScriptModule\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(...)\n",
      "     |      __init__(self: torch._C.ScriptModule) -> None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class ShortStorage(torch._C.ShortStorageBase, torch.storage._StorageBase)\n",
      "     |  Method resolution order:\n",
      "     |      ShortStorage\n",
      "     |      torch._C.ShortStorageBase\n",
      "     |      torch.storage._StorageBase\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch._C.ShortStorageBase:\n",
      "     |  \n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |  \n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |  \n",
      "     |  __len__(self, /)\n",
      "     |      Return len(self).\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  __setitem__(self, key, value, /)\n",
      "     |      Set self[key] to value.\n",
      "     |  \n",
      "     |  copy_(...)\n",
      "     |  \n",
      "     |  data_ptr(...)\n",
      "     |  \n",
      "     |  element_size(...)\n",
      "     |  \n",
      "     |  fill_(...)\n",
      "     |  \n",
      "     |  is_pinned(...)\n",
      "     |  \n",
      "     |  is_shared(...)\n",
      "     |  \n",
      "     |  new(...)\n",
      "     |  \n",
      "     |  resize_(...)\n",
      "     |  \n",
      "     |  size(...)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from torch._C.ShortStorageBase:\n",
      "     |  \n",
      "     |  from_buffer(...)\n",
      "     |  \n",
      "     |  from_file(...)\n",
      "     |      from_file(filename, shared=False, size=0) -> Storage\n",
      "     |      \n",
      "     |      If `shared` is `True`, then memory is shared between all processes.\n",
      "     |      All changes are written to the file. If `shared` is `False`, then the changes on\n",
      "     |      the storage do not affect the file.\n",
      "     |      \n",
      "     |      `size` is the number of elements in the storage. If `shared` is `False`,\n",
      "     |      then the file must contain at least `size * sizeof(Type)` bytes\n",
      "     |      (`Type` is the type of storage). If `shared` is `True` the file will be\n",
      "     |      created if needed.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          filename (str): file name to map\n",
      "     |          shared (bool): whether to share memory\n",
      "     |          size (int): number of elements in the storage\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.storage._StorageBase:\n",
      "     |  \n",
      "     |  __copy__(self)\n",
      "     |  \n",
      "     |  __deepcopy__(self, memo)\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      helper for pickle\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __sizeof__(self)\n",
      "     |      __sizeof__() -> int\n",
      "     |      size of object in memory, in bytes\n",
      "     |  \n",
      "     |  __str__(self)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  byte(self)\n",
      "     |      Casts this storage to byte type\n",
      "     |  \n",
      "     |  char(self)\n",
      "     |      Casts this storage to char type\n",
      "     |  \n",
      "     |  clone(self)\n",
      "     |      Returns a copy of this storage\n",
      "     |  \n",
      "     |  cpu(self)\n",
      "     |      Returns a CPU copy of this storage if it's not already on the CPU\n",
      "     |  \n",
      "     |  cuda = _cuda(self, device=None, non_blocking=False, **kwargs)\n",
      "     |      Returns a copy of this object in CUDA memory.\n",
      "     |      \n",
      "     |      If this object is already in CUDA memory and on the correct device, then\n",
      "     |      no copy is performed and the original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          device (int): The destination GPU id. Defaults to the current device.\n",
      "     |          non_blocking (bool): If ``True`` and the source is in pinned memory,\n",
      "     |              the copy will be asynchronous with respect to the host. Otherwise,\n",
      "     |              the argument has no effect.\n",
      "     |          **kwargs: For compatibility, may contain the key ``async`` in place of\n",
      "     |              the ``non_blocking`` argument.\n",
      "     |  \n",
      "     |  double(self)\n",
      "     |      Casts this storage to double type\n",
      "     |  \n",
      "     |  float(self)\n",
      "     |      Casts this storage to float type\n",
      "     |  \n",
      "     |  half(self)\n",
      "     |      Casts this storage to half type\n",
      "     |  \n",
      "     |  int(self)\n",
      "     |      Casts this storage to int type\n",
      "     |  \n",
      "     |  long(self)\n",
      "     |      Casts this storage to long type\n",
      "     |  \n",
      "     |  pin_memory(self)\n",
      "     |      Copies the storage to pinned memory, if it's not already pinned.\n",
      "     |  \n",
      "     |  share_memory_(self)\n",
      "     |      Moves the storage to shared memory.\n",
      "     |      \n",
      "     |      This is a no-op for storages already in shared memory and for CUDA\n",
      "     |      storages, which do not need to be moved for sharing across processes.\n",
      "     |      Storages in shared memory cannot be resized.\n",
      "     |      \n",
      "     |      Returns: self\n",
      "     |  \n",
      "     |  short(self)\n",
      "     |      Casts this storage to short type\n",
      "     |  \n",
      "     |  tolist(self)\n",
      "     |      Returns a list containing the elements of this storage\n",
      "     |  \n",
      "     |  type = _type(self, dtype=None, non_blocking=False, **kwargs)\n",
      "     |      Returns the type if `dtype` is not provided, else casts this object to\n",
      "     |      the specified type.\n",
      "     |      \n",
      "     |      If this is already of the correct type, no copy is performed and the\n",
      "     |      original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (type or string): The desired type\n",
      "     |          non_blocking (bool): If ``True``, and the source is in pinned memory\n",
      "     |              and destination is on the GPU or vice versa, the copy is performed\n",
      "     |              asynchronously with respect to the host. Otherwise, the argument\n",
      "     |              has no effect.\n",
      "     |          **kwargs: For compatibility, may contain the key ``async`` in place of\n",
      "     |              the ``non_blocking`` argument. The ``async`` arg is deprecated.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.storage._StorageBase:\n",
      "     |  \n",
      "     |  is_cuda = False\n",
      "     |  \n",
      "     |  is_sparse = False\n",
      "    \n",
      "    class ShortTensor(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __abs__ = abs(...)\n",
      "     |  \n",
      "     |  __add__(...)\n",
      "     |  \n",
      "     |  __and__(...)\n",
      "     |  \n",
      "     |  __array__(self, dtype=None)\n",
      "     |      # Numpy array interface, to support `numpy.asarray(tensor) -> ndarray`\n",
      "     |  \n",
      "     |  __array_wrap__(self, array)\n",
      "     |      # Wrap Numpy array again in a suitable tensor when done, to support e.g.\n",
      "     |      # `numpy.sin(tensor) -> tensor` or `numpy.greater(tensor, 0) -> ByteTensor`\n",
      "     |  \n",
      "     |  __bool__(...)\n",
      "     |  \n",
      "     |  __deepcopy__(self, memo)\n",
      "     |  \n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |  \n",
      "     |  __dir__(self)\n",
      "     |      __dir__() -> list\n",
      "     |      default dir() implementation\n",
      "     |  \n",
      "     |  __div__(...)\n",
      "     |  \n",
      "     |  __eq__ = eq(...)\n",
      "     |  \n",
      "     |  __float__(...)\n",
      "     |  \n",
      "     |  __format__(self, format_spec)\n",
      "     |      default object formatter\n",
      "     |  \n",
      "     |  __ge__ = ge(...)\n",
      "     |  \n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |  \n",
      "     |  __gt__ = gt(...)\n",
      "     |  \n",
      "     |  __hash__(self)\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __iadd__(...)\n",
      "     |  \n",
      "     |  __iand__(...)\n",
      "     |  \n",
      "     |  __idiv__(...)\n",
      "     |  \n",
      "     |  __ilshift__(...)\n",
      "     |  \n",
      "     |  __imul__(...)\n",
      "     |  \n",
      "     |  __index__(...)\n",
      "     |  \n",
      "     |  __int__(...)\n",
      "     |  \n",
      "     |  __invert__(...)\n",
      "     |  \n",
      "     |  __ior__(...)\n",
      "     |  \n",
      "     |  __ipow__(self, other)\n",
      "     |  \n",
      "     |  __irshift__(...)\n",
      "     |  \n",
      "     |  __isub__(...)\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |  \n",
      "     |  __itruediv__ = __idiv__(...)\n",
      "     |  \n",
      "     |  __ixor__(...)\n",
      "     |  \n",
      "     |  __le__ = le(...)\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |      Return len(self).\n",
      "     |  \n",
      "     |  __long__(...)\n",
      "     |  \n",
      "     |  __lshift__(...)\n",
      "     |  \n",
      "     |  __lt__ = lt(...)\n",
      "     |  \n",
      "     |  __matmul__(...)\n",
      "     |  \n",
      "     |  __mod__(...)\n",
      "     |  \n",
      "     |  __mul__(...)\n",
      "     |  \n",
      "     |  __ne__ = ne(...)\n",
      "     |  \n",
      "     |  __neg__ = neg(...)\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from tensortype\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  __nonzero__(...)\n",
      "     |  \n",
      "     |  __or__(...)\n",
      "     |  \n",
      "     |  __pow__ = pow(...)\n",
      "     |  \n",
      "     |  __radd__(...)\n",
      "     |  \n",
      "     |  __rdiv__(self, other)\n",
      "     |  \n",
      "     |  __reduce_ex__(self, proto)\n",
      "     |      helper for pickle\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __rmul__(...)\n",
      "     |  \n",
      "     |  __rpow__(self, other)\n",
      "     |  \n",
      "     |  __rshift__(...)\n",
      "     |  \n",
      "     |  __rsub__(self, other)\n",
      "     |  \n",
      "     |  __rtruediv__ = __rdiv__(self, other)\n",
      "     |  \n",
      "     |  __setitem__(self, key, value, /)\n",
      "     |      Set self[key] to value.\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |  \n",
      "     |  __sub__(...)\n",
      "     |  \n",
      "     |  __truediv__(...)\n",
      "     |  \n",
      "     |  __xor__(...)\n",
      "     |  \n",
      "     |  abs(...)\n",
      "     |      abs() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.abs`\n",
      "     |  \n",
      "     |  abs_(...)\n",
      "     |      abs_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.abs`\n",
      "     |  \n",
      "     |  acos(...)\n",
      "     |      acos() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.acos`\n",
      "     |  \n",
      "     |  acos_(...)\n",
      "     |      acos_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.acos`\n",
      "     |  \n",
      "     |  add(...)\n",
      "     |      add(value) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.add`\n",
      "     |  \n",
      "     |  add_(...)\n",
      "     |      add_(value) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.add`\n",
      "     |  \n",
      "     |  addbmm(...)\n",
      "     |      addbmm(beta=1, mat, alpha=1, batch1, batch2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addbmm`\n",
      "     |  \n",
      "     |  addbmm_(...)\n",
      "     |      addbmm_(beta=1, mat, alpha=1, batch1, batch2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addbmm`\n",
      "     |  \n",
      "     |  addcdiv(...)\n",
      "     |      addcdiv(value=1, tensor1, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addcdiv`\n",
      "     |  \n",
      "     |  addcdiv_(...)\n",
      "     |      addcdiv_(value=1, tensor1, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addcdiv`\n",
      "     |  \n",
      "     |  addcmul(...)\n",
      "     |      addcmul(value=1, tensor1, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addcmul`\n",
      "     |  \n",
      "     |  addcmul_(...)\n",
      "     |      addcmul_(value=1, tensor1, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addcmul`\n",
      "     |  \n",
      "     |  addmm(...)\n",
      "     |      addmm(beta=1, mat, alpha=1, mat1, mat2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addmm`\n",
      "     |  \n",
      "     |  addmm_(...)\n",
      "     |      addmm_(beta=1, mat, alpha=1, mat1, mat2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addmm`\n",
      "     |  \n",
      "     |  addmv(...)\n",
      "     |      addmv(beta=1, tensor, alpha=1, mat, vec) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addmv`\n",
      "     |  \n",
      "     |  addmv_(...)\n",
      "     |      addmv_(beta=1, tensor, alpha=1, mat, vec) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addmv`\n",
      "     |  \n",
      "     |  addr(...)\n",
      "     |      addr(beta=1, alpha=1, vec1, vec2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addr`\n",
      "     |  \n",
      "     |  addr_(...)\n",
      "     |      addr_(beta=1, alpha=1, vec1, vec2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addr`\n",
      "     |  \n",
      "     |  all(...)\n",
      "     |      all() -> bool\n",
      "     |      \n",
      "     |      Returns ``True`` if all elements in the tensor are non-zero, ``False`` otherwise.\n",
      "     |  \n",
      "     |  allclose(...)\n",
      "     |  \n",
      "     |  any(...)\n",
      "     |      any() -> bool\n",
      "     |      \n",
      "     |      Returns ``True`` if any elements in the tensor are non-zero, ``False`` otherwise.\n",
      "     |  \n",
      "     |  apply_(...)\n",
      "     |      apply_(callable) -> Tensor\n",
      "     |      \n",
      "     |      Applies the function :attr:`callable` to each element in the tensor, replacing\n",
      "     |      each element with the value returned by :attr:`callable`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          This function only works with CPU tensors and should not be used in code\n",
      "     |          sections that require high performance.\n",
      "     |  \n",
      "     |  argmax(self, dim=None, keepdim=False)\n",
      "     |      See :func:`torch.argmax`\n",
      "     |  \n",
      "     |  argmin(self, dim=None, keepdim=False)\n",
      "     |      See :func:`torch.argmin`\n",
      "     |  \n",
      "     |  as_strided(...)\n",
      "     |  \n",
      "     |  as_strided_(...)\n",
      "     |  \n",
      "     |  asin(...)\n",
      "     |      asin() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.asin`\n",
      "     |  \n",
      "     |  asin_(...)\n",
      "     |      asin_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.asin`\n",
      "     |  \n",
      "     |  atan(...)\n",
      "     |      atan() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.atan`\n",
      "     |  \n",
      "     |  atan2(...)\n",
      "     |      atan2(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.atan2`\n",
      "     |  \n",
      "     |  atan2_(...)\n",
      "     |      atan2_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.atan2`\n",
      "     |  \n",
      "     |  atan_(...)\n",
      "     |      atan_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.atan`\n",
      "     |  \n",
      "     |  backward(self, gradient=None, retain_graph=None, create_graph=False)\n",
      "     |      Computes the gradient of current tensor w.r.t. graph leaves.\n",
      "     |      \n",
      "     |      The graph is differentiated using the chain rule. If the tensor is\n",
      "     |      non-scalar (i.e. its data has more than one element) and requires\n",
      "     |      gradient, the function additionally requires specifying ``gradient``.\n",
      "     |      It should be a tensor of matching type and location, that contains\n",
      "     |      the gradient of the differentiated function w.r.t. ``self``.\n",
      "     |      \n",
      "     |      This function accumulates gradients in the leaves - you might need to\n",
      "     |      zero them before calling it.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          gradient (Tensor or None): Gradient w.r.t. the\n",
      "     |              tensor. If it is a tensor, it will be automatically converted\n",
      "     |              to a Tensor that does not require grad unless ``create_graph`` is True.\n",
      "     |              None values can be specified for scalar Tensors or ones that\n",
      "     |              don't require grad. If a None value would be acceptable then\n",
      "     |              this argument is optional.\n",
      "     |          retain_graph (bool, optional): If ``False``, the graph used to compute\n",
      "     |              the grads will be freed. Note that in nearly all cases setting\n",
      "     |              this option to True is not needed and often can be worked around\n",
      "     |              in a much more efficient way. Defaults to the value of\n",
      "     |              ``create_graph``.\n",
      "     |          create_graph (bool, optional): If ``True``, graph of the derivative will\n",
      "     |              be constructed, allowing to compute higher order derivative\n",
      "     |              products. Defaults to ``False``.\n",
      "     |  \n",
      "     |  baddbmm(...)\n",
      "     |      baddbmm(beta=1, alpha=1, batch1, batch2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.baddbmm`\n",
      "     |  \n",
      "     |  baddbmm_(...)\n",
      "     |      baddbmm_(beta=1, alpha=1, batch1, batch2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.baddbmm`\n",
      "     |  \n",
      "     |  bernoulli(...)\n",
      "     |      bernoulli() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bernoulli`\n",
      "     |  \n",
      "     |  bernoulli_(...)\n",
      "     |      bernoulli_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.bernoulli`\n",
      "     |  \n",
      "     |  bmm(...)\n",
      "     |      bmm(batch2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bmm`\n",
      "     |  \n",
      "     |  btrifact(self, info=None, pivot=True)\n",
      "     |      See :func:`torch.btrifact`\n",
      "     |  \n",
      "     |  btrifact_with_info(...)\n",
      "     |      btrifact_with_info(pivot=True) -> (Tensor, Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.btrifact_with_info`\n",
      "     |  \n",
      "     |  btrisolve(...)\n",
      "     |  \n",
      "     |  byte(...)\n",
      "     |      byte() -> Tensor\n",
      "     |      \n",
      "     |      ``self.byte()`` is equivalent to ``self.to(torch.uint8)``. See :func:`to`.\n",
      "     |  \n",
      "     |  cauchy_(...)\n",
      "     |      cauchy_(median=0, sigma=1, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills the tensor with numbers drawn from the Cauchy distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(x) = \\dfrac{1}{\\pi} \\dfrac{\\sigma}{(x - median)^2 + \\sigma^2}\n",
      "     |  \n",
      "     |  ceil(...)\n",
      "     |      ceil() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ceil`\n",
      "     |  \n",
      "     |  ceil_(...)\n",
      "     |      ceil_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ceil`\n",
      "     |  \n",
      "     |  char(...)\n",
      "     |      char() -> Tensor\n",
      "     |      \n",
      "     |      ``self.char()`` is equivalent to ``self.to(torch.int8)``. See :func:`to`.\n",
      "     |  \n",
      "     |  chunk(...)\n",
      "     |      chunk(chunks, dim=0) -> List of Tensors\n",
      "     |      \n",
      "     |      See :func:`torch.chunk`\n",
      "     |  \n",
      "     |  clamp(...)\n",
      "     |      clamp(min, max) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.clamp`\n",
      "     |  \n",
      "     |  clamp_(...)\n",
      "     |      clamp_(min, max) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.clamp`\n",
      "     |  \n",
      "     |  clone(...)\n",
      "     |      clone() -> Tensor\n",
      "     |      \n",
      "     |      Returns a copy of the :attr:`self` tensor. The copy has the same size and data\n",
      "     |      type as :attr:`self`.\n",
      "     |  \n",
      "     |  coalesce(...)\n",
      "     |  \n",
      "     |  contiguous(...)\n",
      "     |      contiguous() -> Tensor\n",
      "     |      \n",
      "     |      Returns a contiguous tensor containing the same data as :attr:`self` tensor. If\n",
      "     |      :attr:`self` tensor is contiguous, this function returns the :attr:`self`\n",
      "     |      tensor.\n",
      "     |  \n",
      "     |  conv_tbc(...)\n",
      "     |  \n",
      "     |  copy_(...)\n",
      "     |      copy_(src, non_blocking=False) -> Tensor\n",
      "     |      \n",
      "     |      Copies the elements from :attr:`src` into :attr:`self` tensor and returns\n",
      "     |      :attr:`self`.\n",
      "     |      \n",
      "     |      The :attr:`src` tensor must be :ref:`broadcastable <broadcasting-semantics>`\n",
      "     |      with the :attr:`self` tensor. It may be of a different data type or reside on a\n",
      "     |      different device.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          src (Tensor): the source tensor to copy from\n",
      "     |          non_blocking (bool): if ``True`` and this copy is between CPU and GPU,\n",
      "     |              the copy may occur asynchronously with respect to the host. For other\n",
      "     |              cases, this argument has no effect.\n",
      "     |  \n",
      "     |  cos(...)\n",
      "     |      cos() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cos`\n",
      "     |  \n",
      "     |  cos_(...)\n",
      "     |      cos_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.cos`\n",
      "     |  \n",
      "     |  cosh(...)\n",
      "     |      cosh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cosh`\n",
      "     |  \n",
      "     |  cosh_(...)\n",
      "     |      cosh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.cosh`\n",
      "     |  \n",
      "     |  cpu(...)\n",
      "     |  \n",
      "     |  cross(...)\n",
      "     |      cross(other, dim=-1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cross`\n",
      "     |  \n",
      "     |  cuda(...)\n",
      "     |      cuda(device=None, non_blocking=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a copy of this object in CUDA memory.\n",
      "     |      \n",
      "     |      If this object is already in CUDA memory and on the correct device,\n",
      "     |      then no copy is performed and the original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          device (:class:`torch.device`): The destination GPU device.\n",
      "     |              Defaults to the current CUDA device.\n",
      "     |          non_blocking (bool): If ``True`` and the source is in pinned memory,\n",
      "     |              the copy will be asynchronous with respect to the host.\n",
      "     |              Otherwise, the argument has no effect. Default: ``False``.\n",
      "     |  \n",
      "     |  cumprod(...)\n",
      "     |      cumprod(dim) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cumprod`\n",
      "     |  \n",
      "     |  cumsum(...)\n",
      "     |      cumsum(dim) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cumsum`\n",
      "     |  \n",
      "     |  data_ptr(...)\n",
      "     |      data_ptr() -> int\n",
      "     |      \n",
      "     |      Returns the address of the first element of :attr:`self` tensor.\n",
      "     |  \n",
      "     |  det(...)\n",
      "     |      det() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.det`\n",
      "     |  \n",
      "     |  detach(...)\n",
      "     |      Returns a new Tensor, detached from the current graph.\n",
      "     |      \n",
      "     |      The result will never require gradient.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |        Returned Tensor uses the same data tensor as the original one.\n",
      "     |        In-place modifications on either of them will be seen, and may trigger\n",
      "     |        errors in correctness checks.\n",
      "     |  \n",
      "     |  detach_(...)\n",
      "     |      Detaches the Tensor from the graph that created it, making it a leaf.\n",
      "     |      Views cannot be detached in-place.\n",
      "     |  \n",
      "     |  diag(...)\n",
      "     |      diag(diagonal=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diag`\n",
      "     |  \n",
      "     |  digamma(...)\n",
      "     |  \n",
      "     |  digamma_(...)\n",
      "     |  \n",
      "     |  dim(...)\n",
      "     |      dim() -> int\n",
      "     |      \n",
      "     |      Returns the number of dimensions of :attr:`self` tensor.\n",
      "     |  \n",
      "     |  dist(...)\n",
      "     |      dist(other, p=2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.dist`\n",
      "     |  \n",
      "     |  div(...)\n",
      "     |      div(value) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.div`\n",
      "     |  \n",
      "     |  div_(...)\n",
      "     |      div_(value) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.div`\n",
      "     |  \n",
      "     |  dot(...)\n",
      "     |      dot(tensor2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.dot`\n",
      "     |  \n",
      "     |  double(...)\n",
      "     |      double() -> Tensor\n",
      "     |      \n",
      "     |      ``self.double()`` is equivalent to ``self.to(torch.float64)``. See :func:`to`.\n",
      "     |  \n",
      "     |  eig(...)\n",
      "     |      eig(eigenvectors=False) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.eig`\n",
      "     |  \n",
      "     |  element_size(...)\n",
      "     |      element_size() -> int\n",
      "     |      \n",
      "     |      Returns the size in bytes of an individual element.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> torch.tensor([]).element_size()\n",
      "     |          4\n",
      "     |          >>> torch.tensor([], dtype=torch.uint8).element_size()\n",
      "     |          1\n",
      "     |  \n",
      "     |  eq(...)\n",
      "     |      eq(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.eq`\n",
      "     |  \n",
      "     |  eq_(...)\n",
      "     |      eq_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.eq`\n",
      "     |  \n",
      "     |  equal(...)\n",
      "     |      equal(other) -> bool\n",
      "     |      \n",
      "     |      See :func:`torch.equal`\n",
      "     |  \n",
      "     |  erf(...)\n",
      "     |      erf() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.erf`\n",
      "     |  \n",
      "     |  erf_(...)\n",
      "     |  \n",
      "     |  erfinv(...)\n",
      "     |      erfinv() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.erfinv`\n",
      "     |  \n",
      "     |  erfinv_(...)\n",
      "     |  \n",
      "     |  exp(...)\n",
      "     |      exp() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.exp`\n",
      "     |  \n",
      "     |  exp_(...)\n",
      "     |      exp_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.exp`\n",
      "     |  \n",
      "     |  expand(...)\n",
      "     |      expand(*sizes) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new view of the :attr:`self` tensor with singleton dimensions expanded\n",
      "     |      to a larger size.\n",
      "     |      \n",
      "     |      Passing -1 as the size for a dimension means not changing the size of\n",
      "     |      that dimension.\n",
      "     |      \n",
      "     |      Tensor can be also expanded to a larger number of dimensions, and the\n",
      "     |      new ones will be appended at the front. For the new dimensions, the\n",
      "     |      size cannot be set to -1.\n",
      "     |      \n",
      "     |      Expanding a tensor does not allocate new memory, but only creates a\n",
      "     |      new view on the existing tensor where a dimension of size one is\n",
      "     |      expanded to a larger size by setting the ``stride`` to 0. Any dimension\n",
      "     |      of size 1 can be expanded to an arbitrary value without allocating new\n",
      "     |      memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *sizes (torch.Size or int...): the desired expanded size\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1], [2], [3]])\n",
      "     |          >>> x.size()\n",
      "     |          torch.Size([3, 1])\n",
      "     |          >>> x.expand(3, 4)\n",
      "     |          tensor([[ 1,  1,  1,  1],\n",
      "     |                  [ 2,  2,  2,  2],\n",
      "     |                  [ 3,  3,  3,  3]])\n",
      "     |          >>> x.expand(-1, 4)   # -1 means not changing the size of that dimension\n",
      "     |          tensor([[ 1,  1,  1,  1],\n",
      "     |                  [ 2,  2,  2,  2],\n",
      "     |                  [ 3,  3,  3,  3]])\n",
      "     |  \n",
      "     |  expand_as(self, tensor)\n",
      "     |  \n",
      "     |  expm1(...)\n",
      "     |      expm1() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.expm1`\n",
      "     |  \n",
      "     |  expm1_(...)\n",
      "     |      expm1_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.expm1`\n",
      "     |  \n",
      "     |  exponential_(...)\n",
      "     |      exponential_(lambd=1, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with elements drawn from the exponential distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(x) = \\lambda e^{-\\lambda x}\n",
      "     |  \n",
      "     |  fft(...)\n",
      "     |      fft(signal_ndim, normalized=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fft`\n",
      "     |  \n",
      "     |  fill_(...)\n",
      "     |      fill_(value) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with the specified value.\n",
      "     |  \n",
      "     |  float(...)\n",
      "     |      float() -> Tensor\n",
      "     |      \n",
      "     |      ``self.float()`` is equivalent to ``self.to(torch.float32)``. See :func:`to`.\n",
      "     |  \n",
      "     |  floor(...)\n",
      "     |      floor() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.floor`\n",
      "     |  \n",
      "     |  floor_(...)\n",
      "     |      floor_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.floor`\n",
      "     |  \n",
      "     |  fmod(...)\n",
      "     |      fmod(divisor) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fmod`\n",
      "     |  \n",
      "     |  fmod_(...)\n",
      "     |      fmod_(divisor) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.fmod`\n",
      "     |  \n",
      "     |  frac(...)\n",
      "     |      frac() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.frac`\n",
      "     |  \n",
      "     |  frac_(...)\n",
      "     |      frac_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.frac`\n",
      "     |  \n",
      "     |  gather(...)\n",
      "     |      gather(dim, index) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.gather`\n",
      "     |  \n",
      "     |  ge(...)\n",
      "     |      ge(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ge`\n",
      "     |  \n",
      "     |  ge_(...)\n",
      "     |      ge_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ge`\n",
      "     |  \n",
      "     |  gels(...)\n",
      "     |      gels(A) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.gels`\n",
      "     |  \n",
      "     |  geometric_(...)\n",
      "     |      geometric_(p, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with elements drawn from the geometric distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(X=k) = (1 - p)^{k - 1} p\n",
      "     |  \n",
      "     |  geqrf(...)\n",
      "     |      geqrf() -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.geqrf`\n",
      "     |  \n",
      "     |  ger(...)\n",
      "     |      ger(vec2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ger`\n",
      "     |  \n",
      "     |  gesv(...)\n",
      "     |      gesv(A) -> Tensor, Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.gesv`\n",
      "     |  \n",
      "     |  get_device(...)\n",
      "     |  \n",
      "     |  gt(...)\n",
      "     |      gt(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.gt`\n",
      "     |  \n",
      "     |  gt_(...)\n",
      "     |      gt_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.gt`\n",
      "     |  \n",
      "     |  half(...)\n",
      "     |      half() -> Tensor\n",
      "     |      \n",
      "     |      ``self.half()`` is equivalent to ``self.to(torch.float16)``. See :func:`to`.\n",
      "     |  \n",
      "     |  histc(...)\n",
      "     |      histc(bins=100, min=0, max=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.histc`\n",
      "     |  \n",
      "     |  ifft(...)\n",
      "     |      ifft(signal_ndim, normalized=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ifft`\n",
      "     |  \n",
      "     |  index(...)\n",
      "     |      index(m) -> Tensor\n",
      "     |      \n",
      "     |      Selects elements from :attr:`self` tensor using a binary mask or along a given\n",
      "     |      dimension. The expression ``tensor.index(m)`` is equivalent to ``tensor[m]``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          m (int or ByteTensor or slice): the dimension or mask used to select elements\n",
      "     |  \n",
      "     |  index_add(self, dim, index, tensor)\n",
      "     |  \n",
      "     |  index_add_(...)\n",
      "     |      index_add_(dim, index, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Accumulate the elements of :attr:`tensor` into the :attr:`self` tensor by adding\n",
      "     |      to the indices in the order given in :attr:`index`. For example, if ``dim == 0``\n",
      "     |      and ``index[i] == j``, then the ``i``\\ th row of :attr:`tensor` is added to the\n",
      "     |      ``j``\\ th row of :attr:`self`.\n",
      "     |      \n",
      "     |      The :attr:`dim`\\ th dimension of :attr:`tensor` must have the same size as the\n",
      "     |      length of :attr:`index` (which must be a vector), and all other dimensions must\n",
      "     |      match :attr:`self`, or an error will be raised.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension along which to index\n",
      "     |          index (LongTensor): indices of :attr:`tensor` to select from\n",
      "     |          tensor (Tensor): the tensor containing values to add\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.ones(5, 3)\n",
      "     |          >>> t = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
      "     |          >>> index = torch.tensor([0, 4, 2])\n",
      "     |          >>> x.index_add_(0, index, t)\n",
      "     |          tensor([[  2.,   3.,   4.],\n",
      "     |                  [  1.,   1.,   1.],\n",
      "     |                  [  8.,   9.,  10.],\n",
      "     |                  [  1.,   1.,   1.],\n",
      "     |                  [  5.,   6.,   7.]])\n",
      "     |  \n",
      "     |  index_copy(self, dim, index, tensor)\n",
      "     |  \n",
      "     |  index_copy_(...)\n",
      "     |      index_copy_(dim, index, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Copies the elements of :attr:`tensor` into the :attr:`self` tensor by selecting\n",
      "     |      the indices in the order given in :attr:`index`. For example, if ``dim == 0``\n",
      "     |      and ``index[i] == j``, then the ``i``\\ th row of :attr:`tensor` is copied to the\n",
      "     |      ``j``\\ th row of :attr:`self`.\n",
      "     |      \n",
      "     |      The :attr:`dim`\\ th dimension of :attr:`tensor` must have the same size as the\n",
      "     |      length of :attr:`index` (which must be a vector), and all other dimensions must\n",
      "     |      match :attr:`self`, or an error will be raised.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension along which to index\n",
      "     |          index (LongTensor): indices of :attr:`tensor` to select from\n",
      "     |          tensor (Tensor): the tensor containing values to copy\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.zeros(5, 3)\n",
      "     |          >>> t = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
      "     |          >>> index = torch.tensor([0, 4, 2])\n",
      "     |          >>> x.index_copy_(0, index, t)\n",
      "     |          tensor([[ 1.,  2.,  3.],\n",
      "     |                  [ 0.,  0.,  0.],\n",
      "     |                  [ 7.,  8.,  9.],\n",
      "     |                  [ 0.,  0.,  0.],\n",
      "     |                  [ 4.,  5.,  6.]])\n",
      "     |  \n",
      "     |  index_fill(self, dim, index, value)\n",
      "     |  \n",
      "     |  index_fill_(...)\n",
      "     |      index_fill_(dim, index, val) -> Tensor\n",
      "     |      \n",
      "     |      Fills the elements of the :attr:`self` tensor with value :attr:`val` by\n",
      "     |      selecting the indices in the order given in :attr:`index`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension along which to index\n",
      "     |          index (LongTensor): indices of :attr:`self` tensor to fill in\n",
      "     |          val (float): the value to fill with\n",
      "     |      \n",
      "     |      Example::\n",
      "     |          >>> x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
      "     |          >>> index = torch.tensor([0, 2])\n",
      "     |          >>> x.index_fill_(1, index, -1)\n",
      "     |          tensor([[-1.,  2., -1.],\n",
      "     |                  [-1.,  5., -1.],\n",
      "     |                  [-1.,  8., -1.]])\n",
      "     |  \n",
      "     |  index_put_(...)\n",
      "     |      index_put_(indices, value) -> Tensor\n",
      "     |      \n",
      "     |      Puts values from the tensor :attr:`value` into the tensor :attr:`self` using\n",
      "     |      the indices specified in :attr:`indices` (which is a tuple of Tensors). The\n",
      "     |      expression ``tensor.index_put_(indices, value)`` is equivalent to\n",
      "     |      ``tensor[indices] = value``. Returns :attr:`self`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          indices (tuple of LongTensor): tensors used to index into `self`.\n",
      "     |          value (Tensor): tensor of same dtype as `self`.\n",
      "     |  \n",
      "     |  index_select(...)\n",
      "     |      index_select(dim, index) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.index_select`\n",
      "     |  \n",
      "     |  int(...)\n",
      "     |      int() -> Tensor\n",
      "     |      \n",
      "     |      ``self.int()`` is equivalent to ``self.to(torch.int32)``. See :func:`to`.\n",
      "     |  \n",
      "     |  inverse(...)\n",
      "     |      inverse() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.inverse`\n",
      "     |  \n",
      "     |  irfft(...)\n",
      "     |      irfft(signal_ndim, normalized=False, onesided=True, signal_sizes=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.irfft`\n",
      "     |  \n",
      "     |  is_coalesced(...)\n",
      "     |  \n",
      "     |  is_contiguous(...)\n",
      "     |      is_contiguous() -> bool\n",
      "     |      \n",
      "     |      Returns True if :attr:`self` tensor is contiguous in memory in C order.\n",
      "     |  \n",
      "     |  is_distributed(...)\n",
      "     |  \n",
      "     |  is_floating_point(...)\n",
      "     |  \n",
      "     |  is_nonzero(...)\n",
      "     |  \n",
      "     |  is_pinned(self)\n",
      "     |      Returns true if this tensor resides in pinned memory\n",
      "     |  \n",
      "     |  is_same_size(...)\n",
      "     |  \n",
      "     |  is_set_to(...)\n",
      "     |      is_set_to(tensor) -> bool\n",
      "     |      \n",
      "     |      Returns True if this object refers to the same ``THTensor`` object from the\n",
      "     |      Torch C API as the given tensor.\n",
      "     |  \n",
      "     |  is_shared(self)\n",
      "     |      Checks if tensor is in shared memory.\n",
      "     |      \n",
      "     |      This is always ``True`` for CUDA tensors.\n",
      "     |  \n",
      "     |  is_signed(...)\n",
      "     |  \n",
      "     |  isclose(...)\n",
      "     |  \n",
      "     |  item(...)\n",
      "     |      item() -> number\n",
      "     |      \n",
      "     |      Returns the value of this tensor as a standard Python number. This only works\n",
      "     |      for tensors with one element.\n",
      "     |      \n",
      "     |      This operation is not differentiable.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([1.0])\n",
      "     |          >>> x.item()\n",
      "     |          1.0\n",
      "     |  \n",
      "     |  kthvalue(...)\n",
      "     |      kthvalue(k, dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.kthvalue`\n",
      "     |  \n",
      "     |  le(...)\n",
      "     |      le(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.le`\n",
      "     |  \n",
      "     |  le_(...)\n",
      "     |      le_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.le`\n",
      "     |  \n",
      "     |  lerp(...)\n",
      "     |      lerp(start, end, weight) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lerp`\n",
      "     |  \n",
      "     |  lerp_(...)\n",
      "     |      lerp_(start, end, weight) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lerp`\n",
      "     |  \n",
      "     |  lgamma(...)\n",
      "     |  \n",
      "     |  lgamma_(...)\n",
      "     |  \n",
      "     |  log(...)\n",
      "     |      log() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log`\n",
      "     |  \n",
      "     |  log10(...)\n",
      "     |      log10() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log10`\n",
      "     |  \n",
      "     |  log10_(...)\n",
      "     |      log10_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log10`\n",
      "     |  \n",
      "     |  log1p(...)\n",
      "     |      log1p() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log1p`\n",
      "     |  \n",
      "     |  log1p_(...)\n",
      "     |      log1p_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log1p`\n",
      "     |  \n",
      "     |  log2(...)\n",
      "     |      log2() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log2`\n",
      "     |  \n",
      "     |  log2_(...)\n",
      "     |      log2_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log2`\n",
      "     |  \n",
      "     |  log_(...)\n",
      "     |      log_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log`\n",
      "     |  \n",
      "     |  log_normal_(...)\n",
      "     |      log_normal_(mean=1, std=2, *, generator=None)\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with numbers samples from the log-normal distribution\n",
      "     |      parameterized by the given mean (µ) and standard deviation (σ).\n",
      "     |      Note that :attr:`mean` and :attr:`stdv` are the mean and standard deviation of\n",
      "     |      the underlying normal distribution, and not of the returned distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(x) = \\dfrac{1}{x \\sigma \\sqrt{2\\pi}}\\ e^{-\\dfrac{(\\ln x - \\mu)^2}{2\\sigma^2}}\n",
      "     |  \n",
      "     |  logdet(...)\n",
      "     |      logdet() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logdet`\n",
      "     |  \n",
      "     |  long(...)\n",
      "     |      long() -> Tensor\n",
      "     |      \n",
      "     |      ``self.long()`` is equivalent to ``self.to(torch.int64)``. See :func:`to`.\n",
      "     |  \n",
      "     |  lt(...)\n",
      "     |      lt(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lt`\n",
      "     |  \n",
      "     |  lt_(...)\n",
      "     |      lt_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lt`\n",
      "     |  \n",
      "     |  map2_(...)\n",
      "     |  \n",
      "     |  map_(...)\n",
      "     |      map_(tensor, callable)\n",
      "     |      \n",
      "     |      Applies :attr:`callable` for each element in :attr:`self` tensor and the given\n",
      "     |      :attr:`tensor` and stores the results in :attr:`self` tensor. :attr:`self` tensor and\n",
      "     |      the given :attr:`tensor` must be :ref:`broadcastable <broadcasting-semantics>`.\n",
      "     |      \n",
      "     |      The :attr:`callable` should have the signature::\n",
      "     |      \n",
      "     |          def callable(a, b) -> number\n",
      "     |  \n",
      "     |  masked_copy(self, mask, tensor)\n",
      "     |  \n",
      "     |  masked_copy_(self, mask, tensor)\n",
      "     |  \n",
      "     |  masked_fill(self, mask, value)\n",
      "     |  \n",
      "     |  masked_fill_(...)\n",
      "     |      masked_fill_(mask, value)\n",
      "     |      \n",
      "     |      Fills elements of :attr:`self` tensor with :attr:`value` where :attr:`mask` is\n",
      "     |      one. The shape of :attr:`mask` must be\n",
      "     |      :ref:`broadcastable <broadcasting-semantics>` with the shape of the underlying\n",
      "     |      tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          mask (ByteTensor): the binary mask\n",
      "     |          value (float): the value to fill in with\n",
      "     |  \n",
      "     |  masked_scatter(self, mask, tensor)\n",
      "     |  \n",
      "     |  masked_scatter_(...)\n",
      "     |      masked_scatter_(mask, source)\n",
      "     |      \n",
      "     |      Copies elements from :attr:`source` into :attr:`self` tensor at positions where\n",
      "     |      the :attr:`mask` is one.\n",
      "     |      The shape of :attr:`mask` must be :ref:`broadcastable <broadcasting-semantics>`\n",
      "     |      with the shape of the underlying tensor. The :attr:`source` should have at least\n",
      "     |      as many elements as the number of ones in :attr:`mask`\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          mask (ByteTensor): the binary mask\n",
      "     |          source (Tensor): the tensor to copy from\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The :attr:`mask` operates on the :attr:`self` tensor, not on the given\n",
      "     |          :attr:`source` tensor.\n",
      "     |  \n",
      "     |  masked_select(...)\n",
      "     |      masked_select(mask) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.masked_select`\n",
      "     |  \n",
      "     |  matmul(...)\n",
      "     |      matmul(tensor2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.matmul`\n",
      "     |  \n",
      "     |  max(...)\n",
      "     |      max(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.max`\n",
      "     |  \n",
      "     |  mean(...)\n",
      "     |      mean(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.mean`\n",
      "     |  \n",
      "     |  median(...)\n",
      "     |      median(dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.median`\n",
      "     |  \n",
      "     |  min(...)\n",
      "     |      min(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.min`\n",
      "     |  \n",
      "     |  mm(...)\n",
      "     |      mm(mat2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mm`\n",
      "     |  \n",
      "     |  mode(...)\n",
      "     |      mode(dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.mode`\n",
      "     |  \n",
      "     |  mul(...)\n",
      "     |      mul(value) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mul`\n",
      "     |  \n",
      "     |  mul_(...)\n",
      "     |      mul_(value)\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.mul`\n",
      "     |  \n",
      "     |  multinomial(...)\n",
      "     |      multinomial(num_samples, replacement=False, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.multinomial`\n",
      "     |  \n",
      "     |  mv(...)\n",
      "     |      mv(vec) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mv`\n",
      "     |  \n",
      "     |  narrow(...)\n",
      "     |      narrow(dimension, start, length) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new tensor that is a narrowed version of :attr:`self` tensor. The\n",
      "     |      dimension :attr:`dim` is narrowed from :attr:`start` to :attr:`start + length`. The\n",
      "     |      returned tensor and :attr:`self` tensor share the same underlying storage.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dimension (int): the dimension along which to narrow\n",
      "     |          start (int): the starting dimension\n",
      "     |          length (int): the distance to the ending dimension\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
      "     |          >>> x.narrow(0, 0, 2)\n",
      "     |          tensor([[ 1,  2,  3],\n",
      "     |                  [ 4,  5,  6]])\n",
      "     |          >>> x.narrow(1, 1, 2)\n",
      "     |          tensor([[ 2,  3],\n",
      "     |                  [ 5,  6],\n",
      "     |                  [ 8,  9]])\n",
      "     |  \n",
      "     |  ndimension(...)\n",
      "     |      ndimension() -> int\n",
      "     |      \n",
      "     |      Alias for :meth:`~Tensor.dim()`\n",
      "     |  \n",
      "     |  ne(...)\n",
      "     |      ne(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ne`\n",
      "     |  \n",
      "     |  ne_(...)\n",
      "     |      ne_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ne`\n",
      "     |  \n",
      "     |  neg(...)\n",
      "     |      neg() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.neg`\n",
      "     |  \n",
      "     |  neg_(...)\n",
      "     |      neg_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.neg`\n",
      "     |  \n",
      "     |  nelement(...)\n",
      "     |      nelement() -> int\n",
      "     |      \n",
      "     |      Alias for :meth:`~Tensor.numel`\n",
      "     |  \n",
      "     |  new(...)\n",
      "     |  \n",
      "     |  new_empty(...)\n",
      "     |      new_empty(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with uninitialized data.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones(())\n",
      "     |          >>> tensor.new_empty((2, 3))\n",
      "     |          tensor([[ 5.8182e-18,  4.5765e-41, -1.0545e+30],\n",
      "     |                  [ 3.0949e-41,  4.4842e-44,  0.0000e+00]])\n",
      "     |  \n",
      "     |  new_full(...)\n",
      "     |      new_full(size, fill_value, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with :attr:`fill_value`.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          fill_value (scalar): the number to fill the output tensor with.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones((2,), dtype=torch.float64)\n",
      "     |          >>> tensor.new_full((3, 4), 3.141592)\n",
      "     |          tensor([[ 3.1416,  3.1416,  3.1416,  3.1416],\n",
      "     |                  [ 3.1416,  3.1416,  3.1416,  3.1416],\n",
      "     |                  [ 3.1416,  3.1416,  3.1416,  3.1416]], dtype=torch.float64)\n",
      "     |  \n",
      "     |  new_ones(...)\n",
      "     |      new_ones(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with ``1``.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (int...): a list, tuple, or :class:`torch.Size` of integers defining the\n",
      "     |              shape of the output tensor.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.tensor((), dtype=torch.int32)\n",
      "     |          >>> tensor.new_ones((2, 3))\n",
      "     |          tensor([[ 1,  1,  1],\n",
      "     |                  [ 1,  1,  1]], dtype=torch.int32)\n",
      "     |  \n",
      "     |  new_tensor(...)\n",
      "     |      new_tensor(data, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new Tensor with :attr:`data` as the tensor data.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          :func:`new_tensor` always copies :attr:`data`. If you have a Tensor\n",
      "     |          ``data`` and want to avoid a copy, use :func:`torch.Tensor.requires_grad_`\n",
      "     |          or :func:`torch.Tensor.detach`.\n",
      "     |          If you have a numpy array and want to avoid a copy, use\n",
      "     |          :func:`torch.from_numpy`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          data (array_like): The returned Tensor copies :attr:`data`.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones((2,), dtype=torch.int8)\n",
      "     |          >>> data = [[0, 1], [2, 3]]\n",
      "     |          >>> tensor.new_tensor(data)\n",
      "     |          tensor([[ 0,  1],\n",
      "     |                  [ 2,  3]], dtype=torch.int8)\n",
      "     |  \n",
      "     |  new_zeros(...)\n",
      "     |      new_zeros(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with ``0``.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (int...): a list, tuple, or :class:`torch.Size` of integers defining the\n",
      "     |              shape of the output tensor.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.tensor((), dtype=torch.float64)\n",
      "     |          >>> tensor.new_ones((2, 3))\n",
      "     |          tensor([[ 1.,  1.,  1.],\n",
      "     |                  [ 1.,  1.,  1.]], dtype=torch.float64)\n",
      "     |  \n",
      "     |  nonzero(...)\n",
      "     |      nonzero() -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.nonzero`\n",
      "     |  \n",
      "     |  norm(...)\n",
      "     |      norm(p=2, dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.norm`\n",
      "     |  \n",
      "     |  normal_(...)\n",
      "     |      normal_(mean=0, std=1, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with elements samples from the normal distribution\n",
      "     |      parameterized by :attr:`mean` and :attr:`std`.\n",
      "     |  \n",
      "     |  numel(...)\n",
      "     |      numel() -> int\n",
      "     |      \n",
      "     |      See :func:`torch.numel`\n",
      "     |  \n",
      "     |  numpy(...)\n",
      "     |      numpy() -> numpy.ndarray\n",
      "     |      \n",
      "     |      Returns :attr:`self` tensor as a NumPy :class:`ndarray`. This tensor and the\n",
      "     |      returned :class:`ndarray` share the same underlying storage. Changes to\n",
      "     |      :attr:`self` tensor will be reflected in the :class:`ndarray` and vice versa.\n",
      "     |  \n",
      "     |  orgqr(...)\n",
      "     |      orgqr(input2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.orgqr`\n",
      "     |  \n",
      "     |  ormqr(...)\n",
      "     |      ormqr(input2, input3, left=True, transpose=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ormqr`\n",
      "     |  \n",
      "     |  permute(...)\n",
      "     |  \n",
      "     |  pin_memory(...)\n",
      "     |  \n",
      "     |  polygamma(...)\n",
      "     |  \n",
      "     |  polygamma_(...)\n",
      "     |  \n",
      "     |  potrf(...)\n",
      "     |      potrf(upper=True) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.potrf`\n",
      "     |  \n",
      "     |  potri(...)\n",
      "     |      potri(upper=True) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.potri`\n",
      "     |  \n",
      "     |  potrs(...)\n",
      "     |      potrs(input2, upper=True) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.potrs`\n",
      "     |  \n",
      "     |  pow(...)\n",
      "     |      pow(exponent) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.pow`\n",
      "     |  \n",
      "     |  pow_(...)\n",
      "     |      pow_(exponent) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.pow`\n",
      "     |  \n",
      "     |  prod(...)\n",
      "     |      prod(dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.prod`\n",
      "     |  \n",
      "     |  pstrf(...)\n",
      "     |      pstrf(upper=True, tol=-1) -> (Tensor, IntTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.pstrf`\n",
      "     |  \n",
      "     |  put_(...)\n",
      "     |      put_(indices, tensor, accumulate=False) -> Tensor\n",
      "     |      \n",
      "     |      Copies the elements from :attr:`tensor` into the positions specified by\n",
      "     |      indices. For the purpose of indexing, the :attr:`self` tensor is treated as if\n",
      "     |      it were a 1-D tensor.\n",
      "     |      \n",
      "     |      If :attr:`accumulate` is ``True``, the elements in :attr:`tensor` are added to\n",
      "     |      :attr:`self`. If accumulate is ``False``, the behavior is undefined if indices\n",
      "     |      contain duplicate elements.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          indices (LongTensor): the indices into self\n",
      "     |          tensor (Tensor): the tensor containing values to copy from\n",
      "     |          accumulate (bool): whether to accumulate into self\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> src = torch.tensor([[4, 3, 5],\n",
      "     |                                  [6, 7, 8]])\n",
      "     |          >>> src.put_(torch.tensor([1, 3]), torch.tensor([9, 10]))\n",
      "     |          tensor([[  4,   9,   5],\n",
      "     |                  [ 10,   7,   8]])\n",
      "     |  \n",
      "     |  qr(...)\n",
      "     |      qr() -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.qr`\n",
      "     |  \n",
      "     |  random_(...)\n",
      "     |      random_(from=0, to=None, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with numbers sampled from the discrete uniform\n",
      "     |      distribution over ``[from, to - 1]``. If not specified, the values are usually\n",
      "     |      only bounded by :attr:`self` tensor's data type. However, for floating point\n",
      "     |      types, if unspecified, range will be ``[0, 2^mantissa]`` to ensure that every\n",
      "     |      value is representable. For example, `torch.tensor(1, dtype=torch.double).random_()`\n",
      "     |      will be uniform in ``[0, 2^53]``.\n",
      "     |  \n",
      "     |  reciprocal(...)\n",
      "     |      reciprocal() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.reciprocal`\n",
      "     |  \n",
      "     |  reciprocal_(...)\n",
      "     |      reciprocal_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.reciprocal`\n",
      "     |  \n",
      "     |  record_stream(...)\n",
      "     |  \n",
      "     |  register_hook(self, hook)\n",
      "     |      Registers a backward hook.\n",
      "     |      \n",
      "     |      The hook will be called every time a gradient with respect to the\n",
      "     |      Tensor is computed. The hook should have the following signature::\n",
      "     |      \n",
      "     |          hook(grad) -> Tensor or None\n",
      "     |      \n",
      "     |      The hook should not modify its argument, but it can optionally return\n",
      "     |      a new gradient which will be used in place of :attr:`grad`.\n",
      "     |      \n",
      "     |      This function returns a handle with a method ``handle.remove()``\n",
      "     |      that removes the hook from the module.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          >>> v = torch.tensor([0., 0., 0.], requires_grad=True)\n",
      "     |          >>> h = v.register_hook(lambda grad: grad * 2)  # double the gradient\n",
      "     |          >>> v.backward(torch.tensor([1., 2., 3.]))\n",
      "     |          >>> v.grad\n",
      "     |      \n",
      "     |           2\n",
      "     |           4\n",
      "     |           6\n",
      "     |          [torch.FloatTensor of size (3,)]\n",
      "     |      \n",
      "     |          >>> h.remove()  # removes the hook\n",
      "     |  \n",
      "     |  reinforce(self, reward)\n",
      "     |  \n",
      "     |  relu(...)\n",
      "     |  \n",
      "     |  relu_(...)\n",
      "     |  \n",
      "     |  remainder(...)\n",
      "     |      remainder(divisor) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.remainder`\n",
      "     |  \n",
      "     |  remainder_(...)\n",
      "     |      remainder_(divisor) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.remainder`\n",
      "     |  \n",
      "     |  renorm(...)\n",
      "     |      renorm(p, dim, maxnorm) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.renorm`\n",
      "     |  \n",
      "     |  renorm_(...)\n",
      "     |      renorm_(p, dim, maxnorm) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.renorm`\n",
      "     |  \n",
      "     |  repeat(...)\n",
      "     |      repeat(*sizes) -> Tensor\n",
      "     |      \n",
      "     |      Repeats this tensor along the specified dimensions.\n",
      "     |      \n",
      "     |      Unlike :meth:`~Tensor.expand`, this function copies the tensor's data.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          sizes (torch.Size or int...): The number of times to repeat this tensor along each\n",
      "     |              dimension\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([1, 2, 3])\n",
      "     |          >>> x.repeat(4, 2)\n",
      "     |          tensor([[ 1,  2,  3,  1,  2,  3],\n",
      "     |                  [ 1,  2,  3,  1,  2,  3],\n",
      "     |                  [ 1,  2,  3,  1,  2,  3],\n",
      "     |                  [ 1,  2,  3,  1,  2,  3]])\n",
      "     |          >>> x.repeat(4, 2, 1).size()\n",
      "     |          torch.Size([4, 2, 3])\n",
      "     |  \n",
      "     |  requires_grad_(...)\n",
      "     |      requires_grad_(requires_grad=True) -> Tensor\n",
      "     |      \n",
      "     |      Change if autograd should record operations on this tensor: sets this tensor's\n",
      "     |      :attr:`requires_grad` attribute in-place. Returns this tensor.\n",
      "     |      \n",
      "     |      :func:`require_grad_`'s main use case is to tell autograd to begin recording\n",
      "     |      operations on a Tensor ``tensor``. If ``tensor`` has ``requires_grad=False``\n",
      "     |      (because it was obtained through a DataLoader, or required preprocessing or\n",
      "     |      initialization), ``tensor.requires_grad_()`` makes it so that autograd will\n",
      "     |      begin to record operations on ``tensor``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          requires_grad (bool): If autograd should record operations on this tensor.\n",
      "     |              Default: ``True``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> # Let's say we want to preprocess some saved weights and use\n",
      "     |          >>> # the result as new weights.\n",
      "     |          >>> saved_weights = [0.1, 0.2, 0.3, 0.25]\n",
      "     |          >>> loaded_weights = torch.tensor(saved_weights)\n",
      "     |          >>> weights = preprocess(loaded_weights)  # some function\n",
      "     |          >>> weights\n",
      "     |          tensor([-0.5503,  0.4926, -2.1158, -0.8303])\n",
      "     |      \n",
      "     |          >>> # Now, start to record operations done to weights\n",
      "     |          >>> weights.requires_grad_()\n",
      "     |          >>> out = weights.pow(2).sum()\n",
      "     |          >>> out.backward()\n",
      "     |          >>> weights.grad\n",
      "     |          tensor([-1.1007,  0.9853, -4.2316, -1.6606])\n",
      "     |  \n",
      "     |  reshape(...)\n",
      "     |      reshape(*shape) -> Tensor\n",
      "     |      \n",
      "     |      Returns a tensor with the same data and number of elements as :attr:`self`,\n",
      "     |      but with the specified shape.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          shape (tuple of ints or int...): the desired shape\n",
      "     |      \n",
      "     |      See :func:`torch.reshape`\n",
      "     |  \n",
      "     |  resize(self, *sizes)\n",
      "     |  \n",
      "     |  resize_(...)\n",
      "     |      resize_(*sizes) -> Tensor\n",
      "     |      \n",
      "     |      Resizes :attr:`self` tensor to the specified size. If the number of elements is\n",
      "     |      larger than the current storage size, then the underlying storage is resized\n",
      "     |      to fit the new number of elements. If the number of elements is smaller, the\n",
      "     |      underlying storage is not changed. Existing elements are preserved but any new\n",
      "     |      memory is uninitialized.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          sizes (torch.Size or int...): the desired size\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1, 2], [3, 4], [5, 6]])\n",
      "     |          >>> x.resize_(2, 2)\n",
      "     |          tensor([[ 1,  2],\n",
      "     |                  [ 3,  4]])\n",
      "     |  \n",
      "     |  resize_as(self, tensor)\n",
      "     |  \n",
      "     |  resize_as_(...)\n",
      "     |      resize_as_(tensor) -> Tensor\n",
      "     |      \n",
      "     |      Resizes the :attr:`self` tensor to be the same size as the specified\n",
      "     |      :attr:`tensor`. This is equivalent to ``self.resize_(tensor.size())``.\n",
      "     |  \n",
      "     |  retain_grad(self)\n",
      "     |      Enables .grad attribute for non-leaf Tensors.\n",
      "     |  \n",
      "     |  rfft(...)\n",
      "     |      rfft(signal_ndim, normalized=False, onesided=True) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.rfft`\n",
      "     |  \n",
      "     |  round(...)\n",
      "     |      round() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.round`\n",
      "     |  \n",
      "     |  round_(...)\n",
      "     |      round_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.round`\n",
      "     |  \n",
      "     |  rsqrt(...)\n",
      "     |      rsqrt() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.rsqrt`\n",
      "     |  \n",
      "     |  rsqrt_(...)\n",
      "     |      rsqrt_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.rsqrt`\n",
      "     |  \n",
      "     |  scatter(self, dim, index, source)\n",
      "     |  \n",
      "     |  scatter_(...)\n",
      "     |      scatter_(dim, index, src) -> Tensor\n",
      "     |      \n",
      "     |      Writes all values from the tensor :attr:`src` into :attr:`self` at the indices\n",
      "     |      specified in the :attr:`index` tensor. For each value in :attr:`src`, its output\n",
      "     |      index is specified by its index in :attr:`src` for dimension != :attr:`dim` and\n",
      "     |      by the corresponding value in :attr:`index` for dimension = :attr:`dim`.\n",
      "     |      \n",
      "     |      For a 3-D tensor, :attr:`self` is updated as::\n",
      "     |      \n",
      "     |          self[index[i][j][k]][j][k] = src[i][j][k]  # if dim == 0\n",
      "     |          self[i][index[i][j][k]][k] = src[i][j][k]  # if dim == 1\n",
      "     |          self[i][j][index[i][j][k]] = src[i][j][k]  # if dim == 2\n",
      "     |      \n",
      "     |      This is the reverse operation of the manner described in :meth:`~Tensor.gather`.\n",
      "     |      \n",
      "     |      :attr:`self`, :attr:`index` and :attr:`src` should have same number of\n",
      "     |      dimensions. It is also required that `index->size[d] <= src->size[d]` for all\n",
      "     |      dimension `d`, and that `index->size[d] <= real->size[d]` for all dimensions\n",
      "     |      `d != dim`.\n",
      "     |      \n",
      "     |      Moreover, as for :meth:`~Tensor.gather`, the values of :attr:`index` must be\n",
      "     |      between `0` and `(self.size(dim) -1)` inclusive, and all values in a row along\n",
      "     |      the specified dimension :attr:`dim` must be unique.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          input (Tensor): the source tensor\n",
      "     |          dim (int): the axis along which to index\n",
      "     |          index (LongTensor): the indices of elements to scatter\n",
      "     |          src (Tensor or float): the source element(s) to scatter\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.rand(2, 5)\n",
      "     |          >>> x\n",
      "     |          tensor([[ 0.3992,  0.2908,  0.9044,  0.4850,  0.6004],\n",
      "     |                  [ 0.5735,  0.9006,  0.6797,  0.4152,  0.1732]])\n",
      "     |          >>> torch.zeros(3, 5).scatter_(0, torch.tensor([[0, 1, 2, 0, 0], [2, 0, 0, 1, 2]]), x)\n",
      "     |          tensor([[ 0.3992,  0.9006,  0.6797,  0.4850,  0.6004],\n",
      "     |                  [ 0.0000,  0.2908,  0.0000,  0.4152,  0.0000],\n",
      "     |                  [ 0.5735,  0.0000,  0.9044,  0.0000,  0.1732]])\n",
      "     |      \n",
      "     |          >>> z = torch.zeros(2, 4).scatter_(1, torch.tensor([[2], [3]]), 1.23)\n",
      "     |          >>> z\n",
      "     |          tensor([[ 0.0000,  0.0000,  1.2300,  0.0000],\n",
      "     |                  [ 0.0000,  0.0000,  0.0000,  1.2300]])\n",
      "     |  \n",
      "     |  scatter_add(self, dim, index, source)\n",
      "     |  \n",
      "     |  scatter_add_(...)\n",
      "     |  \n",
      "     |  select(...)\n",
      "     |      select(dim, index) -> Tensor\n",
      "     |      \n",
      "     |      Slices the :attr:`self` tensor along the selected dimension at the given index.\n",
      "     |      This function returns a tensor with the given dimension removed.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the dimension to slice\n",
      "     |          index (int): the index to select with\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          :meth:`select` is equivalent to slicing. For example,\n",
      "     |          ``tensor.select(0, index)`` is equivalent to ``tensor[index]`` and\n",
      "     |          ``tensor.select(2, index)`` is equivalent to ``tensor[:,:,index]``.\n",
      "     |  \n",
      "     |  set_(...)\n",
      "     |      set_(source=None, storage_offset=0, size=None, stride=None) -> Tensor\n",
      "     |      \n",
      "     |      Sets the underlying storage, size, and strides. If :attr:`source` is a tensor,\n",
      "     |      :attr:`self` tensor will share the same storage and have the same size and\n",
      "     |      strides as :attr:`source`. Changes to elements in one tensor will be reflected\n",
      "     |      in the other.\n",
      "     |      \n",
      "     |      If :attr:`source` is a :class:`~torch.Storage`, the method sets the underlying\n",
      "     |      storage, offset, size, and stride.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          source (Tensor or Storage): the tensor or storage to use\n",
      "     |          storage_offset (int, optional): the offset in the storage\n",
      "     |          size (torch.Size, optional): the desired size. Defaults to the size of the source.\n",
      "     |          stride (tuple, optional): the desired stride. Defaults to C-contiguous strides.\n",
      "     |  \n",
      "     |  share_memory_(self)\n",
      "     |      Moves the underlying storage to shared memory.\n",
      "     |      \n",
      "     |      This is a no-op if the underlying storage is already in shared memory\n",
      "     |      and for CUDA tensors. Tensors in shared memory cannot be resized.\n",
      "     |  \n",
      "     |  short(...)\n",
      "     |      short() -> Tensor\n",
      "     |      \n",
      "     |      ``self.short()`` is equivalent to ``self.to(torch.int16)``. See :func:`to`.\n",
      "     |  \n",
      "     |  sigmoid(...)\n",
      "     |      sigmoid() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sigmoid`\n",
      "     |  \n",
      "     |  sigmoid_(...)\n",
      "     |      sigmoid_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sigmoid`\n",
      "     |  \n",
      "     |  sign(...)\n",
      "     |      sign() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sign`\n",
      "     |  \n",
      "     |  sign_(...)\n",
      "     |      sign_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sign`\n",
      "     |  \n",
      "     |  sin(...)\n",
      "     |      sin() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sin`\n",
      "     |  \n",
      "     |  sin_(...)\n",
      "     |      sin_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sin`\n",
      "     |  \n",
      "     |  sinh(...)\n",
      "     |      sinh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sinh`\n",
      "     |  \n",
      "     |  sinh_(...)\n",
      "     |      sinh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sinh`\n",
      "     |  \n",
      "     |  size(...)\n",
      "     |      size() -> torch.Size\n",
      "     |      \n",
      "     |      Returns the size of the :attr:`self` tensor. The returned value is a subclass of\n",
      "     |      :class:`tuple`.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> torch.empty(3, 4, 5).size()\n",
      "     |          torch.Size([3, 4, 5])\n",
      "     |  \n",
      "     |  slice(...)\n",
      "     |  \n",
      "     |  slogdet(...)\n",
      "     |      slogdet() -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.slogdet`\n",
      "     |  \n",
      "     |  smm(...)\n",
      "     |  \n",
      "     |  sort(...)\n",
      "     |      sort(dim=None, descending=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.sort`\n",
      "     |  \n",
      "     |  split(self, split_size, dim=0)\n",
      "     |      See :func:`torch.split`\n",
      "     |  \n",
      "     |  split_with_sizes(...)\n",
      "     |  \n",
      "     |  sqrt(...)\n",
      "     |      sqrt() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sqrt`\n",
      "     |  \n",
      "     |  sqrt_(...)\n",
      "     |      sqrt_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sqrt`\n",
      "     |  \n",
      "     |  squeeze(...)\n",
      "     |      squeeze(dim=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.squeeze`\n",
      "     |  \n",
      "     |  squeeze_(...)\n",
      "     |      squeeze_(dim=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.squeeze`\n",
      "     |  \n",
      "     |  sspaddmm(...)\n",
      "     |  \n",
      "     |  std(...)\n",
      "     |      std(dim=None, unbiased=True, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.std`\n",
      "     |  \n",
      "     |  stft(...)\n",
      "     |      stft(frame_length, hop, fft_size=None, return_onesided=True, window=None, pad_end=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.stft`\n",
      "     |  \n",
      "     |  storage(...)\n",
      "     |      storage() -> torch.Storage\n",
      "     |      \n",
      "     |      Returns the underlying storage\n",
      "     |  \n",
      "     |  storage_offset(...)\n",
      "     |      storage_offset() -> int\n",
      "     |      \n",
      "     |      Returns :attr:`self` tensor's offset in the underlying storage in terms of\n",
      "     |      number of storage elements (not bytes).\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([1, 2, 3, 4, 5])\n",
      "     |          >>> x.storage_offset()\n",
      "     |          0\n",
      "     |          >>> x[3:].storage_offset()\n",
      "     |          3\n",
      "     |  \n",
      "     |  storage_type(...)\n",
      "     |  \n",
      "     |  stride(...)\n",
      "     |      stride(dim) -> tuple or int\n",
      "     |      \n",
      "     |      Returns the stride of :attr:`self` tensor.\n",
      "     |      \n",
      "     |      Stride is the jump necessary to go from one element to the next one in the\n",
      "     |      specified dimension :attr:`dim`. A tuple of all strides is returned when no\n",
      "     |      argument is passed in. Otherwise, an integer value is returned as the stride in\n",
      "     |      the particular dimension :attr:`dim`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int, optional): the desired dimension in which stride is required\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1, 2, 3, 4, 5], [6, 7, 8, 9, 10]])\n",
      "     |          >>> x.stride()\n",
      "     |          (5, 1)\n",
      "     |          >>>x.stride(0)\n",
      "     |          5\n",
      "     |          >>> x.stride(-1)\n",
      "     |          1\n",
      "     |  \n",
      "     |  sub(...)\n",
      "     |      sub(value, other) -> Tensor\n",
      "     |      \n",
      "     |      Subtracts a scalar or tensor from :attr:`self` tensor. If both :attr:`value` and\n",
      "     |      :attr:`other` are specified, each element of :attr:`other` is scaled by\n",
      "     |      :attr:`value` before being used.\n",
      "     |      \n",
      "     |      When :attr:`other` is a tensor, the shape of :attr:`other` must be\n",
      "     |      :ref:`broadcastable <broadcasting-semantics>` with the shape of the underlying\n",
      "     |      tensor.\n",
      "     |  \n",
      "     |  sub_(...)\n",
      "     |      sub_(x) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sub`\n",
      "     |  \n",
      "     |  sum(...)\n",
      "     |      sum(dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sum`\n",
      "     |  \n",
      "     |  svd(...)\n",
      "     |      svd(some=True) -> (Tensor, Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.svd`\n",
      "     |  \n",
      "     |  symeig(...)\n",
      "     |      symeig(eigenvectors=False, upper=True) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.symeig`\n",
      "     |  \n",
      "     |  t(...)\n",
      "     |      t() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.t`\n",
      "     |  \n",
      "     |  t_(...)\n",
      "     |      t_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.t`\n",
      "     |  \n",
      "     |  take(...)\n",
      "     |      take(indices) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.take`\n",
      "     |  \n",
      "     |  tan(...)\n",
      "     |  \n",
      "     |  tan_(...)\n",
      "     |      tan_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.tan`\n",
      "     |  \n",
      "     |  tanh(...)\n",
      "     |      tanh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tanh`\n",
      "     |  \n",
      "     |  tanh_(...)\n",
      "     |      tanh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.tanh`\n",
      "     |  \n",
      "     |  to(...)\n",
      "     |      to(*args, **kwargs) -> Tensor\n",
      "     |      \n",
      "     |      Performs Tensor dtype and/or device conversion. A :class:`torch.dtype` and :class:`torch.device` are\n",
      "     |      inferred from the arguments of ``self.to(*args, **kwargs)``.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          If the ``self`` Tensor already\n",
      "     |          has the correct :class:`torch.dtype` and :class:`torch.device`, then ``self`` is returned.\n",
      "     |          Otherwise, the returned tensor is a copy of ``self`` with the desired\n",
      "     |          :class:`torch.dtype` and :class:`torch.device`.\n",
      "     |      \n",
      "     |      Here are the ways to call ``to``:\n",
      "     |      \n",
      "     |      .. function:: to(dtype) -> Tensor\n",
      "     |      \n",
      "     |          Returns a Tensor with the specified :attr:`dtype`\n",
      "     |      \n",
      "     |      .. function:: to(device, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |          Returns a Tensor with the specified :attr:`device` and (optional)\n",
      "     |          :attr:`dtype`. If :attr:`dtype` is ``None`` it is inferred to be ``self.dtype``.\n",
      "     |      \n",
      "     |      .. function:: to(other) -> Tensor\n",
      "     |      \n",
      "     |          Returns a Tensor with same :class:`torch.dtype` and :class:`torch.device` as the Tensor\n",
      "     |          :attr:`other`.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.randn(2, 2)  # Initially dtype=float32, device=cpu\n",
      "     |          >>> tensor.to(torch.float64)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], dtype=torch.float64)\n",
      "     |      \n",
      "     |          >>> cuda0 = torch.device('cuda:0')\n",
      "     |          >>> tensor.to(cuda0)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], device='cuda:0')\n",
      "     |      \n",
      "     |          >>> tensor.to(cuda0, dtype=torch.float64)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], dtype=torch.float64, device='cuda:0')\n",
      "     |      \n",
      "     |          >>> other = torch.randn((), dtype=torch.float64, device=cuda0)\n",
      "     |          >>> tensor.to(other)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], dtype=torch.float64, device='cuda:0')\n",
      "     |  \n",
      "     |  to_dense(...)\n",
      "     |  \n",
      "     |  tolist(...)\n",
      "     |  \n",
      "     |  topk(...)\n",
      "     |      topk(k, dim=None, largest=True, sorted=True) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.topk`\n",
      "     |  \n",
      "     |  trace(...)\n",
      "     |      trace() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.trace`\n",
      "     |  \n",
      "     |  transpose(...)\n",
      "     |      transpose(dim0, dim1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.transpose`\n",
      "     |  \n",
      "     |  transpose_(...)\n",
      "     |      transpose_(dim0, dim1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.transpose`\n",
      "     |  \n",
      "     |  tril(...)\n",
      "     |      tril(k=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tril`\n",
      "     |  \n",
      "     |  tril_(...)\n",
      "     |      tril_(k=0) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.tril`\n",
      "     |  \n",
      "     |  triu(...)\n",
      "     |      triu(k=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.triu`\n",
      "     |  \n",
      "     |  triu_(...)\n",
      "     |      triu_(k=0) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.triu`\n",
      "     |  \n",
      "     |  trtrs(...)\n",
      "     |      trtrs(A, upper=True, transpose=False, unitriangular=False) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.trtrs`\n",
      "     |  \n",
      "     |  trunc(...)\n",
      "     |      trunc() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.trunc`\n",
      "     |  \n",
      "     |  trunc_(...)\n",
      "     |      trunc_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.trunc`\n",
      "     |  \n",
      "     |  type(...)\n",
      "     |      type(dtype=None, non_blocking=False, **kwargs) -> str or Tensor\n",
      "     |      Returns the type if `dtype` is not provided, else casts this object to\n",
      "     |      the specified type.\n",
      "     |      \n",
      "     |      If this is already of the correct type, no copy is performed and the\n",
      "     |      original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (type or string): The desired type\n",
      "     |          non_blocking (bool): If ``True``, and the source is in pinned memory\n",
      "     |              and destination is on the GPU or vice versa, the copy is performed\n",
      "     |              asynchronously with respect to the host. Otherwise, the argument\n",
      "     |              has no effect.\n",
      "     |          **kwargs: For compatibility, may contain the key ``async`` in place of\n",
      "     |              the ``non_blocking`` argument. The ``async`` arg is deprecated.\n",
      "     |  \n",
      "     |  type_as(...)\n",
      "     |      type_as(tensor) -> Tensor\n",
      "     |      \n",
      "     |      Returns this tensor cast to the type of the given tensor.\n",
      "     |      \n",
      "     |      This is a no-op if the tensor is already of the correct type. This is\n",
      "     |      equivalent to::\n",
      "     |      \n",
      "     |          self.type(tensor.type())\n",
      "     |      \n",
      "     |      Params:\n",
      "     |          tensor (Tensor): the tensor which has the desired type\n",
      "     |  \n",
      "     |  unfold(...)\n",
      "     |      unfold(dim, size, step) -> Tensor\n",
      "     |      \n",
      "     |      Returns a tensor which contains all slices of size :attr:`size` from\n",
      "     |      :attr:`self` tensor in the dimension :attr:`dim`.\n",
      "     |      \n",
      "     |      Step between two slices is given by :attr:`step`.\n",
      "     |      \n",
      "     |      If `sizedim` is the size of dimension dim for :attr:`self`, the size of\n",
      "     |      dimension :attr:`dim` in the returned tensor will be\n",
      "     |      `(sizedim - size) / step + 1`.\n",
      "     |      \n",
      "     |      An additional dimension of size size is appended in the returned tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension in which unfolding happens\n",
      "     |          size (int): the size of each slice that is unfolded\n",
      "     |          step (int): the step between each slice\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.arange(1, 8)\n",
      "     |          >>> x\n",
      "     |          tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.])\n",
      "     |          >>> x.unfold(0, 2, 1)\n",
      "     |          tensor([[ 1.,  2.],\n",
      "     |                  [ 2.,  3.],\n",
      "     |                  [ 3.,  4.],\n",
      "     |                  [ 4.,  5.],\n",
      "     |                  [ 5.,  6.],\n",
      "     |                  [ 6.,  7.]])\n",
      "     |          >>> x.unfold(0, 2, 2)\n",
      "     |          tensor([[ 1.,  2.],\n",
      "     |                  [ 3.,  4.],\n",
      "     |                  [ 5.,  6.]])\n",
      "     |  \n",
      "     |  uniform_(...)\n",
      "     |      uniform_(from=0, to=1) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with numbers sampled from the continuous uniform\n",
      "     |      distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |          P(x) = \\dfrac{1}{\\text{to} - \\text{from}}\n",
      "     |  \n",
      "     |  unique(self, sorted=False, return_inverse=False)\n",
      "     |      Returns the unique scalar elements of the tensor as a 1-D tensor.\n",
      "     |      \n",
      "     |      See :func:`torch.unique`\n",
      "     |  \n",
      "     |  unsqueeze(...)\n",
      "     |      unsqueeze(dim) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.unsqueeze`\n",
      "     |  \n",
      "     |  unsqueeze_(...)\n",
      "     |      unsqueeze_(dim) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.unsqueeze`\n",
      "     |  \n",
      "     |  var(...)\n",
      "     |      var(dim=None, unbiased=True, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.var`\n",
      "     |  \n",
      "     |  view(...)\n",
      "     |      view(*args) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new tensor with the same data as the :attr:`self` tensor but of a\n",
      "     |      different size.\n",
      "     |      \n",
      "     |      The returned tensor shares the same data and must have the same number\n",
      "     |      of elements, but may have a different size. For a tensor to be viewed, the new\n",
      "     |      view size must be compatible with its original size and stride, i.e., each new\n",
      "     |      view dimension must either be a subspace of an original dimension, or only span\n",
      "     |      across original dimensions :math:`d, d+1, \\dots, d+k` that satisfy the following\n",
      "     |      contiguity-like condition that :math:`\\forall i = 0, \\dots, k-1`,\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |        stride[i] = stride[i+1] \\times size[i+1]\n",
      "     |      \n",
      "     |      Otherwise, :func:`contiguous` needs to be called before the tensor can be\n",
      "     |      viewed.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          args (torch.Size or int...): the desired size\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.randn(4, 4)\n",
      "     |          >>> x.size()\n",
      "     |          torch.Size([4, 4])\n",
      "     |          >>> y = x.view(16)\n",
      "     |          >>> y.size()\n",
      "     |          torch.Size([16])\n",
      "     |          >>> z = x.view(-1, 8)  # the size -1 is inferred from other dimensions\n",
      "     |          >>> z.size()\n",
      "     |          torch.Size([2, 8])\n",
      "     |  \n",
      "     |  view_as(self, tensor)\n",
      "     |      view_as(other) -> Tensor\n",
      "     |      \n",
      "     |      View this tensor as the same size as :attr:`other`.\n",
      "     |      ``self.view_as(other)`` is equivalent to ``self.view(other.size())``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          other (:class:`torch.Tensor`): The result tensor has the same size\n",
      "     |              as :attr:`other.size()`.\n",
      "     |  \n",
      "     |  where(...)\n",
      "     |      where(condition, y) -> Tensor\n",
      "     |      \n",
      "     |      ``self.where(condition, y)`` is equivalent to ``torch.where(condition, self, y)``.\n",
      "     |      See :func:`torch.where`\n",
      "     |  \n",
      "     |  zero_(...)\n",
      "     |      zero_() -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with zeros.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  data\n",
      "     |  \n",
      "     |  device\n",
      "     |  \n",
      "     |  grad\n",
      "     |  \n",
      "     |  grad_fn\n",
      "     |  \n",
      "     |  is_leaf\n",
      "     |  \n",
      "     |  name\n",
      "     |  \n",
      "     |  output_nr\n",
      "     |  \n",
      "     |  requires_grad\n",
      "     |  \n",
      "     |  shape\n",
      "     |  \n",
      "     |  volatile\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  dtype = torch.int16\n",
      "     |  \n",
      "     |  is_cuda = False\n",
      "     |  \n",
      "     |  is_sparse = False\n",
      "     |  \n",
      "     |  layout = torch.strided\n",
      "    \n",
      "    class Size(builtins.tuple)\n",
      "     |  tuple() -> empty tuple\n",
      "     |  tuple(iterable) -> tuple initialized from iterable's items\n",
      "     |  \n",
      "     |  If the argument is a tuple, the return value is the same object.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Size\n",
      "     |      builtins.tuple\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __add__(self, value, /)\n",
      "     |      Return self+value.\n",
      "     |  \n",
      "     |  __contains__(self, key, /)\n",
      "     |      Return key in self.\n",
      "     |  \n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |  \n",
      "     |  __len__(self, /)\n",
      "     |      Return len(self).\n",
      "     |  \n",
      "     |  __mul__(self, value, /)\n",
      "     |      Return self*value.\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __rmul__(self, value, /)\n",
      "     |      Return value*self.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.tuple:\n",
      "     |  \n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __getnewargs__(...)\n",
      "     |  \n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __hash__(self, /)\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __iter__(self, /)\n",
      "     |      Implement iter(self).\n",
      "     |  \n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  count(...)\n",
      "     |      T.count(value) -> integer -- return number of occurrences of value\n",
      "     |  \n",
      "     |  index(...)\n",
      "     |      T.index(value, [start, [stop]]) -> integer -- return first index of value.\n",
      "     |      Raises ValueError if the value is not present.\n",
      "    \n",
      "    class Tensor(torch._C._TensorBase)\n",
      "     |  Method resolution order:\n",
      "     |      Tensor\n",
      "     |      torch._C._TensorBase\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __abs__ = abs(...)\n",
      "     |      abs() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.abs`\n",
      "     |  \n",
      "     |  __array__(self, dtype=None)\n",
      "     |      # Numpy array interface, to support `numpy.asarray(tensor) -> ndarray`\n",
      "     |  \n",
      "     |  __array_wrap__(self, array)\n",
      "     |      # Wrap Numpy array again in a suitable tensor when done, to support e.g.\n",
      "     |      # `numpy.sin(tensor) -> tensor` or `numpy.greater(tensor, 0) -> ByteTensor`\n",
      "     |  \n",
      "     |  __deepcopy__(self, memo)\n",
      "     |  \n",
      "     |  __dir__(self)\n",
      "     |      __dir__() -> list\n",
      "     |      default dir() implementation\n",
      "     |  \n",
      "     |  __eq__ = eq(...)\n",
      "     |      eq(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.eq`\n",
      "     |  \n",
      "     |  __format__(self, format_spec)\n",
      "     |      default object formatter\n",
      "     |  \n",
      "     |  __ge__ = ge(...)\n",
      "     |      ge(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ge`\n",
      "     |  \n",
      "     |  __gt__ = gt(...)\n",
      "     |      gt(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.gt`\n",
      "     |  \n",
      "     |  __hash__(self)\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __ipow__(self, other)\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |  \n",
      "     |  __itruediv__ = __idiv__(...)\n",
      "     |  \n",
      "     |  __le__ = le(...)\n",
      "     |      le(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.le`\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |      Return len(self).\n",
      "     |  \n",
      "     |  __lt__ = lt(...)\n",
      "     |      lt(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lt`\n",
      "     |  \n",
      "     |  __ne__ = ne(...)\n",
      "     |      ne(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ne`\n",
      "     |  \n",
      "     |  __neg__ = neg(...)\n",
      "     |      neg() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.neg`\n",
      "     |  \n",
      "     |  __pow__ = pow(...)\n",
      "     |      pow(exponent) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.pow`\n",
      "     |  \n",
      "     |  __rdiv__(self, other)\n",
      "     |  \n",
      "     |  __reduce_ex__(self, proto)\n",
      "     |      helper for pickle\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __rpow__(self, other)\n",
      "     |  \n",
      "     |  __rsub__(self, other)\n",
      "     |  \n",
      "     |  __rtruediv__ = __rdiv__(self, other)\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |  \n",
      "     |  argmax(self, dim=None, keepdim=False)\n",
      "     |      See :func:`torch.argmax`\n",
      "     |  \n",
      "     |  argmin(self, dim=None, keepdim=False)\n",
      "     |      See :func:`torch.argmin`\n",
      "     |  \n",
      "     |  backward(self, gradient=None, retain_graph=None, create_graph=False)\n",
      "     |      Computes the gradient of current tensor w.r.t. graph leaves.\n",
      "     |      \n",
      "     |      The graph is differentiated using the chain rule. If the tensor is\n",
      "     |      non-scalar (i.e. its data has more than one element) and requires\n",
      "     |      gradient, the function additionally requires specifying ``gradient``.\n",
      "     |      It should be a tensor of matching type and location, that contains\n",
      "     |      the gradient of the differentiated function w.r.t. ``self``.\n",
      "     |      \n",
      "     |      This function accumulates gradients in the leaves - you might need to\n",
      "     |      zero them before calling it.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          gradient (Tensor or None): Gradient w.r.t. the\n",
      "     |              tensor. If it is a tensor, it will be automatically converted\n",
      "     |              to a Tensor that does not require grad unless ``create_graph`` is True.\n",
      "     |              None values can be specified for scalar Tensors or ones that\n",
      "     |              don't require grad. If a None value would be acceptable then\n",
      "     |              this argument is optional.\n",
      "     |          retain_graph (bool, optional): If ``False``, the graph used to compute\n",
      "     |              the grads will be freed. Note that in nearly all cases setting\n",
      "     |              this option to True is not needed and often can be worked around\n",
      "     |              in a much more efficient way. Defaults to the value of\n",
      "     |              ``create_graph``.\n",
      "     |          create_graph (bool, optional): If ``True``, graph of the derivative will\n",
      "     |              be constructed, allowing to compute higher order derivative\n",
      "     |              products. Defaults to ``False``.\n",
      "     |  \n",
      "     |  btrifact(self, info=None, pivot=True)\n",
      "     |      See :func:`torch.btrifact`\n",
      "     |  \n",
      "     |  detach(...)\n",
      "     |      Returns a new Tensor, detached from the current graph.\n",
      "     |      \n",
      "     |      The result will never require gradient.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |        Returned Tensor uses the same data tensor as the original one.\n",
      "     |        In-place modifications on either of them will be seen, and may trigger\n",
      "     |        errors in correctness checks.\n",
      "     |  \n",
      "     |  detach_(...)\n",
      "     |      Detaches the Tensor from the graph that created it, making it a leaf.\n",
      "     |      Views cannot be detached in-place.\n",
      "     |  \n",
      "     |  expand_as(self, tensor)\n",
      "     |  \n",
      "     |  index_add(self, dim, index, tensor)\n",
      "     |  \n",
      "     |  index_copy(self, dim, index, tensor)\n",
      "     |  \n",
      "     |  index_fill(self, dim, index, value)\n",
      "     |  \n",
      "     |  is_pinned(self)\n",
      "     |      Returns true if this tensor resides in pinned memory\n",
      "     |  \n",
      "     |  is_shared(self)\n",
      "     |      Checks if tensor is in shared memory.\n",
      "     |      \n",
      "     |      This is always ``True`` for CUDA tensors.\n",
      "     |  \n",
      "     |  masked_copy(self, mask, tensor)\n",
      "     |  \n",
      "     |  masked_copy_(self, mask, tensor)\n",
      "     |  \n",
      "     |  masked_fill(self, mask, value)\n",
      "     |  \n",
      "     |  masked_scatter(self, mask, tensor)\n",
      "     |  \n",
      "     |  register_hook(self, hook)\n",
      "     |      Registers a backward hook.\n",
      "     |      \n",
      "     |      The hook will be called every time a gradient with respect to the\n",
      "     |      Tensor is computed. The hook should have the following signature::\n",
      "     |      \n",
      "     |          hook(grad) -> Tensor or None\n",
      "     |      \n",
      "     |      The hook should not modify its argument, but it can optionally return\n",
      "     |      a new gradient which will be used in place of :attr:`grad`.\n",
      "     |      \n",
      "     |      This function returns a handle with a method ``handle.remove()``\n",
      "     |      that removes the hook from the module.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          >>> v = torch.tensor([0., 0., 0.], requires_grad=True)\n",
      "     |          >>> h = v.register_hook(lambda grad: grad * 2)  # double the gradient\n",
      "     |          >>> v.backward(torch.tensor([1., 2., 3.]))\n",
      "     |          >>> v.grad\n",
      "     |      \n",
      "     |           2\n",
      "     |           4\n",
      "     |           6\n",
      "     |          [torch.FloatTensor of size (3,)]\n",
      "     |      \n",
      "     |          >>> h.remove()  # removes the hook\n",
      "     |  \n",
      "     |  reinforce(self, reward)\n",
      "     |  \n",
      "     |  resize(self, *sizes)\n",
      "     |  \n",
      "     |  resize_as(self, tensor)\n",
      "     |  \n",
      "     |  retain_grad(self)\n",
      "     |      Enables .grad attribute for non-leaf Tensors.\n",
      "     |  \n",
      "     |  scatter(self, dim, index, source)\n",
      "     |  \n",
      "     |  scatter_add(self, dim, index, source)\n",
      "     |  \n",
      "     |  share_memory_(self)\n",
      "     |      Moves the underlying storage to shared memory.\n",
      "     |      \n",
      "     |      This is a no-op if the underlying storage is already in shared memory\n",
      "     |      and for CUDA tensors. Tensors in shared memory cannot be resized.\n",
      "     |  \n",
      "     |  split(self, split_size, dim=0)\n",
      "     |      See :func:`torch.split`\n",
      "     |  \n",
      "     |  unique(self, sorted=False, return_inverse=False)\n",
      "     |      Returns the unique scalar elements of the tensor as a 1-D tensor.\n",
      "     |      \n",
      "     |      See :func:`torch.unique`\n",
      "     |  \n",
      "     |  view_as(self, tensor)\n",
      "     |      view_as(other) -> Tensor\n",
      "     |      \n",
      "     |      View this tensor as the same size as :attr:`other`.\n",
      "     |      ``self.view_as(other)`` is equivalent to ``self.view(other.size())``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          other (:class:`torch.Tensor`): The result tensor has the same size\n",
      "     |              as :attr:`other.size()`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch._C._TensorBase:\n",
      "     |  \n",
      "     |  __add__(...)\n",
      "     |  \n",
      "     |  __and__(...)\n",
      "     |  \n",
      "     |  __bool__(...)\n",
      "     |  \n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |  \n",
      "     |  __div__(...)\n",
      "     |  \n",
      "     |  __float__(...)\n",
      "     |  \n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |  \n",
      "     |  __iadd__(...)\n",
      "     |  \n",
      "     |  __iand__(...)\n",
      "     |  \n",
      "     |  __idiv__(...)\n",
      "     |  \n",
      "     |  __ilshift__(...)\n",
      "     |  \n",
      "     |  __imul__(...)\n",
      "     |  \n",
      "     |  __index__(...)\n",
      "     |  \n",
      "     |  __int__(...)\n",
      "     |  \n",
      "     |  __invert__(...)\n",
      "     |  \n",
      "     |  __ior__(...)\n",
      "     |  \n",
      "     |  __irshift__(...)\n",
      "     |  \n",
      "     |  __isub__(...)\n",
      "     |  \n",
      "     |  __ixor__(...)\n",
      "     |  \n",
      "     |  __long__(...)\n",
      "     |  \n",
      "     |  __lshift__(...)\n",
      "     |  \n",
      "     |  __matmul__(...)\n",
      "     |  \n",
      "     |  __mod__(...)\n",
      "     |  \n",
      "     |  __mul__(...)\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  __nonzero__(...)\n",
      "     |  \n",
      "     |  __or__(...)\n",
      "     |  \n",
      "     |  __radd__(...)\n",
      "     |  \n",
      "     |  __rmul__(...)\n",
      "     |  \n",
      "     |  __rshift__(...)\n",
      "     |  \n",
      "     |  __setitem__(self, key, value, /)\n",
      "     |      Set self[key] to value.\n",
      "     |  \n",
      "     |  __sub__(...)\n",
      "     |  \n",
      "     |  __truediv__(...)\n",
      "     |  \n",
      "     |  __xor__(...)\n",
      "     |  \n",
      "     |  abs(...)\n",
      "     |      abs() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.abs`\n",
      "     |  \n",
      "     |  abs_(...)\n",
      "     |      abs_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.abs`\n",
      "     |  \n",
      "     |  acos(...)\n",
      "     |      acos() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.acos`\n",
      "     |  \n",
      "     |  acos_(...)\n",
      "     |      acos_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.acos`\n",
      "     |  \n",
      "     |  add(...)\n",
      "     |      add(value) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.add`\n",
      "     |  \n",
      "     |  add_(...)\n",
      "     |      add_(value) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.add`\n",
      "     |  \n",
      "     |  addbmm(...)\n",
      "     |      addbmm(beta=1, mat, alpha=1, batch1, batch2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addbmm`\n",
      "     |  \n",
      "     |  addbmm_(...)\n",
      "     |      addbmm_(beta=1, mat, alpha=1, batch1, batch2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addbmm`\n",
      "     |  \n",
      "     |  addcdiv(...)\n",
      "     |      addcdiv(value=1, tensor1, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addcdiv`\n",
      "     |  \n",
      "     |  addcdiv_(...)\n",
      "     |      addcdiv_(value=1, tensor1, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addcdiv`\n",
      "     |  \n",
      "     |  addcmul(...)\n",
      "     |      addcmul(value=1, tensor1, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addcmul`\n",
      "     |  \n",
      "     |  addcmul_(...)\n",
      "     |      addcmul_(value=1, tensor1, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addcmul`\n",
      "     |  \n",
      "     |  addmm(...)\n",
      "     |      addmm(beta=1, mat, alpha=1, mat1, mat2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addmm`\n",
      "     |  \n",
      "     |  addmm_(...)\n",
      "     |      addmm_(beta=1, mat, alpha=1, mat1, mat2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addmm`\n",
      "     |  \n",
      "     |  addmv(...)\n",
      "     |      addmv(beta=1, tensor, alpha=1, mat, vec) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addmv`\n",
      "     |  \n",
      "     |  addmv_(...)\n",
      "     |      addmv_(beta=1, tensor, alpha=1, mat, vec) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addmv`\n",
      "     |  \n",
      "     |  addr(...)\n",
      "     |      addr(beta=1, alpha=1, vec1, vec2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addr`\n",
      "     |  \n",
      "     |  addr_(...)\n",
      "     |      addr_(beta=1, alpha=1, vec1, vec2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addr`\n",
      "     |  \n",
      "     |  all(...)\n",
      "     |      all() -> bool\n",
      "     |      \n",
      "     |      Returns ``True`` if all elements in the tensor are non-zero, ``False`` otherwise.\n",
      "     |  \n",
      "     |  allclose(...)\n",
      "     |  \n",
      "     |  any(...)\n",
      "     |      any() -> bool\n",
      "     |      \n",
      "     |      Returns ``True`` if any elements in the tensor are non-zero, ``False`` otherwise.\n",
      "     |  \n",
      "     |  apply_(...)\n",
      "     |      apply_(callable) -> Tensor\n",
      "     |      \n",
      "     |      Applies the function :attr:`callable` to each element in the tensor, replacing\n",
      "     |      each element with the value returned by :attr:`callable`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          This function only works with CPU tensors and should not be used in code\n",
      "     |          sections that require high performance.\n",
      "     |  \n",
      "     |  as_strided(...)\n",
      "     |  \n",
      "     |  as_strided_(...)\n",
      "     |  \n",
      "     |  asin(...)\n",
      "     |      asin() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.asin`\n",
      "     |  \n",
      "     |  asin_(...)\n",
      "     |      asin_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.asin`\n",
      "     |  \n",
      "     |  atan(...)\n",
      "     |      atan() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.atan`\n",
      "     |  \n",
      "     |  atan2(...)\n",
      "     |      atan2(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.atan2`\n",
      "     |  \n",
      "     |  atan2_(...)\n",
      "     |      atan2_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.atan2`\n",
      "     |  \n",
      "     |  atan_(...)\n",
      "     |      atan_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.atan`\n",
      "     |  \n",
      "     |  baddbmm(...)\n",
      "     |      baddbmm(beta=1, alpha=1, batch1, batch2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.baddbmm`\n",
      "     |  \n",
      "     |  baddbmm_(...)\n",
      "     |      baddbmm_(beta=1, alpha=1, batch1, batch2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.baddbmm`\n",
      "     |  \n",
      "     |  bernoulli(...)\n",
      "     |      bernoulli() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bernoulli`\n",
      "     |  \n",
      "     |  bernoulli_(...)\n",
      "     |      bernoulli_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.bernoulli`\n",
      "     |  \n",
      "     |  bmm(...)\n",
      "     |      bmm(batch2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bmm`\n",
      "     |  \n",
      "     |  btrifact_with_info(...)\n",
      "     |      btrifact_with_info(pivot=True) -> (Tensor, Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.btrifact_with_info`\n",
      "     |  \n",
      "     |  btrisolve(...)\n",
      "     |  \n",
      "     |  byte(...)\n",
      "     |      byte() -> Tensor\n",
      "     |      \n",
      "     |      ``self.byte()`` is equivalent to ``self.to(torch.uint8)``. See :func:`to`.\n",
      "     |  \n",
      "     |  cauchy_(...)\n",
      "     |      cauchy_(median=0, sigma=1, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills the tensor with numbers drawn from the Cauchy distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(x) = \\dfrac{1}{\\pi} \\dfrac{\\sigma}{(x - median)^2 + \\sigma^2}\n",
      "     |  \n",
      "     |  ceil(...)\n",
      "     |      ceil() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ceil`\n",
      "     |  \n",
      "     |  ceil_(...)\n",
      "     |      ceil_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ceil`\n",
      "     |  \n",
      "     |  char(...)\n",
      "     |      char() -> Tensor\n",
      "     |      \n",
      "     |      ``self.char()`` is equivalent to ``self.to(torch.int8)``. See :func:`to`.\n",
      "     |  \n",
      "     |  chunk(...)\n",
      "     |      chunk(chunks, dim=0) -> List of Tensors\n",
      "     |      \n",
      "     |      See :func:`torch.chunk`\n",
      "     |  \n",
      "     |  clamp(...)\n",
      "     |      clamp(min, max) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.clamp`\n",
      "     |  \n",
      "     |  clamp_(...)\n",
      "     |      clamp_(min, max) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.clamp`\n",
      "     |  \n",
      "     |  clone(...)\n",
      "     |      clone() -> Tensor\n",
      "     |      \n",
      "     |      Returns a copy of the :attr:`self` tensor. The copy has the same size and data\n",
      "     |      type as :attr:`self`.\n",
      "     |  \n",
      "     |  coalesce(...)\n",
      "     |  \n",
      "     |  contiguous(...)\n",
      "     |      contiguous() -> Tensor\n",
      "     |      \n",
      "     |      Returns a contiguous tensor containing the same data as :attr:`self` tensor. If\n",
      "     |      :attr:`self` tensor is contiguous, this function returns the :attr:`self`\n",
      "     |      tensor.\n",
      "     |  \n",
      "     |  conv_tbc(...)\n",
      "     |  \n",
      "     |  copy_(...)\n",
      "     |      copy_(src, non_blocking=False) -> Tensor\n",
      "     |      \n",
      "     |      Copies the elements from :attr:`src` into :attr:`self` tensor and returns\n",
      "     |      :attr:`self`.\n",
      "     |      \n",
      "     |      The :attr:`src` tensor must be :ref:`broadcastable <broadcasting-semantics>`\n",
      "     |      with the :attr:`self` tensor. It may be of a different data type or reside on a\n",
      "     |      different device.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          src (Tensor): the source tensor to copy from\n",
      "     |          non_blocking (bool): if ``True`` and this copy is between CPU and GPU,\n",
      "     |              the copy may occur asynchronously with respect to the host. For other\n",
      "     |              cases, this argument has no effect.\n",
      "     |  \n",
      "     |  cos(...)\n",
      "     |      cos() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cos`\n",
      "     |  \n",
      "     |  cos_(...)\n",
      "     |      cos_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.cos`\n",
      "     |  \n",
      "     |  cosh(...)\n",
      "     |      cosh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cosh`\n",
      "     |  \n",
      "     |  cosh_(...)\n",
      "     |      cosh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.cosh`\n",
      "     |  \n",
      "     |  cpu(...)\n",
      "     |  \n",
      "     |  cross(...)\n",
      "     |      cross(other, dim=-1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cross`\n",
      "     |  \n",
      "     |  cuda(...)\n",
      "     |      cuda(device=None, non_blocking=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a copy of this object in CUDA memory.\n",
      "     |      \n",
      "     |      If this object is already in CUDA memory and on the correct device,\n",
      "     |      then no copy is performed and the original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          device (:class:`torch.device`): The destination GPU device.\n",
      "     |              Defaults to the current CUDA device.\n",
      "     |          non_blocking (bool): If ``True`` and the source is in pinned memory,\n",
      "     |              the copy will be asynchronous with respect to the host.\n",
      "     |              Otherwise, the argument has no effect. Default: ``False``.\n",
      "     |  \n",
      "     |  cumprod(...)\n",
      "     |      cumprod(dim) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cumprod`\n",
      "     |  \n",
      "     |  cumsum(...)\n",
      "     |      cumsum(dim) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cumsum`\n",
      "     |  \n",
      "     |  data_ptr(...)\n",
      "     |      data_ptr() -> int\n",
      "     |      \n",
      "     |      Returns the address of the first element of :attr:`self` tensor.\n",
      "     |  \n",
      "     |  det(...)\n",
      "     |      det() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.det`\n",
      "     |  \n",
      "     |  diag(...)\n",
      "     |      diag(diagonal=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diag`\n",
      "     |  \n",
      "     |  digamma(...)\n",
      "     |  \n",
      "     |  digamma_(...)\n",
      "     |  \n",
      "     |  dim(...)\n",
      "     |      dim() -> int\n",
      "     |      \n",
      "     |      Returns the number of dimensions of :attr:`self` tensor.\n",
      "     |  \n",
      "     |  dist(...)\n",
      "     |      dist(other, p=2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.dist`\n",
      "     |  \n",
      "     |  div(...)\n",
      "     |      div(value) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.div`\n",
      "     |  \n",
      "     |  div_(...)\n",
      "     |      div_(value) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.div`\n",
      "     |  \n",
      "     |  dot(...)\n",
      "     |      dot(tensor2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.dot`\n",
      "     |  \n",
      "     |  double(...)\n",
      "     |      double() -> Tensor\n",
      "     |      \n",
      "     |      ``self.double()`` is equivalent to ``self.to(torch.float64)``. See :func:`to`.\n",
      "     |  \n",
      "     |  eig(...)\n",
      "     |      eig(eigenvectors=False) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.eig`\n",
      "     |  \n",
      "     |  element_size(...)\n",
      "     |      element_size() -> int\n",
      "     |      \n",
      "     |      Returns the size in bytes of an individual element.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> torch.tensor([]).element_size()\n",
      "     |          4\n",
      "     |          >>> torch.tensor([], dtype=torch.uint8).element_size()\n",
      "     |          1\n",
      "     |  \n",
      "     |  eq(...)\n",
      "     |      eq(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.eq`\n",
      "     |  \n",
      "     |  eq_(...)\n",
      "     |      eq_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.eq`\n",
      "     |  \n",
      "     |  equal(...)\n",
      "     |      equal(other) -> bool\n",
      "     |      \n",
      "     |      See :func:`torch.equal`\n",
      "     |  \n",
      "     |  erf(...)\n",
      "     |      erf() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.erf`\n",
      "     |  \n",
      "     |  erf_(...)\n",
      "     |  \n",
      "     |  erfinv(...)\n",
      "     |      erfinv() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.erfinv`\n",
      "     |  \n",
      "     |  erfinv_(...)\n",
      "     |  \n",
      "     |  exp(...)\n",
      "     |      exp() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.exp`\n",
      "     |  \n",
      "     |  exp_(...)\n",
      "     |      exp_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.exp`\n",
      "     |  \n",
      "     |  expand(...)\n",
      "     |      expand(*sizes) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new view of the :attr:`self` tensor with singleton dimensions expanded\n",
      "     |      to a larger size.\n",
      "     |      \n",
      "     |      Passing -1 as the size for a dimension means not changing the size of\n",
      "     |      that dimension.\n",
      "     |      \n",
      "     |      Tensor can be also expanded to a larger number of dimensions, and the\n",
      "     |      new ones will be appended at the front. For the new dimensions, the\n",
      "     |      size cannot be set to -1.\n",
      "     |      \n",
      "     |      Expanding a tensor does not allocate new memory, but only creates a\n",
      "     |      new view on the existing tensor where a dimension of size one is\n",
      "     |      expanded to a larger size by setting the ``stride`` to 0. Any dimension\n",
      "     |      of size 1 can be expanded to an arbitrary value without allocating new\n",
      "     |      memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *sizes (torch.Size or int...): the desired expanded size\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1], [2], [3]])\n",
      "     |          >>> x.size()\n",
      "     |          torch.Size([3, 1])\n",
      "     |          >>> x.expand(3, 4)\n",
      "     |          tensor([[ 1,  1,  1,  1],\n",
      "     |                  [ 2,  2,  2,  2],\n",
      "     |                  [ 3,  3,  3,  3]])\n",
      "     |          >>> x.expand(-1, 4)   # -1 means not changing the size of that dimension\n",
      "     |          tensor([[ 1,  1,  1,  1],\n",
      "     |                  [ 2,  2,  2,  2],\n",
      "     |                  [ 3,  3,  3,  3]])\n",
      "     |  \n",
      "     |  expm1(...)\n",
      "     |      expm1() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.expm1`\n",
      "     |  \n",
      "     |  expm1_(...)\n",
      "     |      expm1_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.expm1`\n",
      "     |  \n",
      "     |  exponential_(...)\n",
      "     |      exponential_(lambd=1, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with elements drawn from the exponential distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(x) = \\lambda e^{-\\lambda x}\n",
      "     |  \n",
      "     |  fft(...)\n",
      "     |      fft(signal_ndim, normalized=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fft`\n",
      "     |  \n",
      "     |  fill_(...)\n",
      "     |      fill_(value) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with the specified value.\n",
      "     |  \n",
      "     |  float(...)\n",
      "     |      float() -> Tensor\n",
      "     |      \n",
      "     |      ``self.float()`` is equivalent to ``self.to(torch.float32)``. See :func:`to`.\n",
      "     |  \n",
      "     |  floor(...)\n",
      "     |      floor() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.floor`\n",
      "     |  \n",
      "     |  floor_(...)\n",
      "     |      floor_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.floor`\n",
      "     |  \n",
      "     |  fmod(...)\n",
      "     |      fmod(divisor) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fmod`\n",
      "     |  \n",
      "     |  fmod_(...)\n",
      "     |      fmod_(divisor) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.fmod`\n",
      "     |  \n",
      "     |  frac(...)\n",
      "     |      frac() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.frac`\n",
      "     |  \n",
      "     |  frac_(...)\n",
      "     |      frac_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.frac`\n",
      "     |  \n",
      "     |  gather(...)\n",
      "     |      gather(dim, index) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.gather`\n",
      "     |  \n",
      "     |  ge(...)\n",
      "     |      ge(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ge`\n",
      "     |  \n",
      "     |  ge_(...)\n",
      "     |      ge_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ge`\n",
      "     |  \n",
      "     |  gels(...)\n",
      "     |      gels(A) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.gels`\n",
      "     |  \n",
      "     |  geometric_(...)\n",
      "     |      geometric_(p, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with elements drawn from the geometric distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(X=k) = (1 - p)^{k - 1} p\n",
      "     |  \n",
      "     |  geqrf(...)\n",
      "     |      geqrf() -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.geqrf`\n",
      "     |  \n",
      "     |  ger(...)\n",
      "     |      ger(vec2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ger`\n",
      "     |  \n",
      "     |  gesv(...)\n",
      "     |      gesv(A) -> Tensor, Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.gesv`\n",
      "     |  \n",
      "     |  get_device(...)\n",
      "     |  \n",
      "     |  gt(...)\n",
      "     |      gt(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.gt`\n",
      "     |  \n",
      "     |  gt_(...)\n",
      "     |      gt_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.gt`\n",
      "     |  \n",
      "     |  half(...)\n",
      "     |      half() -> Tensor\n",
      "     |      \n",
      "     |      ``self.half()`` is equivalent to ``self.to(torch.float16)``. See :func:`to`.\n",
      "     |  \n",
      "     |  histc(...)\n",
      "     |      histc(bins=100, min=0, max=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.histc`\n",
      "     |  \n",
      "     |  ifft(...)\n",
      "     |      ifft(signal_ndim, normalized=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ifft`\n",
      "     |  \n",
      "     |  index(...)\n",
      "     |      index(m) -> Tensor\n",
      "     |      \n",
      "     |      Selects elements from :attr:`self` tensor using a binary mask or along a given\n",
      "     |      dimension. The expression ``tensor.index(m)`` is equivalent to ``tensor[m]``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          m (int or ByteTensor or slice): the dimension or mask used to select elements\n",
      "     |  \n",
      "     |  index_add_(...)\n",
      "     |      index_add_(dim, index, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Accumulate the elements of :attr:`tensor` into the :attr:`self` tensor by adding\n",
      "     |      to the indices in the order given in :attr:`index`. For example, if ``dim == 0``\n",
      "     |      and ``index[i] == j``, then the ``i``\\ th row of :attr:`tensor` is added to the\n",
      "     |      ``j``\\ th row of :attr:`self`.\n",
      "     |      \n",
      "     |      The :attr:`dim`\\ th dimension of :attr:`tensor` must have the same size as the\n",
      "     |      length of :attr:`index` (which must be a vector), and all other dimensions must\n",
      "     |      match :attr:`self`, or an error will be raised.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension along which to index\n",
      "     |          index (LongTensor): indices of :attr:`tensor` to select from\n",
      "     |          tensor (Tensor): the tensor containing values to add\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.ones(5, 3)\n",
      "     |          >>> t = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
      "     |          >>> index = torch.tensor([0, 4, 2])\n",
      "     |          >>> x.index_add_(0, index, t)\n",
      "     |          tensor([[  2.,   3.,   4.],\n",
      "     |                  [  1.,   1.,   1.],\n",
      "     |                  [  8.,   9.,  10.],\n",
      "     |                  [  1.,   1.,   1.],\n",
      "     |                  [  5.,   6.,   7.]])\n",
      "     |  \n",
      "     |  index_copy_(...)\n",
      "     |      index_copy_(dim, index, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Copies the elements of :attr:`tensor` into the :attr:`self` tensor by selecting\n",
      "     |      the indices in the order given in :attr:`index`. For example, if ``dim == 0``\n",
      "     |      and ``index[i] == j``, then the ``i``\\ th row of :attr:`tensor` is copied to the\n",
      "     |      ``j``\\ th row of :attr:`self`.\n",
      "     |      \n",
      "     |      The :attr:`dim`\\ th dimension of :attr:`tensor` must have the same size as the\n",
      "     |      length of :attr:`index` (which must be a vector), and all other dimensions must\n",
      "     |      match :attr:`self`, or an error will be raised.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension along which to index\n",
      "     |          index (LongTensor): indices of :attr:`tensor` to select from\n",
      "     |          tensor (Tensor): the tensor containing values to copy\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.zeros(5, 3)\n",
      "     |          >>> t = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
      "     |          >>> index = torch.tensor([0, 4, 2])\n",
      "     |          >>> x.index_copy_(0, index, t)\n",
      "     |          tensor([[ 1.,  2.,  3.],\n",
      "     |                  [ 0.,  0.,  0.],\n",
      "     |                  [ 7.,  8.,  9.],\n",
      "     |                  [ 0.,  0.,  0.],\n",
      "     |                  [ 4.,  5.,  6.]])\n",
      "     |  \n",
      "     |  index_fill_(...)\n",
      "     |      index_fill_(dim, index, val) -> Tensor\n",
      "     |      \n",
      "     |      Fills the elements of the :attr:`self` tensor with value :attr:`val` by\n",
      "     |      selecting the indices in the order given in :attr:`index`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension along which to index\n",
      "     |          index (LongTensor): indices of :attr:`self` tensor to fill in\n",
      "     |          val (float): the value to fill with\n",
      "     |      \n",
      "     |      Example::\n",
      "     |          >>> x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
      "     |          >>> index = torch.tensor([0, 2])\n",
      "     |          >>> x.index_fill_(1, index, -1)\n",
      "     |          tensor([[-1.,  2., -1.],\n",
      "     |                  [-1.,  5., -1.],\n",
      "     |                  [-1.,  8., -1.]])\n",
      "     |  \n",
      "     |  index_put_(...)\n",
      "     |      index_put_(indices, value) -> Tensor\n",
      "     |      \n",
      "     |      Puts values from the tensor :attr:`value` into the tensor :attr:`self` using\n",
      "     |      the indices specified in :attr:`indices` (which is a tuple of Tensors). The\n",
      "     |      expression ``tensor.index_put_(indices, value)`` is equivalent to\n",
      "     |      ``tensor[indices] = value``. Returns :attr:`self`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          indices (tuple of LongTensor): tensors used to index into `self`.\n",
      "     |          value (Tensor): tensor of same dtype as `self`.\n",
      "     |  \n",
      "     |  index_select(...)\n",
      "     |      index_select(dim, index) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.index_select`\n",
      "     |  \n",
      "     |  int(...)\n",
      "     |      int() -> Tensor\n",
      "     |      \n",
      "     |      ``self.int()`` is equivalent to ``self.to(torch.int32)``. See :func:`to`.\n",
      "     |  \n",
      "     |  inverse(...)\n",
      "     |      inverse() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.inverse`\n",
      "     |  \n",
      "     |  irfft(...)\n",
      "     |      irfft(signal_ndim, normalized=False, onesided=True, signal_sizes=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.irfft`\n",
      "     |  \n",
      "     |  is_coalesced(...)\n",
      "     |  \n",
      "     |  is_contiguous(...)\n",
      "     |      is_contiguous() -> bool\n",
      "     |      \n",
      "     |      Returns True if :attr:`self` tensor is contiguous in memory in C order.\n",
      "     |  \n",
      "     |  is_distributed(...)\n",
      "     |  \n",
      "     |  is_floating_point(...)\n",
      "     |  \n",
      "     |  is_nonzero(...)\n",
      "     |  \n",
      "     |  is_same_size(...)\n",
      "     |  \n",
      "     |  is_set_to(...)\n",
      "     |      is_set_to(tensor) -> bool\n",
      "     |      \n",
      "     |      Returns True if this object refers to the same ``THTensor`` object from the\n",
      "     |      Torch C API as the given tensor.\n",
      "     |  \n",
      "     |  is_signed(...)\n",
      "     |  \n",
      "     |  isclose(...)\n",
      "     |  \n",
      "     |  item(...)\n",
      "     |      item() -> number\n",
      "     |      \n",
      "     |      Returns the value of this tensor as a standard Python number. This only works\n",
      "     |      for tensors with one element.\n",
      "     |      \n",
      "     |      This operation is not differentiable.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([1.0])\n",
      "     |          >>> x.item()\n",
      "     |          1.0\n",
      "     |  \n",
      "     |  kthvalue(...)\n",
      "     |      kthvalue(k, dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.kthvalue`\n",
      "     |  \n",
      "     |  le(...)\n",
      "     |      le(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.le`\n",
      "     |  \n",
      "     |  le_(...)\n",
      "     |      le_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.le`\n",
      "     |  \n",
      "     |  lerp(...)\n",
      "     |      lerp(start, end, weight) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lerp`\n",
      "     |  \n",
      "     |  lerp_(...)\n",
      "     |      lerp_(start, end, weight) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lerp`\n",
      "     |  \n",
      "     |  lgamma(...)\n",
      "     |  \n",
      "     |  lgamma_(...)\n",
      "     |  \n",
      "     |  log(...)\n",
      "     |      log() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log`\n",
      "     |  \n",
      "     |  log10(...)\n",
      "     |      log10() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log10`\n",
      "     |  \n",
      "     |  log10_(...)\n",
      "     |      log10_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log10`\n",
      "     |  \n",
      "     |  log1p(...)\n",
      "     |      log1p() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log1p`\n",
      "     |  \n",
      "     |  log1p_(...)\n",
      "     |      log1p_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log1p`\n",
      "     |  \n",
      "     |  log2(...)\n",
      "     |      log2() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log2`\n",
      "     |  \n",
      "     |  log2_(...)\n",
      "     |      log2_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log2`\n",
      "     |  \n",
      "     |  log_(...)\n",
      "     |      log_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log`\n",
      "     |  \n",
      "     |  log_normal_(...)\n",
      "     |      log_normal_(mean=1, std=2, *, generator=None)\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with numbers samples from the log-normal distribution\n",
      "     |      parameterized by the given mean (µ) and standard deviation (σ).\n",
      "     |      Note that :attr:`mean` and :attr:`stdv` are the mean and standard deviation of\n",
      "     |      the underlying normal distribution, and not of the returned distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(x) = \\dfrac{1}{x \\sigma \\sqrt{2\\pi}}\\ e^{-\\dfrac{(\\ln x - \\mu)^2}{2\\sigma^2}}\n",
      "     |  \n",
      "     |  logdet(...)\n",
      "     |      logdet() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logdet`\n",
      "     |  \n",
      "     |  long(...)\n",
      "     |      long() -> Tensor\n",
      "     |      \n",
      "     |      ``self.long()`` is equivalent to ``self.to(torch.int64)``. See :func:`to`.\n",
      "     |  \n",
      "     |  lt(...)\n",
      "     |      lt(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lt`\n",
      "     |  \n",
      "     |  lt_(...)\n",
      "     |      lt_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lt`\n",
      "     |  \n",
      "     |  map2_(...)\n",
      "     |  \n",
      "     |  map_(...)\n",
      "     |      map_(tensor, callable)\n",
      "     |      \n",
      "     |      Applies :attr:`callable` for each element in :attr:`self` tensor and the given\n",
      "     |      :attr:`tensor` and stores the results in :attr:`self` tensor. :attr:`self` tensor and\n",
      "     |      the given :attr:`tensor` must be :ref:`broadcastable <broadcasting-semantics>`.\n",
      "     |      \n",
      "     |      The :attr:`callable` should have the signature::\n",
      "     |      \n",
      "     |          def callable(a, b) -> number\n",
      "     |  \n",
      "     |  masked_fill_(...)\n",
      "     |      masked_fill_(mask, value)\n",
      "     |      \n",
      "     |      Fills elements of :attr:`self` tensor with :attr:`value` where :attr:`mask` is\n",
      "     |      one. The shape of :attr:`mask` must be\n",
      "     |      :ref:`broadcastable <broadcasting-semantics>` with the shape of the underlying\n",
      "     |      tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          mask (ByteTensor): the binary mask\n",
      "     |          value (float): the value to fill in with\n",
      "     |  \n",
      "     |  masked_scatter_(...)\n",
      "     |      masked_scatter_(mask, source)\n",
      "     |      \n",
      "     |      Copies elements from :attr:`source` into :attr:`self` tensor at positions where\n",
      "     |      the :attr:`mask` is one.\n",
      "     |      The shape of :attr:`mask` must be :ref:`broadcastable <broadcasting-semantics>`\n",
      "     |      with the shape of the underlying tensor. The :attr:`source` should have at least\n",
      "     |      as many elements as the number of ones in :attr:`mask`\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          mask (ByteTensor): the binary mask\n",
      "     |          source (Tensor): the tensor to copy from\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The :attr:`mask` operates on the :attr:`self` tensor, not on the given\n",
      "     |          :attr:`source` tensor.\n",
      "     |  \n",
      "     |  masked_select(...)\n",
      "     |      masked_select(mask) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.masked_select`\n",
      "     |  \n",
      "     |  matmul(...)\n",
      "     |      matmul(tensor2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.matmul`\n",
      "     |  \n",
      "     |  max(...)\n",
      "     |      max(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.max`\n",
      "     |  \n",
      "     |  mean(...)\n",
      "     |      mean(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.mean`\n",
      "     |  \n",
      "     |  median(...)\n",
      "     |      median(dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.median`\n",
      "     |  \n",
      "     |  min(...)\n",
      "     |      min(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.min`\n",
      "     |  \n",
      "     |  mm(...)\n",
      "     |      mm(mat2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mm`\n",
      "     |  \n",
      "     |  mode(...)\n",
      "     |      mode(dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.mode`\n",
      "     |  \n",
      "     |  mul(...)\n",
      "     |      mul(value) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mul`\n",
      "     |  \n",
      "     |  mul_(...)\n",
      "     |      mul_(value)\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.mul`\n",
      "     |  \n",
      "     |  multinomial(...)\n",
      "     |      multinomial(num_samples, replacement=False, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.multinomial`\n",
      "     |  \n",
      "     |  mv(...)\n",
      "     |      mv(vec) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mv`\n",
      "     |  \n",
      "     |  narrow(...)\n",
      "     |      narrow(dimension, start, length) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new tensor that is a narrowed version of :attr:`self` tensor. The\n",
      "     |      dimension :attr:`dim` is narrowed from :attr:`start` to :attr:`start + length`. The\n",
      "     |      returned tensor and :attr:`self` tensor share the same underlying storage.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dimension (int): the dimension along which to narrow\n",
      "     |          start (int): the starting dimension\n",
      "     |          length (int): the distance to the ending dimension\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
      "     |          >>> x.narrow(0, 0, 2)\n",
      "     |          tensor([[ 1,  2,  3],\n",
      "     |                  [ 4,  5,  6]])\n",
      "     |          >>> x.narrow(1, 1, 2)\n",
      "     |          tensor([[ 2,  3],\n",
      "     |                  [ 5,  6],\n",
      "     |                  [ 8,  9]])\n",
      "     |  \n",
      "     |  ndimension(...)\n",
      "     |      ndimension() -> int\n",
      "     |      \n",
      "     |      Alias for :meth:`~Tensor.dim()`\n",
      "     |  \n",
      "     |  ne(...)\n",
      "     |      ne(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ne`\n",
      "     |  \n",
      "     |  ne_(...)\n",
      "     |      ne_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ne`\n",
      "     |  \n",
      "     |  neg(...)\n",
      "     |      neg() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.neg`\n",
      "     |  \n",
      "     |  neg_(...)\n",
      "     |      neg_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.neg`\n",
      "     |  \n",
      "     |  nelement(...)\n",
      "     |      nelement() -> int\n",
      "     |      \n",
      "     |      Alias for :meth:`~Tensor.numel`\n",
      "     |  \n",
      "     |  new(...)\n",
      "     |  \n",
      "     |  new_empty(...)\n",
      "     |      new_empty(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with uninitialized data.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones(())\n",
      "     |          >>> tensor.new_empty((2, 3))\n",
      "     |          tensor([[ 5.8182e-18,  4.5765e-41, -1.0545e+30],\n",
      "     |                  [ 3.0949e-41,  4.4842e-44,  0.0000e+00]])\n",
      "     |  \n",
      "     |  new_full(...)\n",
      "     |      new_full(size, fill_value, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with :attr:`fill_value`.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          fill_value (scalar): the number to fill the output tensor with.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones((2,), dtype=torch.float64)\n",
      "     |          >>> tensor.new_full((3, 4), 3.141592)\n",
      "     |          tensor([[ 3.1416,  3.1416,  3.1416,  3.1416],\n",
      "     |                  [ 3.1416,  3.1416,  3.1416,  3.1416],\n",
      "     |                  [ 3.1416,  3.1416,  3.1416,  3.1416]], dtype=torch.float64)\n",
      "     |  \n",
      "     |  new_ones(...)\n",
      "     |      new_ones(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with ``1``.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (int...): a list, tuple, or :class:`torch.Size` of integers defining the\n",
      "     |              shape of the output tensor.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.tensor((), dtype=torch.int32)\n",
      "     |          >>> tensor.new_ones((2, 3))\n",
      "     |          tensor([[ 1,  1,  1],\n",
      "     |                  [ 1,  1,  1]], dtype=torch.int32)\n",
      "     |  \n",
      "     |  new_tensor(...)\n",
      "     |      new_tensor(data, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new Tensor with :attr:`data` as the tensor data.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          :func:`new_tensor` always copies :attr:`data`. If you have a Tensor\n",
      "     |          ``data`` and want to avoid a copy, use :func:`torch.Tensor.requires_grad_`\n",
      "     |          or :func:`torch.Tensor.detach`.\n",
      "     |          If you have a numpy array and want to avoid a copy, use\n",
      "     |          :func:`torch.from_numpy`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          data (array_like): The returned Tensor copies :attr:`data`.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones((2,), dtype=torch.int8)\n",
      "     |          >>> data = [[0, 1], [2, 3]]\n",
      "     |          >>> tensor.new_tensor(data)\n",
      "     |          tensor([[ 0,  1],\n",
      "     |                  [ 2,  3]], dtype=torch.int8)\n",
      "     |  \n",
      "     |  new_zeros(...)\n",
      "     |      new_zeros(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with ``0``.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (int...): a list, tuple, or :class:`torch.Size` of integers defining the\n",
      "     |              shape of the output tensor.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.tensor((), dtype=torch.float64)\n",
      "     |          >>> tensor.new_ones((2, 3))\n",
      "     |          tensor([[ 1.,  1.,  1.],\n",
      "     |                  [ 1.,  1.,  1.]], dtype=torch.float64)\n",
      "     |  \n",
      "     |  nonzero(...)\n",
      "     |      nonzero() -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.nonzero`\n",
      "     |  \n",
      "     |  norm(...)\n",
      "     |      norm(p=2, dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.norm`\n",
      "     |  \n",
      "     |  normal_(...)\n",
      "     |      normal_(mean=0, std=1, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with elements samples from the normal distribution\n",
      "     |      parameterized by :attr:`mean` and :attr:`std`.\n",
      "     |  \n",
      "     |  numel(...)\n",
      "     |      numel() -> int\n",
      "     |      \n",
      "     |      See :func:`torch.numel`\n",
      "     |  \n",
      "     |  numpy(...)\n",
      "     |      numpy() -> numpy.ndarray\n",
      "     |      \n",
      "     |      Returns :attr:`self` tensor as a NumPy :class:`ndarray`. This tensor and the\n",
      "     |      returned :class:`ndarray` share the same underlying storage. Changes to\n",
      "     |      :attr:`self` tensor will be reflected in the :class:`ndarray` and vice versa.\n",
      "     |  \n",
      "     |  orgqr(...)\n",
      "     |      orgqr(input2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.orgqr`\n",
      "     |  \n",
      "     |  ormqr(...)\n",
      "     |      ormqr(input2, input3, left=True, transpose=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ormqr`\n",
      "     |  \n",
      "     |  permute(...)\n",
      "     |  \n",
      "     |  pin_memory(...)\n",
      "     |  \n",
      "     |  polygamma(...)\n",
      "     |  \n",
      "     |  polygamma_(...)\n",
      "     |  \n",
      "     |  potrf(...)\n",
      "     |      potrf(upper=True) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.potrf`\n",
      "     |  \n",
      "     |  potri(...)\n",
      "     |      potri(upper=True) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.potri`\n",
      "     |  \n",
      "     |  potrs(...)\n",
      "     |      potrs(input2, upper=True) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.potrs`\n",
      "     |  \n",
      "     |  pow(...)\n",
      "     |      pow(exponent) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.pow`\n",
      "     |  \n",
      "     |  pow_(...)\n",
      "     |      pow_(exponent) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.pow`\n",
      "     |  \n",
      "     |  prod(...)\n",
      "     |      prod(dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.prod`\n",
      "     |  \n",
      "     |  pstrf(...)\n",
      "     |      pstrf(upper=True, tol=-1) -> (Tensor, IntTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.pstrf`\n",
      "     |  \n",
      "     |  put_(...)\n",
      "     |      put_(indices, tensor, accumulate=False) -> Tensor\n",
      "     |      \n",
      "     |      Copies the elements from :attr:`tensor` into the positions specified by\n",
      "     |      indices. For the purpose of indexing, the :attr:`self` tensor is treated as if\n",
      "     |      it were a 1-D tensor.\n",
      "     |      \n",
      "     |      If :attr:`accumulate` is ``True``, the elements in :attr:`tensor` are added to\n",
      "     |      :attr:`self`. If accumulate is ``False``, the behavior is undefined if indices\n",
      "     |      contain duplicate elements.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          indices (LongTensor): the indices into self\n",
      "     |          tensor (Tensor): the tensor containing values to copy from\n",
      "     |          accumulate (bool): whether to accumulate into self\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> src = torch.tensor([[4, 3, 5],\n",
      "     |                                  [6, 7, 8]])\n",
      "     |          >>> src.put_(torch.tensor([1, 3]), torch.tensor([9, 10]))\n",
      "     |          tensor([[  4,   9,   5],\n",
      "     |                  [ 10,   7,   8]])\n",
      "     |  \n",
      "     |  qr(...)\n",
      "     |      qr() -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.qr`\n",
      "     |  \n",
      "     |  random_(...)\n",
      "     |      random_(from=0, to=None, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with numbers sampled from the discrete uniform\n",
      "     |      distribution over ``[from, to - 1]``. If not specified, the values are usually\n",
      "     |      only bounded by :attr:`self` tensor's data type. However, for floating point\n",
      "     |      types, if unspecified, range will be ``[0, 2^mantissa]`` to ensure that every\n",
      "     |      value is representable. For example, `torch.tensor(1, dtype=torch.double).random_()`\n",
      "     |      will be uniform in ``[0, 2^53]``.\n",
      "     |  \n",
      "     |  reciprocal(...)\n",
      "     |      reciprocal() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.reciprocal`\n",
      "     |  \n",
      "     |  reciprocal_(...)\n",
      "     |      reciprocal_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.reciprocal`\n",
      "     |  \n",
      "     |  record_stream(...)\n",
      "     |  \n",
      "     |  relu(...)\n",
      "     |  \n",
      "     |  relu_(...)\n",
      "     |  \n",
      "     |  remainder(...)\n",
      "     |      remainder(divisor) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.remainder`\n",
      "     |  \n",
      "     |  remainder_(...)\n",
      "     |      remainder_(divisor) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.remainder`\n",
      "     |  \n",
      "     |  renorm(...)\n",
      "     |      renorm(p, dim, maxnorm) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.renorm`\n",
      "     |  \n",
      "     |  renorm_(...)\n",
      "     |      renorm_(p, dim, maxnorm) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.renorm`\n",
      "     |  \n",
      "     |  repeat(...)\n",
      "     |      repeat(*sizes) -> Tensor\n",
      "     |      \n",
      "     |      Repeats this tensor along the specified dimensions.\n",
      "     |      \n",
      "     |      Unlike :meth:`~Tensor.expand`, this function copies the tensor's data.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          sizes (torch.Size or int...): The number of times to repeat this tensor along each\n",
      "     |              dimension\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([1, 2, 3])\n",
      "     |          >>> x.repeat(4, 2)\n",
      "     |          tensor([[ 1,  2,  3,  1,  2,  3],\n",
      "     |                  [ 1,  2,  3,  1,  2,  3],\n",
      "     |                  [ 1,  2,  3,  1,  2,  3],\n",
      "     |                  [ 1,  2,  3,  1,  2,  3]])\n",
      "     |          >>> x.repeat(4, 2, 1).size()\n",
      "     |          torch.Size([4, 2, 3])\n",
      "     |  \n",
      "     |  requires_grad_(...)\n",
      "     |      requires_grad_(requires_grad=True) -> Tensor\n",
      "     |      \n",
      "     |      Change if autograd should record operations on this tensor: sets this tensor's\n",
      "     |      :attr:`requires_grad` attribute in-place. Returns this tensor.\n",
      "     |      \n",
      "     |      :func:`require_grad_`'s main use case is to tell autograd to begin recording\n",
      "     |      operations on a Tensor ``tensor``. If ``tensor`` has ``requires_grad=False``\n",
      "     |      (because it was obtained through a DataLoader, or required preprocessing or\n",
      "     |      initialization), ``tensor.requires_grad_()`` makes it so that autograd will\n",
      "     |      begin to record operations on ``tensor``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          requires_grad (bool): If autograd should record operations on this tensor.\n",
      "     |              Default: ``True``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> # Let's say we want to preprocess some saved weights and use\n",
      "     |          >>> # the result as new weights.\n",
      "     |          >>> saved_weights = [0.1, 0.2, 0.3, 0.25]\n",
      "     |          >>> loaded_weights = torch.tensor(saved_weights)\n",
      "     |          >>> weights = preprocess(loaded_weights)  # some function\n",
      "     |          >>> weights\n",
      "     |          tensor([-0.5503,  0.4926, -2.1158, -0.8303])\n",
      "     |      \n",
      "     |          >>> # Now, start to record operations done to weights\n",
      "     |          >>> weights.requires_grad_()\n",
      "     |          >>> out = weights.pow(2).sum()\n",
      "     |          >>> out.backward()\n",
      "     |          >>> weights.grad\n",
      "     |          tensor([-1.1007,  0.9853, -4.2316, -1.6606])\n",
      "     |  \n",
      "     |  reshape(...)\n",
      "     |      reshape(*shape) -> Tensor\n",
      "     |      \n",
      "     |      Returns a tensor with the same data and number of elements as :attr:`self`,\n",
      "     |      but with the specified shape.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          shape (tuple of ints or int...): the desired shape\n",
      "     |      \n",
      "     |      See :func:`torch.reshape`\n",
      "     |  \n",
      "     |  resize_(...)\n",
      "     |      resize_(*sizes) -> Tensor\n",
      "     |      \n",
      "     |      Resizes :attr:`self` tensor to the specified size. If the number of elements is\n",
      "     |      larger than the current storage size, then the underlying storage is resized\n",
      "     |      to fit the new number of elements. If the number of elements is smaller, the\n",
      "     |      underlying storage is not changed. Existing elements are preserved but any new\n",
      "     |      memory is uninitialized.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          sizes (torch.Size or int...): the desired size\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1, 2], [3, 4], [5, 6]])\n",
      "     |          >>> x.resize_(2, 2)\n",
      "     |          tensor([[ 1,  2],\n",
      "     |                  [ 3,  4]])\n",
      "     |  \n",
      "     |  resize_as_(...)\n",
      "     |      resize_as_(tensor) -> Tensor\n",
      "     |      \n",
      "     |      Resizes the :attr:`self` tensor to be the same size as the specified\n",
      "     |      :attr:`tensor`. This is equivalent to ``self.resize_(tensor.size())``.\n",
      "     |  \n",
      "     |  rfft(...)\n",
      "     |      rfft(signal_ndim, normalized=False, onesided=True) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.rfft`\n",
      "     |  \n",
      "     |  round(...)\n",
      "     |      round() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.round`\n",
      "     |  \n",
      "     |  round_(...)\n",
      "     |      round_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.round`\n",
      "     |  \n",
      "     |  rsqrt(...)\n",
      "     |      rsqrt() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.rsqrt`\n",
      "     |  \n",
      "     |  rsqrt_(...)\n",
      "     |      rsqrt_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.rsqrt`\n",
      "     |  \n",
      "     |  scatter_(...)\n",
      "     |      scatter_(dim, index, src) -> Tensor\n",
      "     |      \n",
      "     |      Writes all values from the tensor :attr:`src` into :attr:`self` at the indices\n",
      "     |      specified in the :attr:`index` tensor. For each value in :attr:`src`, its output\n",
      "     |      index is specified by its index in :attr:`src` for dimension != :attr:`dim` and\n",
      "     |      by the corresponding value in :attr:`index` for dimension = :attr:`dim`.\n",
      "     |      \n",
      "     |      For a 3-D tensor, :attr:`self` is updated as::\n",
      "     |      \n",
      "     |          self[index[i][j][k]][j][k] = src[i][j][k]  # if dim == 0\n",
      "     |          self[i][index[i][j][k]][k] = src[i][j][k]  # if dim == 1\n",
      "     |          self[i][j][index[i][j][k]] = src[i][j][k]  # if dim == 2\n",
      "     |      \n",
      "     |      This is the reverse operation of the manner described in :meth:`~Tensor.gather`.\n",
      "     |      \n",
      "     |      :attr:`self`, :attr:`index` and :attr:`src` should have same number of\n",
      "     |      dimensions. It is also required that `index->size[d] <= src->size[d]` for all\n",
      "     |      dimension `d`, and that `index->size[d] <= real->size[d]` for all dimensions\n",
      "     |      `d != dim`.\n",
      "     |      \n",
      "     |      Moreover, as for :meth:`~Tensor.gather`, the values of :attr:`index` must be\n",
      "     |      between `0` and `(self.size(dim) -1)` inclusive, and all values in a row along\n",
      "     |      the specified dimension :attr:`dim` must be unique.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          input (Tensor): the source tensor\n",
      "     |          dim (int): the axis along which to index\n",
      "     |          index (LongTensor): the indices of elements to scatter\n",
      "     |          src (Tensor or float): the source element(s) to scatter\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.rand(2, 5)\n",
      "     |          >>> x\n",
      "     |          tensor([[ 0.3992,  0.2908,  0.9044,  0.4850,  0.6004],\n",
      "     |                  [ 0.5735,  0.9006,  0.6797,  0.4152,  0.1732]])\n",
      "     |          >>> torch.zeros(3, 5).scatter_(0, torch.tensor([[0, 1, 2, 0, 0], [2, 0, 0, 1, 2]]), x)\n",
      "     |          tensor([[ 0.3992,  0.9006,  0.6797,  0.4850,  0.6004],\n",
      "     |                  [ 0.0000,  0.2908,  0.0000,  0.4152,  0.0000],\n",
      "     |                  [ 0.5735,  0.0000,  0.9044,  0.0000,  0.1732]])\n",
      "     |      \n",
      "     |          >>> z = torch.zeros(2, 4).scatter_(1, torch.tensor([[2], [3]]), 1.23)\n",
      "     |          >>> z\n",
      "     |          tensor([[ 0.0000,  0.0000,  1.2300,  0.0000],\n",
      "     |                  [ 0.0000,  0.0000,  0.0000,  1.2300]])\n",
      "     |  \n",
      "     |  scatter_add_(...)\n",
      "     |  \n",
      "     |  select(...)\n",
      "     |      select(dim, index) -> Tensor\n",
      "     |      \n",
      "     |      Slices the :attr:`self` tensor along the selected dimension at the given index.\n",
      "     |      This function returns a tensor with the given dimension removed.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the dimension to slice\n",
      "     |          index (int): the index to select with\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          :meth:`select` is equivalent to slicing. For example,\n",
      "     |          ``tensor.select(0, index)`` is equivalent to ``tensor[index]`` and\n",
      "     |          ``tensor.select(2, index)`` is equivalent to ``tensor[:,:,index]``.\n",
      "     |  \n",
      "     |  set_(...)\n",
      "     |      set_(source=None, storage_offset=0, size=None, stride=None) -> Tensor\n",
      "     |      \n",
      "     |      Sets the underlying storage, size, and strides. If :attr:`source` is a tensor,\n",
      "     |      :attr:`self` tensor will share the same storage and have the same size and\n",
      "     |      strides as :attr:`source`. Changes to elements in one tensor will be reflected\n",
      "     |      in the other.\n",
      "     |      \n",
      "     |      If :attr:`source` is a :class:`~torch.Storage`, the method sets the underlying\n",
      "     |      storage, offset, size, and stride.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          source (Tensor or Storage): the tensor or storage to use\n",
      "     |          storage_offset (int, optional): the offset in the storage\n",
      "     |          size (torch.Size, optional): the desired size. Defaults to the size of the source.\n",
      "     |          stride (tuple, optional): the desired stride. Defaults to C-contiguous strides.\n",
      "     |  \n",
      "     |  short(...)\n",
      "     |      short() -> Tensor\n",
      "     |      \n",
      "     |      ``self.short()`` is equivalent to ``self.to(torch.int16)``. See :func:`to`.\n",
      "     |  \n",
      "     |  sigmoid(...)\n",
      "     |      sigmoid() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sigmoid`\n",
      "     |  \n",
      "     |  sigmoid_(...)\n",
      "     |      sigmoid_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sigmoid`\n",
      "     |  \n",
      "     |  sign(...)\n",
      "     |      sign() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sign`\n",
      "     |  \n",
      "     |  sign_(...)\n",
      "     |      sign_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sign`\n",
      "     |  \n",
      "     |  sin(...)\n",
      "     |      sin() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sin`\n",
      "     |  \n",
      "     |  sin_(...)\n",
      "     |      sin_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sin`\n",
      "     |  \n",
      "     |  sinh(...)\n",
      "     |      sinh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sinh`\n",
      "     |  \n",
      "     |  sinh_(...)\n",
      "     |      sinh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sinh`\n",
      "     |  \n",
      "     |  size(...)\n",
      "     |      size() -> torch.Size\n",
      "     |      \n",
      "     |      Returns the size of the :attr:`self` tensor. The returned value is a subclass of\n",
      "     |      :class:`tuple`.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> torch.empty(3, 4, 5).size()\n",
      "     |          torch.Size([3, 4, 5])\n",
      "     |  \n",
      "     |  slice(...)\n",
      "     |  \n",
      "     |  slogdet(...)\n",
      "     |      slogdet() -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.slogdet`\n",
      "     |  \n",
      "     |  smm(...)\n",
      "     |  \n",
      "     |  sort(...)\n",
      "     |      sort(dim=None, descending=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.sort`\n",
      "     |  \n",
      "     |  split_with_sizes(...)\n",
      "     |  \n",
      "     |  sqrt(...)\n",
      "     |      sqrt() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sqrt`\n",
      "     |  \n",
      "     |  sqrt_(...)\n",
      "     |      sqrt_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sqrt`\n",
      "     |  \n",
      "     |  squeeze(...)\n",
      "     |      squeeze(dim=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.squeeze`\n",
      "     |  \n",
      "     |  squeeze_(...)\n",
      "     |      squeeze_(dim=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.squeeze`\n",
      "     |  \n",
      "     |  sspaddmm(...)\n",
      "     |  \n",
      "     |  std(...)\n",
      "     |      std(dim=None, unbiased=True, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.std`\n",
      "     |  \n",
      "     |  stft(...)\n",
      "     |      stft(frame_length, hop, fft_size=None, return_onesided=True, window=None, pad_end=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.stft`\n",
      "     |  \n",
      "     |  storage(...)\n",
      "     |      storage() -> torch.Storage\n",
      "     |      \n",
      "     |      Returns the underlying storage\n",
      "     |  \n",
      "     |  storage_offset(...)\n",
      "     |      storage_offset() -> int\n",
      "     |      \n",
      "     |      Returns :attr:`self` tensor's offset in the underlying storage in terms of\n",
      "     |      number of storage elements (not bytes).\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([1, 2, 3, 4, 5])\n",
      "     |          >>> x.storage_offset()\n",
      "     |          0\n",
      "     |          >>> x[3:].storage_offset()\n",
      "     |          3\n",
      "     |  \n",
      "     |  storage_type(...)\n",
      "     |  \n",
      "     |  stride(...)\n",
      "     |      stride(dim) -> tuple or int\n",
      "     |      \n",
      "     |      Returns the stride of :attr:`self` tensor.\n",
      "     |      \n",
      "     |      Stride is the jump necessary to go from one element to the next one in the\n",
      "     |      specified dimension :attr:`dim`. A tuple of all strides is returned when no\n",
      "     |      argument is passed in. Otherwise, an integer value is returned as the stride in\n",
      "     |      the particular dimension :attr:`dim`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int, optional): the desired dimension in which stride is required\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1, 2, 3, 4, 5], [6, 7, 8, 9, 10]])\n",
      "     |          >>> x.stride()\n",
      "     |          (5, 1)\n",
      "     |          >>>x.stride(0)\n",
      "     |          5\n",
      "     |          >>> x.stride(-1)\n",
      "     |          1\n",
      "     |  \n",
      "     |  sub(...)\n",
      "     |      sub(value, other) -> Tensor\n",
      "     |      \n",
      "     |      Subtracts a scalar or tensor from :attr:`self` tensor. If both :attr:`value` and\n",
      "     |      :attr:`other` are specified, each element of :attr:`other` is scaled by\n",
      "     |      :attr:`value` before being used.\n",
      "     |      \n",
      "     |      When :attr:`other` is a tensor, the shape of :attr:`other` must be\n",
      "     |      :ref:`broadcastable <broadcasting-semantics>` with the shape of the underlying\n",
      "     |      tensor.\n",
      "     |  \n",
      "     |  sub_(...)\n",
      "     |      sub_(x) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sub`\n",
      "     |  \n",
      "     |  sum(...)\n",
      "     |      sum(dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sum`\n",
      "     |  \n",
      "     |  svd(...)\n",
      "     |      svd(some=True) -> (Tensor, Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.svd`\n",
      "     |  \n",
      "     |  symeig(...)\n",
      "     |      symeig(eigenvectors=False, upper=True) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.symeig`\n",
      "     |  \n",
      "     |  t(...)\n",
      "     |      t() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.t`\n",
      "     |  \n",
      "     |  t_(...)\n",
      "     |      t_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.t`\n",
      "     |  \n",
      "     |  take(...)\n",
      "     |      take(indices) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.take`\n",
      "     |  \n",
      "     |  tan(...)\n",
      "     |  \n",
      "     |  tan_(...)\n",
      "     |      tan_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.tan`\n",
      "     |  \n",
      "     |  tanh(...)\n",
      "     |      tanh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tanh`\n",
      "     |  \n",
      "     |  tanh_(...)\n",
      "     |      tanh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.tanh`\n",
      "     |  \n",
      "     |  to(...)\n",
      "     |      to(*args, **kwargs) -> Tensor\n",
      "     |      \n",
      "     |      Performs Tensor dtype and/or device conversion. A :class:`torch.dtype` and :class:`torch.device` are\n",
      "     |      inferred from the arguments of ``self.to(*args, **kwargs)``.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          If the ``self`` Tensor already\n",
      "     |          has the correct :class:`torch.dtype` and :class:`torch.device`, then ``self`` is returned.\n",
      "     |          Otherwise, the returned tensor is a copy of ``self`` with the desired\n",
      "     |          :class:`torch.dtype` and :class:`torch.device`.\n",
      "     |      \n",
      "     |      Here are the ways to call ``to``:\n",
      "     |      \n",
      "     |      .. function:: to(dtype) -> Tensor\n",
      "     |      \n",
      "     |          Returns a Tensor with the specified :attr:`dtype`\n",
      "     |      \n",
      "     |      .. function:: to(device, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |          Returns a Tensor with the specified :attr:`device` and (optional)\n",
      "     |          :attr:`dtype`. If :attr:`dtype` is ``None`` it is inferred to be ``self.dtype``.\n",
      "     |      \n",
      "     |      .. function:: to(other) -> Tensor\n",
      "     |      \n",
      "     |          Returns a Tensor with same :class:`torch.dtype` and :class:`torch.device` as the Tensor\n",
      "     |          :attr:`other`.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.randn(2, 2)  # Initially dtype=float32, device=cpu\n",
      "     |          >>> tensor.to(torch.float64)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], dtype=torch.float64)\n",
      "     |      \n",
      "     |          >>> cuda0 = torch.device('cuda:0')\n",
      "     |          >>> tensor.to(cuda0)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], device='cuda:0')\n",
      "     |      \n",
      "     |          >>> tensor.to(cuda0, dtype=torch.float64)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], dtype=torch.float64, device='cuda:0')\n",
      "     |      \n",
      "     |          >>> other = torch.randn((), dtype=torch.float64, device=cuda0)\n",
      "     |          >>> tensor.to(other)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], dtype=torch.float64, device='cuda:0')\n",
      "     |  \n",
      "     |  to_dense(...)\n",
      "     |  \n",
      "     |  tolist(...)\n",
      "     |  \n",
      "     |  topk(...)\n",
      "     |      topk(k, dim=None, largest=True, sorted=True) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.topk`\n",
      "     |  \n",
      "     |  trace(...)\n",
      "     |      trace() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.trace`\n",
      "     |  \n",
      "     |  transpose(...)\n",
      "     |      transpose(dim0, dim1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.transpose`\n",
      "     |  \n",
      "     |  transpose_(...)\n",
      "     |      transpose_(dim0, dim1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.transpose`\n",
      "     |  \n",
      "     |  tril(...)\n",
      "     |      tril(k=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tril`\n",
      "     |  \n",
      "     |  tril_(...)\n",
      "     |      tril_(k=0) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.tril`\n",
      "     |  \n",
      "     |  triu(...)\n",
      "     |      triu(k=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.triu`\n",
      "     |  \n",
      "     |  triu_(...)\n",
      "     |      triu_(k=0) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.triu`\n",
      "     |  \n",
      "     |  trtrs(...)\n",
      "     |      trtrs(A, upper=True, transpose=False, unitriangular=False) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.trtrs`\n",
      "     |  \n",
      "     |  trunc(...)\n",
      "     |      trunc() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.trunc`\n",
      "     |  \n",
      "     |  trunc_(...)\n",
      "     |      trunc_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.trunc`\n",
      "     |  \n",
      "     |  type(...)\n",
      "     |      type(dtype=None, non_blocking=False, **kwargs) -> str or Tensor\n",
      "     |      Returns the type if `dtype` is not provided, else casts this object to\n",
      "     |      the specified type.\n",
      "     |      \n",
      "     |      If this is already of the correct type, no copy is performed and the\n",
      "     |      original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (type or string): The desired type\n",
      "     |          non_blocking (bool): If ``True``, and the source is in pinned memory\n",
      "     |              and destination is on the GPU or vice versa, the copy is performed\n",
      "     |              asynchronously with respect to the host. Otherwise, the argument\n",
      "     |              has no effect.\n",
      "     |          **kwargs: For compatibility, may contain the key ``async`` in place of\n",
      "     |              the ``non_blocking`` argument. The ``async`` arg is deprecated.\n",
      "     |  \n",
      "     |  type_as(...)\n",
      "     |      type_as(tensor) -> Tensor\n",
      "     |      \n",
      "     |      Returns this tensor cast to the type of the given tensor.\n",
      "     |      \n",
      "     |      This is a no-op if the tensor is already of the correct type. This is\n",
      "     |      equivalent to::\n",
      "     |      \n",
      "     |          self.type(tensor.type())\n",
      "     |      \n",
      "     |      Params:\n",
      "     |          tensor (Tensor): the tensor which has the desired type\n",
      "     |  \n",
      "     |  unfold(...)\n",
      "     |      unfold(dim, size, step) -> Tensor\n",
      "     |      \n",
      "     |      Returns a tensor which contains all slices of size :attr:`size` from\n",
      "     |      :attr:`self` tensor in the dimension :attr:`dim`.\n",
      "     |      \n",
      "     |      Step between two slices is given by :attr:`step`.\n",
      "     |      \n",
      "     |      If `sizedim` is the size of dimension dim for :attr:`self`, the size of\n",
      "     |      dimension :attr:`dim` in the returned tensor will be\n",
      "     |      `(sizedim - size) / step + 1`.\n",
      "     |      \n",
      "     |      An additional dimension of size size is appended in the returned tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension in which unfolding happens\n",
      "     |          size (int): the size of each slice that is unfolded\n",
      "     |          step (int): the step between each slice\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.arange(1, 8)\n",
      "     |          >>> x\n",
      "     |          tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.])\n",
      "     |          >>> x.unfold(0, 2, 1)\n",
      "     |          tensor([[ 1.,  2.],\n",
      "     |                  [ 2.,  3.],\n",
      "     |                  [ 3.,  4.],\n",
      "     |                  [ 4.,  5.],\n",
      "     |                  [ 5.,  6.],\n",
      "     |                  [ 6.,  7.]])\n",
      "     |          >>> x.unfold(0, 2, 2)\n",
      "     |          tensor([[ 1.,  2.],\n",
      "     |                  [ 3.,  4.],\n",
      "     |                  [ 5.,  6.]])\n",
      "     |  \n",
      "     |  uniform_(...)\n",
      "     |      uniform_(from=0, to=1) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with numbers sampled from the continuous uniform\n",
      "     |      distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |          P(x) = \\dfrac{1}{\\text{to} - \\text{from}}\n",
      "     |  \n",
      "     |  unsqueeze(...)\n",
      "     |      unsqueeze(dim) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.unsqueeze`\n",
      "     |  \n",
      "     |  unsqueeze_(...)\n",
      "     |      unsqueeze_(dim) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.unsqueeze`\n",
      "     |  \n",
      "     |  var(...)\n",
      "     |      var(dim=None, unbiased=True, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.var`\n",
      "     |  \n",
      "     |  view(...)\n",
      "     |      view(*args) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new tensor with the same data as the :attr:`self` tensor but of a\n",
      "     |      different size.\n",
      "     |      \n",
      "     |      The returned tensor shares the same data and must have the same number\n",
      "     |      of elements, but may have a different size. For a tensor to be viewed, the new\n",
      "     |      view size must be compatible with its original size and stride, i.e., each new\n",
      "     |      view dimension must either be a subspace of an original dimension, or only span\n",
      "     |      across original dimensions :math:`d, d+1, \\dots, d+k` that satisfy the following\n",
      "     |      contiguity-like condition that :math:`\\forall i = 0, \\dots, k-1`,\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |        stride[i] = stride[i+1] \\times size[i+1]\n",
      "     |      \n",
      "     |      Otherwise, :func:`contiguous` needs to be called before the tensor can be\n",
      "     |      viewed.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          args (torch.Size or int...): the desired size\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.randn(4, 4)\n",
      "     |          >>> x.size()\n",
      "     |          torch.Size([4, 4])\n",
      "     |          >>> y = x.view(16)\n",
      "     |          >>> y.size()\n",
      "     |          torch.Size([16])\n",
      "     |          >>> z = x.view(-1, 8)  # the size -1 is inferred from other dimensions\n",
      "     |          >>> z.size()\n",
      "     |          torch.Size([2, 8])\n",
      "     |  \n",
      "     |  where(...)\n",
      "     |      where(condition, y) -> Tensor\n",
      "     |      \n",
      "     |      ``self.where(condition, y)`` is equivalent to ``torch.where(condition, self, y)``.\n",
      "     |      See :func:`torch.where`\n",
      "     |  \n",
      "     |  zero_(...)\n",
      "     |      zero_() -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with zeros.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch._C._TensorBase:\n",
      "     |  \n",
      "     |  data\n",
      "     |  \n",
      "     |  device\n",
      "     |  \n",
      "     |  dtype\n",
      "     |  \n",
      "     |  grad\n",
      "     |  \n",
      "     |  grad_fn\n",
      "     |  \n",
      "     |  is_cuda\n",
      "     |  \n",
      "     |  is_leaf\n",
      "     |  \n",
      "     |  is_sparse\n",
      "     |  \n",
      "     |  layout\n",
      "     |  \n",
      "     |  name\n",
      "     |  \n",
      "     |  output_nr\n",
      "     |  \n",
      "     |  requires_grad\n",
      "     |  \n",
      "     |  shape\n",
      "     |  \n",
      "     |  volatile\n",
      "    \n",
      "    class TracingState(pybind11_builtins.pybind11_object)\n",
      "     |  Method resolution order:\n",
      "     |      TracingState\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(...)\n",
      "     |      __repr__(self: torch._C.TracingState) -> str\n",
      "     |  \n",
      "     |  __str__(...)\n",
      "     |      __str__(self: torch._C.TracingState) -> str\n",
      "     |  \n",
      "     |  export(...)\n",
      "     |      export(self: torch._C.TracingState, arg0: List[at::Tensor], arg1: int, arg2: bool) -> Tuple[bytes, Dict[str, bytes]]\n",
      "     |  \n",
      "     |  graph(...)\n",
      "     |      graph(self: torch._C.TracingState) -> torch._C.Graph\n",
      "     |  \n",
      "     |  pop_scope(...)\n",
      "     |      pop_scope(self: torch._C.TracingState) -> None\n",
      "     |  \n",
      "     |  push_scope(...)\n",
      "     |      push_scope(self: torch._C.TracingState, arg0: str) -> None\n",
      "     |  \n",
      "     |  set_graph(...)\n",
      "     |      set_graph(self: torch._C.TracingState, arg0: torch._C.Graph) -> None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |  \n",
      "     |  is_complete\n",
      "     |  \n",
      "     |  is_expired\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class Type(pybind11_builtins.pybind11_object)\n",
      "     |  Method resolution order:\n",
      "     |      Type\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(...)\n",
      "     |      __repr__(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  contiguous(...)\n",
      "     |      contiguous(self: torch._C.Type) -> torch._C.Type\n",
      "     |  \n",
      "     |  kind(...)\n",
      "     |      kind(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  scalarType(...)\n",
      "     |      scalarType(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  sizes(...)\n",
      "     |      sizes(self: torch._C.Type) -> List[int]\n",
      "     |  \n",
      "     |  strides(...)\n",
      "     |      strides(self: torch._C.Type) -> List[int]\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class Use(pybind11_builtins.pybind11_object)\n",
      "     |  Method resolution order:\n",
      "     |      Use\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  offset\n",
      "     |  \n",
      "     |  user\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class Value(pybind11_builtins.pybind11_object)\n",
      "     |  Method resolution order:\n",
      "     |      Value\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(...)\n",
      "     |      __repr__(self: torch._C.Value) -> str\n",
      "     |  \n",
      "     |  copyMetadata(...)\n",
      "     |      copyMetadata(self: torch._C.Value, arg0: torch._C.Value) -> torch._C.Value\n",
      "     |  \n",
      "     |  inferTypeFrom(...)\n",
      "     |      inferTypeFrom(self: torch._C.Value, arg0: at::Tensor) -> None\n",
      "     |  \n",
      "     |  isHandle(...)\n",
      "     |      isHandle(self: torch._C.Value) -> bool\n",
      "     |  \n",
      "     |  node(...)\n",
      "     |      node(self: torch._C.Value) -> torch::jit::Node\n",
      "     |  \n",
      "     |  offset(...)\n",
      "     |      offset(self: torch._C.Value) -> int\n",
      "     |  \n",
      "     |  replaceAllUsesWith(...)\n",
      "     |      replaceAllUsesWith(self: torch._C.Value, arg0: torch._C.Value) -> None\n",
      "     |  \n",
      "     |  setStage(...)\n",
      "     |      setStage(self: torch._C.Value, arg0: int) -> torch._C.Value\n",
      "     |  \n",
      "     |  setType(...)\n",
      "     |      setType(self: torch._C.Value, arg0: torch::jit::Type) -> torch._C.Value\n",
      "     |  \n",
      "     |  setTypeAs(...)\n",
      "     |      setTypeAs(self: torch._C.Value, arg0: torch._C.Value) -> torch._C.Value\n",
      "     |  \n",
      "     |  setUniqueName(...)\n",
      "     |      setUniqueName(self: torch._C.Value, arg0: str) -> torch._C.Value\n",
      "     |  \n",
      "     |  stage(...)\n",
      "     |      stage(self: torch._C.Value) -> int\n",
      "     |  \n",
      "     |  type(...)\n",
      "     |      type(self: torch._C.Value) -> torch::jit::Type\n",
      "     |  \n",
      "     |  unique(...)\n",
      "     |      unique(self: torch._C.Value) -> int\n",
      "     |  \n",
      "     |  uniqueName(...)\n",
      "     |      uniqueName(self: torch._C.Value) -> str\n",
      "     |  \n",
      "     |  uses(...)\n",
      "     |      uses(self: torch._C.Value) -> List[torch::jit::Use]\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    __class__ = class module(object)\n",
      "     |  module(name[, doc])\n",
      "     |  \n",
      "     |  Create a module object.\n",
      "     |  The name must be a string; the optional doc argument can have any type.\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __delattr__(self, name, /)\n",
      "     |      Implement delattr(self, name).\n",
      "     |  \n",
      "     |  __dir__(...)\n",
      "     |      __dir__() -> list\n",
      "     |      specialized dir() implementation\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setattr__(self, name, value, /)\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "    \n",
      "    device = class Device(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  index\n",
      "     |  \n",
      "     |  type\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "    \n",
      "    class dtype(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  is_floating_point\n",
      "    \n",
      "    class enable_grad(builtins.object)\n",
      "     |  Context-manager that enables gradient calculation.\n",
      "     |  \n",
      "     |  Enables gradient calculation inside a :class:`~no_grad` context. This has\n",
      "     |  no effect outside of :class:`~no_grad`.\n",
      "     |  \n",
      "     |  \n",
      "     |  Example::\n",
      "     |  \n",
      "     |      >>> x = torch.tensor([1], requires_grad=True)\n",
      "     |      >>> with torch.no_grad():\n",
      "     |      ...   with torch.enable_grad():\n",
      "     |      ...     y = x * 2\n",
      "     |      >>> y.requires_grad\n",
      "     |      True\n",
      "     |      >>> y.backward()\n",
      "     |      >>> x.grad\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __enter__(self)\n",
      "     |  \n",
      "     |  __exit__(self, *args)\n",
      "     |  \n",
      "     |  __init__(self)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class layout(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "    \n",
      "    class no_grad(builtins.object)\n",
      "     |  Context-manager that disabled gradient calculation.\n",
      "     |  \n",
      "     |  Disabling gradient calculation is useful for inference, when you are sure\n",
      "     |  that you will not call :meth:`Tensor.backward()`. It will reduce memory\n",
      "     |  consumption for computations that would otherwise have `requires_grad=True`.\n",
      "     |  In this mode, the result of every computation will have\n",
      "     |  `requires_grad=False`, even when the inputs have `requires_grad=True`.\n",
      "     |  \n",
      "     |  Example::\n",
      "     |  \n",
      "     |      >>> x = torch.tensor([1], requires_grad=True)\n",
      "     |      >>> with torch.no_grad():\n",
      "     |      ...   y = x * 2\n",
      "     |      >>> y.requires_grad\n",
      "     |      False\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __enter__(self)\n",
      "     |  \n",
      "     |  __exit__(self, *args)\n",
      "     |  \n",
      "     |  __init__(self)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class set_grad_enabled(builtins.object)\n",
      "     |  Context-manager that sets gradient calculation to on or off.\n",
      "     |  \n",
      "     |  ``set_grad_enabled`` will enable or disable grads based on its argument :attr:`mode`.\n",
      "     |  It can be used as a context-manager or as a function.\n",
      "     |  \n",
      "     |  Arguments:\n",
      "     |      mode (bool): Flag whether to enable grad (``True``), or disable\n",
      "     |                   (``False``). This can be used to conditionally enable\n",
      "     |                   gradients.\n",
      "     |  \n",
      "     |  \n",
      "     |  Example::\n",
      "     |  \n",
      "     |      >>> x = torch.tensor([1], requires_grad=True)\n",
      "     |      >>> is_train = False\n",
      "     |      >>> with torch.set_grad_enabled(is_train):\n",
      "     |      ...   y = x * 2\n",
      "     |      >>> y.requires_grad\n",
      "     |      False\n",
      "     |      >>> set_grad_enabled(True)\n",
      "     |      >>> y = x * 2\n",
      "     |      >>> y.requires_grad\n",
      "     |      True\n",
      "     |      >>> set_grad_enabled(False)\n",
      "     |      >>> y = x * 2\n",
      "     |      >>> y.requires_grad\n",
      "     |      True\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __enter__(self)\n",
      "     |  \n",
      "     |  __exit__(self, *args)\n",
      "     |  \n",
      "     |  __init__(self, mode)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "\n",
      "FUNCTIONS\n",
      "    __and__(...)\n",
      "    \n",
      "    __delattr__(self, name, /)\n",
      "        Implement delattr(self, name).\n",
      "    \n",
      "    __dir__(...)\n",
      "        __dir__() -> list\n",
      "        default dir() implementation\n",
      "    \n",
      "    __eq__(self, value, /)\n",
      "        Return self==value.\n",
      "    \n",
      "    __format__(...)\n",
      "        default object formatter\n",
      "    \n",
      "    __ge__(self, value, /)\n",
      "        Return self>=value.\n",
      "    \n",
      "    __getattribute__(self, name, /)\n",
      "        Return getattr(self, name).\n",
      "    \n",
      "    __gt__(self, value, /)\n",
      "        Return self>value.\n",
      "    \n",
      "    __hash__(self, /)\n",
      "        Return hash(self).\n",
      "    \n",
      "    __init__(self, /, *args, **kwargs)\n",
      "        Initialize self.  See help(type(self)) for accurate signature.\n",
      "    \n",
      "    __init_subclass__(...) method of builtins.type instance\n",
      "        This method is called when a class is subclassed.\n",
      "        \n",
      "        The default implementation does nothing. It may be\n",
      "        overridden to extend subclasses.\n",
      "    \n",
      "    __le__(self, value, /)\n",
      "        Return self<=value.\n",
      "    \n",
      "    __lshift__(...)\n",
      "    \n",
      "    __lt__(self, value, /)\n",
      "        Return self<value.\n",
      "    \n",
      "    __ne__(self, value, /)\n",
      "        Return self!=value.\n",
      "    \n",
      "    __new__(*args, **kwargs) method of builtins.type instance\n",
      "        Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    __or__(...)\n",
      "    \n",
      "    __reduce__(...)\n",
      "        helper for pickle\n",
      "    \n",
      "    __reduce_ex__(...)\n",
      "        helper for pickle\n",
      "    \n",
      "    __repr__(self, /)\n",
      "        Return repr(self).\n",
      "    \n",
      "    __rshift__(...)\n",
      "    \n",
      "    __setattr__(self, name, value, /)\n",
      "        Implement setattr(self, name, value).\n",
      "    \n",
      "    __sizeof__(...)\n",
      "        __sizeof__() -> int\n",
      "        size of object in memory, in bytes\n",
      "    \n",
      "    __str__(self, /)\n",
      "        Return str(self).\n",
      "    \n",
      "    __subclasshook__(...) method of builtins.type instance\n",
      "        Abstract classes can override this to customize issubclass().\n",
      "        \n",
      "        This is invoked early on by abc.ABCMeta.__subclasscheck__().\n",
      "        It should return True, False or NotImplemented.  If it returns\n",
      "        NotImplemented, the normal algorithm is used.  Otherwise, it\n",
      "        overrides the normal algorithm (and the outcome is cached).\n",
      "    \n",
      "    __xor__(...)\n",
      "    \n",
      "    chunk(...)\n",
      "        chunk(tensor, chunks, dim=0) -> List of Tensors\n",
      "        \n",
      "        Splits a tensor into a specific number of chunks.\n",
      "        \n",
      "        Last chunk will be smaller if the tensor size along the given dimension\n",
      "        :attr:`dim` is not divisible by :attr:`chunks`.\n",
      "        \n",
      "        Arguments:\n",
      "            tensor (Tensor): the tensor to split\n",
      "            chunks (int): number of chunks to return\n",
      "            dim (int): dimension along which to split the tensor\n",
      "    \n",
      "    get_default_dtype(...)\n",
      "        get_default_dtype() -> :class:`torch.dtype`\n",
      "        \n",
      "        Get the current default floating point :class:`torch.dtype`.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> torch.get_default_dtype()  # initial default for floating point is torch.float32\n",
      "            torch.float32\n",
      "            >>> torch.set_default_dtype(torch.float64)\n",
      "            >>> torch.get_default_dtype()  # default is now changed to torch.float64\n",
      "            torch.float64\n",
      "            >>> torch.set_default_tensor_type(torch.FloatTensor)  # setting tensor type also affects this\n",
      "            >>> torch.get_default_dtype()  # changed to torch.float32, the dtype for torch.FloatTensor\n",
      "            torch.float32\n",
      "    \n",
      "    get_num_threads(...)\n",
      "        get_num_threads() -> int\n",
      "        \n",
      "        Gets the number of OpenMP threads used for parallelizing CPU operations\n",
      "    \n",
      "    get_rng_state()\n",
      "        Returns the random number generator state as a `torch.ByteTensor`.\n",
      "    \n",
      "    initial_seed()\n",
      "        Returns the initial seed for generating random numbers as a\n",
      "        Python `long`.\n",
      "    \n",
      "    is_grad_enabled(...)\n",
      "    \n",
      "    is_storage(obj)\n",
      "        Returns True if `obj` is a PyTorch storage object.\n",
      "        \n",
      "        Args:\n",
      "            obj (Object): Object to test\n",
      "    \n",
      "    is_tensor(obj)\n",
      "        Returns True if `obj` is a PyTorch tensor.\n",
      "        \n",
      "        Args:\n",
      "            obj (Object): Object to test\n",
      "    \n",
      "    load(f, map_location=None, pickle_module=<module 'pickle' from '/opt/conda/lib/python3.6/pickle.py'>)\n",
      "        Loads an object saved with :func:`torch.save` from a file.\n",
      "        \n",
      "        :meth:`torch.load` uses Python's unpickling facilities but treats storages,\n",
      "        which underlie tensors, specially. They are first deserialized on the\n",
      "        CPU and are then moved to the device they were saved from. If this fails\n",
      "        (e.g. because the run time system doesn't have certain devices), an exception\n",
      "        is raised. However, storages can be dynamically remapped to an alternative\n",
      "        set of devices using the `map_location` argument.\n",
      "        \n",
      "        If `map_location` is a callable, it will be called once for each serialized\n",
      "        storage with two arguments: storage and location. The storage argument\n",
      "        will be the initial deserialization of the storage, residing on the CPU.\n",
      "        Each serialized storage has a location tag associated with it which\n",
      "        identifies the device it was saved from, and this tag is the second\n",
      "        argument passed to map_location. The builtin location tags are `'cpu'` for\n",
      "        CPU tensors and `'cuda:device_id'` (e.g. `'cuda:2'`) for CUDA tensors.\n",
      "        `map_location` should return either None or a storage. If `map_location` returns\n",
      "        a storage, it will be used as the final deserialized object, already moved to\n",
      "        the right device. Otherwise, :math:`torch.load` will fall back to the default\n",
      "        behavior, as if `map_location` wasn't specified.\n",
      "        \n",
      "        If `map_location` is a string, it should be a device tag, where all tensors\n",
      "        should be loaded.\n",
      "        \n",
      "        Otherwise, if `map_location` is a dict, it will be used to remap location tags\n",
      "        appearing in the file (keys), to ones that specify where to put the\n",
      "        storages (values).\n",
      "        \n",
      "        User extensions can register their own location tags and tagging and\n",
      "        deserialization methods using `register_package`.\n",
      "        \n",
      "        Args:\n",
      "            f: a file-like object (has to implement read, readline, tell, and seek),\n",
      "                or a string containing a file name\n",
      "            map_location: a function, string or a dict specifying how to remap storage\n",
      "                locations\n",
      "            pickle_module: module used for unpickling metadata and objects (has to\n",
      "                match the pickle_module used to serialize file)\n",
      "        \n",
      "        Example:\n",
      "            >>> torch.load('tensors.pt')\n",
      "            # Load all tensors onto the CPU\n",
      "            >>> torch.load('tensors.pt', map_location='cpu')\n",
      "            # Load all tensors onto the CPU, using a function\n",
      "            >>> torch.load('tensors.pt', map_location=lambda storage, loc: storage)\n",
      "            # Load all tensors onto GPU 1\n",
      "            >>> torch.load('tensors.pt', map_location=lambda storage, loc: storage.cuda(1))\n",
      "            # Map tensors from GPU 1 to GPU 0\n",
      "            >>> torch.load('tensors.pt', map_location={'cuda:1':'cuda:0'})\n",
      "            # Load tensor from io.BytesIO object\n",
      "            >>> with open('tensor.pt') as f:\n",
      "                    buffer = io.BytesIO(f.read())\n",
      "            >>> torch.load(buffer)\n",
      "    \n",
      "    manual_seed(seed)\n",
      "        Sets the seed for generating random numbers. Returns a\n",
      "        `torch._C.Generator` object.\n",
      "        \n",
      "        Args:\n",
      "            seed (int): The desired seed.\n",
      "    \n",
      "    matmul(...)\n",
      "        matmul(tensor1, tensor2, out=None) -> Tensor\n",
      "        \n",
      "        Matrix product of two tensors.\n",
      "        \n",
      "        The behavior depends on the dimensionality of the tensors as follows:\n",
      "        \n",
      "        - If both tensors are 1-dimensional, the dot product (scalar) is returned.\n",
      "        - If both arguments are 2-dimensional, the matrix-matrix product is returned.\n",
      "        - If the first argument is 1-dimensional and the second argument is 2-dimensional,\n",
      "          a 1 is prepended to its dimension for the purpose of the matrix multiply.\n",
      "          After the matrix multiply, the prepended dimension is removed.\n",
      "        - If the first argument is 2-dimensional and the second argument is 1-dimensional,\n",
      "          the matrix-vector product is returned.\n",
      "        - If both arguments are at least 1-dimensional and at least one argument is\n",
      "          N-dimensional (where N > 2), then a batched matrix multiply is returned.  If the first\n",
      "          argument is 1-dimensional, a 1 is prepended to its dimension for the purpose of the\n",
      "          batched matrix multiply and removed after.  If the second argument is 1-dimensional, a\n",
      "          1 is appended to its dimension for the purpose of the batched matrix multiple and removed after.\n",
      "          The non-matrix (i.e. batch) dimensions are :ref:`broadcasted <broadcasting-semantics>` (and thus\n",
      "          must be broadcastable).  For example, if :attr:`tensor1` is a\n",
      "          :math:`(j \\times 1 \\times n \\times m)` tensor and :attr:`tensor2` is a :math:`(k \\times m \\times p)`\n",
      "          tensor, :attr:`out` will be an :math:`(j \\times k \\times n \\times p)` tensor.\n",
      "        \n",
      "        .. note::\n",
      "        \n",
      "            The 1-dimensional dot product version of this function does not support an :attr:`out` parameter.\n",
      "        \n",
      "        Arguments:\n",
      "            tensor1 (Tensor): the first tensor to be multiplied\n",
      "            tensor2 (Tensor): the second tensor to be multiplied\n",
      "            out (Tensor, optional): the output tensor\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> # vector x vector\n",
      "            >>> tensor1 = torch.randn(3)\n",
      "            >>> tensor2 = torch.randn(3)\n",
      "            >>> torch.matmul(tensor1, tensor2).size()\n",
      "            torch.Size([])\n",
      "            >>> # matrix x vector\n",
      "            >>> tensor1 = torch.randn(3, 4)\n",
      "            >>> tensor2 = torch.randn(4)\n",
      "            >>> torch.matmul(tensor1, tensor2).size()\n",
      "            torch.Size([3])\n",
      "            >>> # batched matrix x broadcasted vector\n",
      "            >>> tensor1 = torch.randn(10, 3, 4)\n",
      "            >>> tensor2 = torch.randn(4)\n",
      "            >>> torch.matmul(tensor1, tensor2).size()\n",
      "            torch.Size([10, 3])\n",
      "            >>> # batched matrix x batched matrix\n",
      "            >>> tensor1 = torch.randn(10, 3, 4)\n",
      "            >>> tensor2 = torch.randn(10, 4, 5)\n",
      "            >>> torch.matmul(tensor1, tensor2).size()\n",
      "            torch.Size([10, 3, 5])\n",
      "            >>> # batched matrix x broadcasted matrix\n",
      "            >>> tensor1 = torch.randn(10, 3, 4)\n",
      "            >>> tensor2 = torch.randn(4, 5)\n",
      "            >>> torch.matmul(tensor1, tensor2).size()\n",
      "            torch.Size([10, 3, 5])\n",
      "    \n",
      "    save(obj, f, pickle_module=<module 'pickle' from '/opt/conda/lib/python3.6/pickle.py'>, pickle_protocol=2)\n",
      "        Saves an object to a disk file.\n",
      "        \n",
      "        See also: :ref:`recommend-saving-models`\n",
      "        \n",
      "        Args:\n",
      "            obj: saved object\n",
      "            f: a file-like object (has to implement write and flush) or a string\n",
      "               containing a file name\n",
      "            pickle_module: module used for pickling metadata and objects\n",
      "            pickle_protocol: can be specified to override the default protocol\n",
      "        \n",
      "        .. warning::\n",
      "            If you are using Python 2, torch.save does NOT support StringIO.StringIO\n",
      "            as a valid file-like object. This is because the write method should return\n",
      "            the number of bytes written; StringIO.write() does not do this.\n",
      "        \n",
      "            Please use something like io.BytesIO instead.\n",
      "        \n",
      "        Example:\n",
      "            >>> # Save to file\n",
      "            >>> x = torch.tensor([0, 1, 2, 3, 4])\n",
      "            >>> torch.save(x, 'tensor.pt')\n",
      "            >>> # Save to io.BytesIO buffer\n",
      "            >>> buffer = io.BytesIO()\n",
      "            >>> torch.save(x, buffer)\n",
      "    \n",
      "    set_default_tensor_type(t)\n",
      "        Sets the default ``torch.Tensor`` type to floating point tensor type\n",
      "        :attr:`t`. This type will also be used as default floating point type for\n",
      "        type inference in :func:`torch.tensor`.\n",
      "        \n",
      "        The default floating point tensor type is initially ``torch.FloatTensor``.\n",
      "        \n",
      "        Args:\n",
      "            t (type or string): the floating point tensor type or its name\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> torch.tensor([1.2, 3]).dtype    # initial default for floating point is torch.float32\n",
      "            torch.float32\n",
      "            >>> torch.set_default_tensor_type(torch.DoubleTensor)\n",
      "            >>> torch.tensor([1.2, 3]).dtype    # a new floating point tensor\n",
      "            torch.float64\n",
      "    \n",
      "    set_flush_denormal(...)\n",
      "        set_flush_denormal(mode) -> bool\n",
      "        \n",
      "        Disables denormal floating numbers on CPU.\n",
      "        \n",
      "        Returns ``True`` if your system supports flushing denormal numbers and it\n",
      "        successfully configures flush denormal mode.  :meth:`~torch.set_flush_denormal`\n",
      "        is only supported on x86 architectures supporting SSE3.\n",
      "        \n",
      "        Args:\n",
      "            mode (bool): Controls whether to enable flush denormal mode or not\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> torch.set_flush_denormal(True)\n",
      "            True\n",
      "            >>> torch.tensor([1e-323], dtype=torch.float64)\n",
      "            tensor([ 0.], dtype=torch.float64)\n",
      "            >>> torch.set_flush_denormal(False)\n",
      "            True\n",
      "            >>> torch.tensor([1e-323], dtype=torch.float64)\n",
      "            tensor(9.88131e-324 *\n",
      "                   [ 1.0000], dtype=torch.float64)\n",
      "    \n",
      "    set_num_threads(...)\n",
      "        set_num_threads(int)\n",
      "        \n",
      "        Sets the number of OpenMP threads used for parallelizing CPU operations\n",
      "    \n",
      "    set_printoptions(precision=None, threshold=None, edgeitems=None, linewidth=None, profile=None)\n",
      "        Set options for printing. Items shamelessly taken from NumPy\n",
      "        \n",
      "        Args:\n",
      "            precision: Number of digits of precision for floating point output\n",
      "                (default = 8).\n",
      "            threshold: Total number of array elements which trigger summarization\n",
      "                rather than full `repr` (default = 1000).\n",
      "            edgeitems: Number of array items in summary at beginning and end of\n",
      "                each dimension (default = 3).\n",
      "            linewidth: The number of characters per line for the purpose of\n",
      "                inserting line breaks (default = 80). Thresholded matrices will\n",
      "                ignore this parameter.\n",
      "            profile: Sane defaults for pretty printing. Can override with any of\n",
      "                the above options. (any one of `default`, `short`, `full`)\n",
      "    \n",
      "    set_rng_state(new_state)\n",
      "        Sets the random number generator state.\n",
      "        \n",
      "        Args:\n",
      "            new_state (torch.ByteTensor): The desired state\n",
      "    \n",
      "    split(tensor, split_size_or_sections, dim=0)\n",
      "        Splits the tensor into chunks.\n",
      "        \n",
      "        If :attr:`split_size_or_sections` is an integer type, then :attr:`tensor` will\n",
      "        be split into equally sized chunks (if possible). Last chunk will be smaller if\n",
      "        the tensor size along the given dimension :attr:`dim= is not divisible by\n",
      "        :attr:`split_size`.\n",
      "        \n",
      "        If :attr:`split_size_or_sections` is a list, then :attr:`tensor` will be split\n",
      "        into ``len(split_size_or_sections)`` chunks with sizes in :attr:`dim` according\n",
      "        to :attr:`split_size_or_sections`.\n",
      "        \n",
      "        Arguments:\n",
      "            tensor (Tensor): tensor to split.\n",
      "            split_size_or_sections (int) or (list(int)): size of a single chunk or\n",
      "            list of sizes for each chunk\n",
      "            dim (int): dimension along which to split the tensor.\n",
      "    \n",
      "    stack(...)\n",
      "        stack(seq, dim=0, out=None) -> Tensor\n",
      "        \n",
      "        Concatenates sequence of tensors along a new dimension.\n",
      "        \n",
      "        All tensors need to be of the same size.\n",
      "        \n",
      "        Arguments:\n",
      "            seq (sequence of Tensors): sequence of tensors to concatenate\n",
      "            dim (int): dimension to insert. Has to be between 0 and the number\n",
      "                of dimensions of concatenated tensors (inclusive)\n",
      "            out (Tensor, optional): the output tensor\n",
      "    \n",
      "    typename(o)\n",
      "\n",
      "DATA\n",
      "    __all__ = ['typename', 'is_tensor', 'is_storage', 'set_default_tensor_...\n",
      "    default_generator = <torch._C.Generator object>\n",
      "    has_cudnn = True\n",
      "    has_mkl = True\n",
      "\n",
      "VERSION\n",
      "    0.4.0\n",
      "\n",
      "FILE\n",
      "    /opt/conda/lib/python3.6/site-packages/torch/__init__.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
